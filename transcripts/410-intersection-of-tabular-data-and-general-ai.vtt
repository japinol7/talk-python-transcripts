WEBVTT

00:00:00.000 --> 00:00:02.200
AI has taken the world by storm.


00:00:02.200 --> 00:00:05.520
It's gone from near zero to amazing in just a few years.


00:00:05.520 --> 00:00:08.460
We have chat GDP, we have stable diffusion.


00:00:08.460 --> 00:00:10.840
What about Jupyter notebooks and pandas?


00:00:10.840 --> 00:00:14.280
In this episode, we meet Justin Wong, the creator of Sketch.


00:00:14.280 --> 00:00:20.720
Sketch adds the ability to have conversational AI interactions about your pandas data frames,


00:00:20.720 --> 00:00:24.040
code and data right inside of your notebook.


00:00:24.040 --> 00:00:27.040
It's pretty powerful and I know you'll enjoy the conversation.


00:00:27.040 --> 00:00:34.040
This is Talk Python to Me, episode 410, recorded April 2nd, 2023.


00:00:34.040 --> 00:00:48.360
Welcome to Talk Python to Me, a weekly podcast on Python.


00:00:48.360 --> 00:00:50.200
This is your host, Michael Kennedy.


00:00:50.200 --> 00:00:55.120
Follow me on Mastodon, where I'm @mkennedy, and follow the podcast using @talkpython,


00:00:55.120 --> 00:00:57.360
both on bostodon.org.


00:00:57.360 --> 00:01:00.000
Be careful with impersonating accounts on other instances.


00:01:00.000 --> 00:01:01.200
There are many.


00:01:01.200 --> 00:01:03.320
Keep up with the show and listen to over seven years


00:01:03.320 --> 00:01:06.700
of past episodes at talkpython.fm.


00:01:06.700 --> 00:01:08.760
We've started streaming most of our episodes


00:01:08.760 --> 00:01:10.200
live on YouTube.


00:01:10.200 --> 00:01:11.400
Subscribe to our YouTube channel


00:01:11.400 --> 00:01:13.800
over at talkpython.fm/youtube


00:01:13.800 --> 00:01:16.000
to get notified about upcoming shows


00:01:16.000 --> 00:01:18.200
and be part of that episode.


00:01:18.200 --> 00:01:20.760
This episode is brought to you by brilliant.org


00:01:20.760 --> 00:01:24.560
and us with our online courses over at Talk Python Training.


00:01:24.560 --> 00:01:27.960
Justin, welcome to TalkByTheNemy.


00:01:27.960 --> 00:01:28.960
Thanks for having me.


00:01:28.960 --> 00:01:29.960
It's great to have you here.


00:01:29.960 --> 00:01:30.960
I'm a little suspicious.


00:01:30.960 --> 00:01:37.120
I got to know, I really know how to test whether you're actually Justin or an AI speaking


00:01:37.120 --> 00:01:38.120
as Justin.


00:01:38.120 --> 00:01:40.480
What's the deal here?


00:01:40.480 --> 00:01:41.480
There's no way to know now.


00:01:41.480 --> 00:01:42.480
No, there's not.


00:01:42.480 --> 00:01:46.240
Well, apparently I've recently learned from you that I can give you a bunch of Xs and


00:01:46.240 --> 00:01:48.480
other arbitrary characters.


00:01:48.480 --> 00:01:49.800
This is like the test.


00:01:49.800 --> 00:01:54.800
It's like asking Germans to say squirrel in World War II sort of thing.


00:01:54.800 --> 00:01:55.800
It's the test.


00:01:55.800 --> 00:01:56.800
It's the tell.


00:01:56.800 --> 00:01:58.300
>> There's always going to be something.


00:01:58.300 --> 00:02:00.800
Some sort of adversarial attack.


00:02:00.800 --> 00:02:01.800
>> Exactly.


00:02:01.800 --> 00:02:05.800
It's only going to get more interesting with this kind of stuff, for sure.


00:02:05.800 --> 00:02:12.800
We're going to talk about using generative AI in large language models, paired with things


00:02:12.800 --> 00:02:17.800
like pandas, or consumed with straight Python with a couple of your projects, which are


00:02:17.800 --> 00:02:18.800
super exciting.


00:02:18.800 --> 00:02:24.800
I think it's going to empower a lot of people in ways that it hasn't really been done yet.


00:02:24.800 --> 00:02:27.800
So, awesome on that. But before we get to it, let's start with your story.


00:02:27.800 --> 00:02:30.800
How did you get into programming and Python and AI?


00:02:30.800 --> 00:02:36.800
I got into programming just like when I was a kid, TI-83, learning to code on that.


00:02:36.800 --> 00:02:39.800
And then sort of just kept it up as a side hobby my whole life.


00:02:39.800 --> 00:02:43.800
Didn't ever sort of choose it as my career path or anything for a while.


00:02:43.800 --> 00:02:44.800
It chose you.


00:02:44.800 --> 00:02:47.800
Yeah, it chose me. I dragged it along with me everywhere.


00:02:47.800 --> 00:02:54.600
is just like the toolkit. I got a went to undergrad and for physics electrical engineering,


00:02:54.600 --> 00:03:00.440
then did a physics PhD, experimental physics. During that, I did a lot of non traditional


00:03:00.440 --> 00:03:06.760
languages, things like LabVIEW, Igor Pro, just weird, Windows, Windows hotkey for like,


00:03:06.760 --> 00:03:11.560
just trying to like automate things. Yeah, sure. So just was sort of dragging that along. But along


00:03:11.560 --> 00:03:16.680
that path, I sort of came across GPUs and used it for accelerating processing, specifically,


00:03:16.680 --> 00:03:21.640
like particle detection. So it was doing some like electron counting in some


00:03:21.640 --> 00:03:23.080
just detector experiments.


00:03:23.080 --> 00:03:25.720
Is this like CUDA cores on NVIDIA type things?


00:03:25.720 --> 00:03:26.040
Precisely.


00:03:26.040 --> 00:03:26.920
Stuff like that. Okay.


00:03:26.920 --> 00:03:27.400
That was the...


00:03:27.400 --> 00:03:29.640
Was that with Python or was that with C++ or what?


00:03:29.640 --> 00:03:33.640
At the time it was C++ and I made like a DLL and then called it from LabVIEW.


00:03:33.640 --> 00:03:37.160
Wow, that's some crazy integration. That's like drag and drop programming too


00:03:37.160 --> 00:03:39.640
on the memory GPU.


00:03:39.640 --> 00:03:43.800
Exactly. It was all over the place. Also had, it was a distributed LabVIEW project.


00:03:43.800 --> 00:03:48.040
that we had multiple machines that were coordinating and doing this all just to


00:03:48.040 --> 00:03:53.000
move some motors and measured electrons. But it got me into kudos stuff, which


00:03:53.000 --> 00:03:57.560
then at the time was around the time that the like Alex net some of these


00:03:57.560 --> 00:04:00.400
like very first neural net stuff was happening. And so those same


00:04:00.400 --> 00:04:03.720
convolutional kernels were the same exact code I was trying to write to run


00:04:03.720 --> 00:04:06.440
like convolutions on these images. And so it's like, Oh, look at this like


00:04:06.440 --> 00:04:09.360
paper. Let me go read it. It seems like it's got so many citations. This is


00:04:09.360 --> 00:04:12.120
interesting. And then like that sent me down the rabbit hole like, Oh, this


00:04:12.120 --> 00:04:16.720
AI stuff. Okay, let me go deep dive into this. And then that just, I'd say that like became


00:04:16.720 --> 00:04:21.720
the obsession from them. Yeah, it's been like, eight years of doing that, then sort of just


00:04:21.720 --> 00:04:26.460
after I left academia, tried my own startup, then joined multiple others and just sort


00:04:26.460 --> 00:04:31.320
of have been bouncing around as the sort of like, founding engineer, early engineer at


00:04:31.320 --> 00:04:36.760
a startup for a while now. And yeah, Python has been the choice ever since, like late


00:04:36.760 --> 00:04:42.920
grad school and on, I would say it sort of like came through the pandas and numpy part, but then


00:04:42.920 --> 00:04:47.400
stuck for the scripting, like just power, just can throw anything together at any time.


00:04:47.400 --> 00:04:55.160
So it seems like there were two groups that were just hammering GPUs, hammering them. Crypto miners


00:04:55.160 --> 00:05:01.480
and AI people. But the physicists and some of those people doing large scale research like that,


00:05:01.480 --> 00:05:08.520
they were the OG graphics card users, right? Way before crypto mining existed and really before AI


00:05:08.520 --> 00:05:11.640
was using graphics cards all that much. When I was like looking at some of the code,


00:05:11.640 --> 00:05:15.480
like pre-CUDA, there were some like quant traders that were doing some like crazy stuff


00:05:15.480 --> 00:05:20.280
off of shaders. Like it wasn't even CUDA yet, but it was shaders and they were trying to like


00:05:20.280 --> 00:05:24.600
extract the compute power out of them from that. So, it's like, look, if we could shave


00:05:24.600 --> 00:05:31.000
one millisecond off this, we can short them all day. Let's do it. But yeah, the physicist has


00:05:31.000 --> 00:05:33.760
It's always been, yeah, it's always the get as much compute


00:05:33.760 --> 00:05:35.920
as you can out of the devices you have


00:05:35.920 --> 00:05:37.960
'cause simulations are slow.


00:05:37.960 --> 00:05:40.760
- Yeah, I remember when I was in grad school studying math,


00:05:40.760 --> 00:05:44.280
actually senior year, regular college, my bachelor's,


00:05:44.280 --> 00:05:46.960
the research team that I was on had gotten


00:05:46.960 --> 00:05:50.640
a used Silicon Graphics computer for a quarter million


00:05:50.640 --> 00:05:54.120
dollars and some Onyx workstations that we all were given.


00:05:54.120 --> 00:05:56.080
I'm like, this thing is so awesome.


00:05:56.080 --> 00:05:59.160
A couple years later, like an NVIDIA graphics card


00:05:59.160 --> 00:06:02.040
and like a simple PC would crush it.


00:06:02.040 --> 00:06:03.240
Like that's $2,000.


00:06:03.240 --> 00:06:05.720
It's just, yeah, there's so much power in those things


00:06:05.720 --> 00:06:07.760
to be able to harness them for whatever, I guess.


00:06:07.760 --> 00:06:09.560
- Yeah, as long as you don't have too much branching,


00:06:09.560 --> 00:06:11.320
it works really well.


00:06:11.320 --> 00:06:12.440
- Awesome.


00:06:12.440 --> 00:06:16.680
So let's jump in and start talking about,


00:06:16.680 --> 00:06:18.720
let's start to talk about ChatGP


00:06:18.720 --> 00:06:20.640
and some of this AI stuff


00:06:20.640 --> 00:06:24.000
before we totally get into the projects


00:06:24.000 --> 00:06:24.820
that you're working on,


00:06:24.820 --> 00:06:31.100
brings that type of conversational generative AI to things like pandas, as


00:06:31.100 --> 00:06:35.740
you said, but to me, I don't know how, maybe you've been more on the inside


00:06:35.740 --> 00:06:40.740
than I have, but to me, it looks like AI has been one of those things that's


00:06:40.740 --> 00:06:42.580
30 years in the future forever, right?


00:06:42.580 --> 00:06:45.700
It was like the Turing test and, oh, here's a chat.


00:06:45.700 --> 00:06:48.700
I'm going to talk to this thing and see if it feels human or not.


00:06:48.700 --> 00:06:53.860
And then, you know, there was like OCR and, and then all of a sudden we got


00:06:53.860 --> 00:06:57.200
self-driving cars, like, wait a minute, that's actually solving real problems.


00:06:57.200 --> 00:07:02.080
And then we got things like chat GTP, where people are like, wait, this can do my job.


00:07:02.080 --> 00:07:06.920
It seems like it just in the last couple of years, there's been some inflection


00:07:06.920 --> 00:07:08.460
point in this world.


00:07:08.460 --> 00:07:09.200
What do you think?


00:07:09.200 --> 00:07:12.160
Yeah, I think there's sort of like two key things that have sort of happened in


00:07:12.160 --> 00:07:15.440
the past, I guess, four or five years, four years, roughly.


00:07:15.440 --> 00:07:19.320
One is the attention is all you need paper from Google, sort of this


00:07:19.320 --> 00:07:23.160
transformer architecture came out and it's sort of a good, very hungry model


00:07:23.180 --> 00:07:27.500
that can just sort of absorb a lot of facts and just like a nice learnable key value store almost.


00:07:27.500 --> 00:07:28.500
That's stuff.


00:07:28.500 --> 00:07:32.660
So, and then the other thing is, is that GPUs, we were sort of just talking about GPU compute,


00:07:32.660 --> 00:07:38.460
but this has just been really, GPU compute has really been growing so fast.


00:07:38.460 --> 00:07:41.260
If you like look at the like Moore's law equivalent type things,


00:07:41.260 --> 00:07:45.180
like it's just, it's faster how much we're getting flops out of these things like faster and faster.


00:07:45.180 --> 00:07:47.020
So it's been really nice.


00:07:47.020 --> 00:07:52.020
I mean, obviously, there'll be a wall eventually, but it's been good writing this like exponential curve for a bit.


00:07:52.020 --> 00:07:55.780
Yeah. Is the benefit that we're getting from the faster GPUs,


00:07:55.780 --> 00:07:59.740
is that because people are able to program it better and the frameworks are


00:07:59.740 --> 00:08:03.580
getting better or because just the raw processing power is getting better?


00:08:03.580 --> 00:08:04.340
All of the above.


00:08:04.340 --> 00:08:04.660
Okay.


00:08:04.660 --> 00:08:07.660
I think that there was a paper that tried to dissect this.


00:08:07.660 --> 00:08:08.860
I wish I knew the reference,


00:08:08.860 --> 00:08:12.420
but I believe that their argument was that it was actually more the processing


00:08:12.420 --> 00:08:15.020
power was getting better. The actual like physical silicon,


00:08:15.020 --> 00:08:17.860
we're getting better at making that for specifically this type of stuff,


00:08:17.860 --> 00:08:20.300
but like how on exponentials. But yeah.


00:08:20.340 --> 00:08:22.740
- Yeah, yeah, yeah, the power that those things take.


00:08:22.740 --> 00:08:25.180
I have a gaming system over there


00:08:25.180 --> 00:08:29.660
and it has a GeForce 2070 Super.


00:08:29.660 --> 00:08:31.140
I don't know what the Super really gets me,


00:08:31.140 --> 00:08:33.620
but it's better than the not Super, I guess.


00:08:33.620 --> 00:08:37.980
Anyway, that one still plugs into the wall normal,


00:08:37.980 --> 00:08:40.300
but the newer ones like the 4090s,


00:08:40.300 --> 00:08:42.740
those things, the amount of power they consume,


00:08:42.740 --> 00:08:45.780
it's like space heater level of power.


00:08:45.780 --> 00:08:47.820
Like, I don't know, 800 watts or something


00:08:47.820 --> 00:08:49.220
just for the GPU.


00:08:49.220 --> 00:08:51.540
- You're gonna brown out the house


00:08:51.540 --> 00:08:53.420
if you plug in too many of those.


00:08:53.420 --> 00:08:57.740
- Yeah, go look at those DGX A100 clusters


00:08:57.740 --> 00:08:59.820
and they've got like eight of those A100s


00:08:59.820 --> 00:09:01.540
just stacked right in there.


00:09:01.540 --> 00:09:03.540
They take really beefy power supply.


00:09:03.540 --> 00:09:07.460
- It's built directly attached to the power plant,


00:09:07.460 --> 00:09:09.340
electrical power plant.


00:09:09.340 --> 00:09:10.780
Nuts, okay, so yeah, so those things


00:09:10.780 --> 00:09:12.180
are getting really, really massive.


00:09:12.180 --> 00:09:14.660
Here's the paper, "Attention is all you need"


00:09:14.660 --> 00:09:16.340
from Google Research.


00:09:16.340 --> 00:09:18.420
What was the story of that?


00:09:18.420 --> 00:09:19.420
How's that play into things?


00:09:19.420 --> 00:09:24.060
Yeah, so this came up during machine translation research at Google.


00:09:24.060 --> 00:09:29.660
And the core thing is they present this idea of,


00:09:29.660 --> 00:09:33.420
instead of just stacking these layers of neural nets like we're used to,


00:09:33.420 --> 00:09:38.980
they replace the neural net layer with this concept of a transformer block.


00:09:38.980 --> 00:09:43.100
A transformer block has this concept inside that's an attention mechanism.


00:09:43.100 --> 00:09:46.780
The attention mechanism is effectively three matrices


00:09:46.780 --> 00:09:51.040
that you combine in a specific order. And the sort of logic is


00:09:51.040 --> 00:09:54.760
it is that one of the vectors takes you from some space to


00:09:54.760 --> 00:09:57.820
keys. So it's almost like it's like identifying labels out of


00:09:57.820 --> 00:10:02.140
your data. Another one is taking you from your data to queries.


00:10:02.140 --> 00:10:05.180
And then it like dot products those to find a weight. And then


00:10:05.180 --> 00:10:08.640
for the one and then another one finds weight values for your


00:10:08.640 --> 00:10:12.040
things. So it takes this query and key, you get the weights for


00:10:12.040 --> 00:10:15.140
them. And then you take the ones that were sort of the closest to


00:10:15.140 --> 00:10:18.140
get those values from the third matrix. Yeah, just doing it sort


00:10:18.140 --> 00:10:21.380
of like looks a little bit like a, you know, accessing an


00:10:21.380 --> 00:10:23.300
element in a dictionary, like, you know, key value lookup.


00:10:23.300 --> 00:10:27.020
Yeah. And they, it's a differentiable version of that.


00:10:27.020 --> 00:10:30.140
And it did really well on their machine learning, sorry, on


00:10:30.140 --> 00:10:33.700
their machine translation stuff. This was a think it's like one


00:10:33.700 --> 00:10:37.580
of the first big one is this Bert model. And that paper sort


00:10:37.580 --> 00:10:41.740
of the architecture of the actual neural net code is


00:10:42.260 --> 00:10:45.380
effectively unchanged from this to ChatGPT.


00:10:45.380 --> 00:10:50.340
Like there's a lot of stuff for like milking performance and increasing stability,


00:10:50.340 --> 00:10:55.020
but the actual like core essence of the actual mechanism that drives it, it's the same thing since this paper.


00:10:55.020 --> 00:10:58.220
Interesting. It's funny that Google didn't release something sooner.


00:10:58.220 --> 00:11:06.860
It's wild that they've had, they keep showing off that they've got like, equivalent or better things at different times, but then not releasing it.


00:11:06.860 --> 00:11:10.940
When Dolly happened, they had image in Imagine, I guess, I don't know how you say it.


00:11:10.940 --> 00:11:16.340
And what was the party as the two said two different, really good, way better


00:11:16.340 --> 00:11:19.700
than Dolly, way better than stable diffusion models like the that had


00:11:19.700 --> 00:11:23.420
brought out and they like showed it, demoed it like, but never released it to


00:11:23.420 --> 00:11:23.860
be used.


00:11:23.860 --> 00:11:27.540
So yeah, it's one of these, who knows what's going to happen with Google if


00:11:27.540 --> 00:11:28.860
they keep holding on to these things?


00:11:28.860 --> 00:11:30.940
Yeah, well, I think there was some hesitation.


00:11:30.940 --> 00:11:34.700
I don't know holds up on accuracy or weird stuff like that.


00:11:34.700 --> 00:11:35.660
Sure.


00:11:35.660 --> 00:11:38.060
Yeah, now it cuts out of the bag now.


00:11:38.060 --> 00:11:38.620
Now it's happening.


00:11:38.620 --> 00:11:42.500
Yeah, the cat's out of the bag and people are racing to do the best they can.


00:11:42.500 --> 00:11:47.100
And it's going to have interesting consequences for us, both positive and


00:11:47.100 --> 00:11:50.580
negative, I think, but you know, let's leverage the positive once the cat's


00:11:50.580 --> 00:11:51.580
out of the bag anyway, right?


00:11:51.580 --> 00:11:51.860
Yeah.


00:11:51.860 --> 00:11:54.660
Hopefully you might as well like ask it questions for pandas.


00:11:54.660 --> 00:11:58.580
So let's play a little bit with chat GDP and maybe another one


00:11:58.580 --> 00:12:00.580
of these, image type things.


00:12:00.580 --> 00:12:04.460
So I came in here and I stole this example from a blog post.


00:12:04.460 --> 00:12:08.620
is pretty nice about not using deeply nested codes.


00:12:08.620 --> 00:12:12.520
You can use a design pattern called a guarding clause


00:12:12.520 --> 00:12:15.180
that will look and say if the conditions are not right,


00:12:15.180 --> 00:12:17.900
we're going to return early instead of having


00:12:17.900 --> 00:12:21.220
if something, if that also, if something else.


00:12:21.220 --> 00:12:24.200
So there's this example that is written in a poor way


00:12:24.200 --> 00:12:26.820
and it says like it's checking for a platypus.


00:12:26.820 --> 00:12:31.460
So it says if self.isMammal, if self.hasFur,


00:12:31.460 --> 00:12:33.860
if self.hasBeak, et cetera, et cetera.


00:12:33.860 --> 00:12:35.540
It's all deeply nested.


00:12:35.540 --> 00:12:38.740
And just for people who haven't played with chat GDP, like I put that in and


00:12:38.740 --> 00:12:41.600
they said, sure, I told her I wanted to call this arrow because it looks like


00:12:41.600 --> 00:12:45.140
an arrow and it says, it tells me a little bit about this.


00:12:45.140 --> 00:12:46.020
So I'm going to ask it.


00:12:46.020 --> 00:12:53.860
Please rewrite arrow to be less nested with guarding clauses, right?


00:12:53.860 --> 00:12:55.020
This is like a machine, right?


00:12:55.020 --> 00:12:57.460
If I tell it this, what is it going to say?


00:12:57.460 --> 00:12:58.420
Let's see.


00:12:58.420 --> 00:13:00.660
It may fail, but it might, I think it's going to get it.


00:13:00.660 --> 00:13:01.900
It's thinking I put it.


00:13:01.900 --> 00:13:04.900
I mistakenly put it into chat to be four, which takes longer.


00:13:04.900 --> 00:13:06.640
I might switch it over to three.


00:13:06.640 --> 00:13:07.180
I don't know.


00:13:07.180 --> 00:13:11.860
But the, the understanding of these things, there's a lot of hype about it.


00:13:11.860 --> 00:13:16.260
Like, I think you kind of agree with me that maybe this hype is worthwhile.


00:13:16.260 --> 00:13:16.680
Here we go.


00:13:16.680 --> 00:13:18.540
So, look at this.


00:13:18.540 --> 00:13:19.740
It rewrote.


00:13:19.740 --> 00:13:21.280
It's a deaf is platypus.


00:13:21.280 --> 00:13:23.260
If not self as man, I'll return false.


00:13:23.260 --> 00:13:25.580
If not has for, and there's no more nesting.


00:13:25.580 --> 00:13:26.120
That's pretty cool.


00:13:26.120 --> 00:13:26.420
Right?


00:13:26.420 --> 00:13:26.840
Yep.


00:13:26.840 --> 00:13:29.780
I mean, I'm sure you've, you've, you've played with stuff like this, right?


00:13:29.780 --> 00:13:30.580
Well, you've, yeah.


00:13:30.580 --> 00:13:31.340
Big user of this.


00:13:31.400 --> 00:13:32.760
I mean, this is kind of interesting, right?


00:13:32.760 --> 00:13:34.520
Like it understood there was a structure


00:13:34.520 --> 00:13:35.720
and it understood what these were


00:13:35.720 --> 00:13:36.920
and it understood what I said,


00:13:36.920 --> 00:13:39.120
but what's more impressive is like,


00:13:39.120 --> 00:13:44.120
please rewrite the program to check for crocodiles,


00:13:44.120 --> 00:13:49.720
crocodiles, and you know, what is it gonna do here?


00:13:49.720 --> 00:13:51.120
Let's see.


00:13:51.120 --> 00:13:52.880
It says, sure, no problem.


00:13:52.880 --> 00:13:54.520
Then writes the function is crocodile.


00:13:54.520 --> 00:13:56.520
If not, self.is reptile.


00:13:56.520 --> 00:13:58.420
If not, self.has scales.


00:13:58.420 --> 00:14:01.080
If not, self.has long snout.


00:14:01.080 --> 00:14:04.560
Oh my gosh, like it not only remembered,


00:14:04.560 --> 00:14:06.560
oh yeah, there's this new version I wrote


00:14:06.560 --> 00:14:08.560
in the garden clause format,


00:14:08.560 --> 00:14:10.880
but then it rewrote the tests.


00:14:10.880 --> 00:14:13.840
I mean, and then it's explaining to me


00:14:13.840 --> 00:14:16.320
why it wrote it that way.


00:14:16.320 --> 00:14:19.080
It's just, it's mind blowing,


00:14:19.080 --> 00:14:22.280
like how much you can have conversations with this


00:14:22.280 --> 00:14:24.720
and how much it understands things like code


00:14:24.720 --> 00:14:26.240
or physics or history.


00:14:26.240 --> 00:14:27.700
What do you think?


00:14:27.700 --> 00:14:28.720
- Yeah, it's really satisfying.


00:14:28.720 --> 00:14:32.700
I love that it's such a powerful generalist


00:14:32.700 --> 00:14:34.640
at these things that are found on the internet.


00:14:34.640 --> 00:14:37.200
So if it exists and it's in the training data,


00:14:37.200 --> 00:14:40.000
it can do so good at synthesizing, composing,


00:14:40.000 --> 00:14:41.240
bridging between them.


00:14:41.240 --> 00:14:42.200
It's really satisfying.


00:14:42.200 --> 00:14:44.480
So it's really fun asking it to-- as you're doing,


00:14:44.480 --> 00:14:46.080
rewriting, changing language.


00:14:46.080 --> 00:14:48.120
I've been getting into a lot more JavaScript


00:14:48.120 --> 00:14:49.480
because I'm doing a bunch more front end stuff.


00:14:49.480 --> 00:14:52.200
And just I sometimes will write a quick one-liner in Python


00:14:52.200 --> 00:14:54.800
that I know how to do with list comprehension.


00:14:54.800 --> 00:14:57.160
And then I'll be like, make this for me in JavaScript


00:14:57.160 --> 00:15:01.160
because I can't figure out this, like, how to initialize an array with integers in it.


00:15:01.160 --> 00:15:02.160
Yeah.


00:15:02.160 --> 00:15:05.160
It's great for just like really quick spot checks.


00:15:05.160 --> 00:15:08.160
And it also seems to know a lot about like really popular frameworks.


00:15:08.160 --> 00:15:12.160
So you can ask it things that are surprisingly detailed about like a


00:15:12.160 --> 00:15:16.160
how would you do cores with requests in FastAPI.


00:15:16.160 --> 00:15:19.160
And it can help you find that exact middleware.


00:15:19.160 --> 00:15:23.160
You know, it's like boilerplate-y, but it's great that it can just be a source for that.


00:15:24.160 --> 00:15:27.440
This portion of Talk Python to Me is brought to you by Brilliant.org.


00:15:27.440 --> 00:15:30.320
You are a curious person who loves to learn about technology.


00:15:30.320 --> 00:15:32.320
I know because you're listening to my show.


00:15:32.320 --> 00:15:37.120
That's why you would also be interested in this episode's sponsor, Brilliant.org.


00:15:37.120 --> 00:15:40.320
Brilliant.org is entertaining, engaging, and effective.


00:15:40.320 --> 00:15:45.360
If you're like me and feel that binging yet another sitcom series is kind of missing out on life,


00:15:45.360 --> 00:15:48.560
then how about spending 30 minutes a day getting better at programming


00:15:48.560 --> 00:15:53.200
or deepening your knowledge and foundations of topics you've always wanted to learn better,


00:15:53.200 --> 00:15:56.720
like chemistry or biology over on Brilliant.


00:15:56.720 --> 00:15:58.480
Brilliant has thousands of lessons,


00:15:58.480 --> 00:16:01.720
from foundational and advanced math to data science,


00:16:01.720 --> 00:16:03.560
algorithms, neural networks, and more,


00:16:03.560 --> 00:16:05.800
with new lessons added monthly.


00:16:05.800 --> 00:16:07.240
When you sign up for a free trial,


00:16:07.240 --> 00:16:08.440
they ask a couple of questions


00:16:08.440 --> 00:16:09.840
about what you're interested in,


00:16:09.840 --> 00:16:11.480
as well as your background knowledge.


00:16:11.480 --> 00:16:13.240
Then you're presented with a cool learning path


00:16:13.240 --> 00:16:15.600
to get you started right where you should be.


00:16:15.600 --> 00:16:18.360
Personally, I'm going back to some science foundations.


00:16:18.360 --> 00:16:19.680
I love chemistry and physics,


00:16:19.680 --> 00:16:22.160
but haven't touched them for 20 years.


00:16:22.160 --> 00:16:28.480
So I'm looking forward to playing with PV=NRT, you know, the ideal gas law, and all the other


00:16:28.480 --> 00:16:33.680
foundations of our world. With Brilliant, you'll get hands-on on a whole universe of concepts in


00:16:33.680 --> 00:16:38.720
math, science, computer science, and solve fun problems while growing your critical thinking


00:16:38.720 --> 00:16:43.040
skills. Of course, you could just visit brilliant.org directly. Its URL is right there in the


00:16:43.040 --> 00:16:48.560
name, isn't it? But please use our link because you'll get something extra, 20% off an annual


00:16:48.560 --> 00:16:54.000
premium subscription. So sign up today at talkbython.fm/brilliant and start a seven-day


00:16:54.000 --> 00:16:59.760
free trial. That's talkbython.fm/brilliant. The link is in your podcast player show notes.


00:16:59.760 --> 00:17:04.400
Thank you to brilliant.org for supporting the show.


00:17:04.400 --> 00:17:10.920
It's insane. I don't know if I've got it in my history here. We're rewriting our mobile


00:17:10.920 --> 00:17:16.940
apps for TalkByThon training for our courses and Flutter, and we're having a problem downloading


00:17:16.940 --> 00:17:21.620
stuff concurrently using a particular library in Flutter.


00:17:21.620 --> 00:17:26.740
And so I asked it, I said, "Hey, I want some help with a Flutter and Dart program.


00:17:26.740 --> 00:17:27.740
What do you want?"


00:17:27.740 --> 00:17:29.300
It says, "I'm using the DIO package.


00:17:29.300 --> 00:17:30.300
Do you know it?"


00:17:30.300 --> 00:17:31.300
"Oh, yes, I'm familiar.


00:17:31.300 --> 00:17:33.260
It does HTTP client stuff for Dart."


00:17:33.260 --> 00:17:37.580
"Okay, I want to download binary video files and a bunch of them given a URL.


00:17:37.580 --> 00:17:40.900
I want to do them concurrently with three of them at a time.


00:17:40.900 --> 00:17:41.900
Write the code for that."


00:17:41.900 --> 00:17:43.300
And boom, it just writes it.


00:17:43.300 --> 00:17:48.740
using that library I told you about, not just Dart. So that's incredible that we can get


00:17:48.740 --> 00:17:53.060
this kind of assistance for knowledge and programming. Like you'll never find, I mean,


00:17:53.060 --> 00:17:58.380
I take that back. You might find that if there's a very specific Stack Overflow question or


00:17:58.380 --> 00:18:01.460
something, but if there's not a write on question for it, you're not going to find it.


00:18:01.460 --> 00:18:05.380
- Yep, yep. I love the, when you have a, like, you know, the Stack Overflow would exist for


00:18:05.380 --> 00:18:09.740
a variant of your question, but it's like the exact one doesn't exist and you have to


00:18:09.740 --> 00:18:11.580
to go grab like the three of them to synthesize.


00:18:11.580 --> 00:18:13.340
And it's just great at that.


00:18:13.340 --> 00:18:16.260
It's also, yeah, it also is pretty good at fixing errors.


00:18:16.260 --> 00:18:17.700
I mean, sometimes it can walk itself


00:18:17.700 --> 00:18:20.260
into just like lying to you repeatedly, but that's,


00:18:20.260 --> 00:18:21.260
you know, it's like--


00:18:21.260 --> 00:18:24.060
- That's that accuracy part that's so problematic, yeah.


00:18:24.060 --> 00:18:26.640
But you can also ask it like, here's my program,


00:18:26.640 --> 00:18:28.160
are there security vulnerabilities?


00:18:28.160 --> 00:18:29.180
Or do you see any bugs?


00:18:29.180 --> 00:18:30.420
And it'll find them.


00:18:30.420 --> 00:18:32.780
- Yep, yeah, it's nuts.


00:18:32.780 --> 00:18:34.220
- So people may be wondering,


00:18:34.220 --> 00:18:36.340
we haven't talked yet about your project sketch,


00:18:36.340 --> 00:18:38.260
why I'm talking so much about ChatsCP.


00:18:38.260 --> 00:18:43.260
So that is kind of the style of AI that your project brings


00:18:43.260 --> 00:18:45.300
to pandas, which we're gonna get to.


00:18:45.300 --> 00:18:47.740
But I wanna touch on two more really quick AI things


00:18:47.740 --> 00:18:49.220
that we'll dive into it.


00:18:49.220 --> 00:18:51.780
The other is this just around images,


00:18:51.780 --> 00:18:53.780
just the ability to ask questions.


00:18:53.780 --> 00:18:57.060
You've already mentioned three, Dolly, Imagine,


00:18:57.060 --> 00:18:59.020
and then the other one I don't remember from Google


00:18:59.020 --> 00:19:00.860
that they haven't put out yet.


00:19:00.860 --> 00:19:03.340
A mid-journey is another, just the ability to say,


00:19:03.340 --> 00:19:05.100
"Hey, I want a picture of this."


00:19:05.100 --> 00:19:07.060
No, actually change it slightly like that.


00:19:07.060 --> 00:19:08.340
It's mind-blowing.


00:19:08.340 --> 00:19:09.180
- They're a lot of fun.


00:19:09.180 --> 00:19:10.860
They're great for sparking creativity


00:19:10.860 --> 00:19:12.720
or having an idea and just getting to see it in front of you.


00:19:12.720 --> 00:19:14.480
- I think it's more impressive to me


00:19:14.480 --> 00:19:17.740
than even this chat, GTP, telling me how to write Dart,


00:19:17.740 --> 00:19:20.460
is 'cause it's like, I gave you a blank canvas.


00:19:20.460 --> 00:19:22.340
And so, for example, for this video,


00:19:22.340 --> 00:19:24.140
for this conversation, I'll probably use this


00:19:24.140 --> 00:19:28.460
as the YouTube thumbnail and image for this episode.


00:19:28.460 --> 00:19:31.260
So I want an artificial intelligence panda.


00:19:31.260 --> 00:19:33.620
And it came up, and I want it photorealistic


00:19:33.620 --> 00:19:35.860
in the style of National Geographic.


00:19:35.860 --> 00:19:37.880
And so it gave me this panda.


00:19:37.880 --> 00:19:39.280
You can see beautiful whiskers,


00:19:39.280 --> 00:19:42.280
but just behind the ear, you can see the fur is gone


00:19:42.280 --> 00:19:46.080
and it's like an android type of creature.


00:19:46.080 --> 00:19:46.920
That's incredible.


00:19:46.920 --> 00:19:48.880
I mean, that is a beautiful picture.


00:19:48.880 --> 00:19:50.440
It's pretty accurate.


00:19:50.440 --> 00:19:53.120
It's nuts that I can just go talk to these systems


00:19:53.120 --> 00:19:54.320
and ask them these questions.


00:19:54.320 --> 00:19:56.000
- Yeah, I find it interesting you're comparing


00:19:56.000 --> 00:19:59.040
the ChatGPT and the Mid-Journey style


00:19:59.040 --> 00:20:01.000
and find the Mid-Journey ones impressive.


00:20:01.000 --> 00:20:02.840
They are, I completely get it.


00:20:02.840 --> 00:20:03.720
It's very visceral.


00:20:03.720 --> 00:20:05.820
It's also, from another perspective,


00:20:05.820 --> 00:20:08.220
I think of like the weights and the scale of the model.


00:20:08.220 --> 00:20:10.480
And the image, you know, these like image ones


00:20:10.480 --> 00:20:13.900
that like solve all images are so much smaller in scale


00:20:13.900 --> 00:20:15.060
than these like language ones


00:20:15.060 --> 00:20:16.660
that have all this other data and stuff.


00:20:16.660 --> 00:20:18.780
So it's fascinating how complex languages.


00:20:18.780 --> 00:20:20.780
- Yeah, I know the smarts is so much less,


00:20:20.780 --> 00:20:23.200
but just something about it actually came up


00:20:23.200 --> 00:20:27.020
with a creative picture that never existed.


00:20:27.020 --> 00:20:29.220
Right, you could show this to somebody like,


00:20:29.220 --> 00:20:32.020
oh, that's an artificial panda, that's insane, right?


00:20:32.020 --> 00:20:35.460
But it's, but I just gave it like a sentence or two.


00:20:35.460 --> 00:20:41.220
Yeah, yeah, yeah, this, it's a sort of a technical interpretation, but I love it


00:20:41.220 --> 00:20:45.860
because it's like this. It's just phenomenal interpolation. It's like through semantically


00:20:45.860 --> 00:20:50.100
labeled space. So like the words have meaning and it understands the meeting and can move


00:20:50.100 --> 00:20:53.500
sliders of like, well, I've seen lots of these machine things. I understand the concept of


00:20:53.500 --> 00:20:58.180
gears and this metal and this like the shiny texture and then the fur texture and like


00:20:58.180 --> 00:21:02.920
a specific they're very good at texture. It's yes, yeah, really great how it interprets


00:21:02.920 --> 00:21:05.020
all of that just to fit the small prompt.


00:21:05.020 --> 00:21:07.740
>> Yeah. There are other angles which is frustrating.


00:21:07.740 --> 00:21:09.860
I want it in the back of the picture,


00:21:09.860 --> 00:21:12.060
not the front. No, it's always in the center.


00:21:12.060 --> 00:21:13.360
One more thing really quick,


00:21:13.360 --> 00:21:17.300
and this leads me into my final thing is GitHub Copilot.


00:21:17.300 --> 00:21:19.740
GitHub Copilot is like this in your editor,


00:21:19.740 --> 00:21:21.280
which is insane.


00:21:21.280 --> 00:21:24.380
You can just give it a comment or a series of comments,


00:21:24.380 --> 00:21:25.460
and it will write it.


00:21:25.460 --> 00:21:29.380
I think chat GTPs may be more open-ended and more creative,


00:21:29.380 --> 00:21:32.640
but this is also a pretty interesting way to go.


00:21:32.640 --> 00:21:34.040
I'm a heavy user of Copilot.


00:21:34.040 --> 00:21:40.200
I, if there's a weird crux and I'm like slowly developing like a need to have this in my browser.


00:21:40.200 --> 00:21:44.840
I was on a flight recently and was with the internet and Copilot wasn't working.


00:21:44.840 --> 00:21:47.520
And I felt the like, I felt the difference.


00:21:47.520 --> 00:21:51.840
I felt like I was like walking through mud instead of just like actually running a little bit.


00:21:51.840 --> 00:21:52.360
And I was like, oh,


00:21:52.360 --> 00:21:55.800
I've been disconnected from my distributed mind.


00:21:55.800 --> 00:21:57.320
I am broken partially.


00:21:57.320 --> 00:21:58.720
Yeah.


00:21:58.720 --> 00:21:59.880
So incredible.


00:21:59.920 --> 00:22:03.880
So the last part I guess is like, what are the ethics of this?


00:22:03.880 --> 00:22:06.840
Like I went on very positively about Midjourney,


00:22:06.840 --> 00:22:10.080
but how much of that is trained on copyright material?


00:22:10.080 --> 00:22:11.680
Or there's GitHub Copilot.


00:22:11.680 --> 00:22:16.480
How much of that is trained on GPL-based stuff


00:22:16.480 --> 00:22:18.760
that was in GitHub?


00:22:18.760 --> 00:22:22.000
But when I use it, I don't have the GPL any longer on my code.


00:22:22.000 --> 00:22:23.800
I might use it on a commercial code.


00:22:23.800 --> 00:22:27.560
But just running it through the AI, does that strip licenses?


00:22:27.560 --> 00:22:28.720
Or does it not?


00:22:28.720 --> 00:22:32.560
There's a GitHub copilot litigation.com, which is interesting.


00:22:32.560 --> 00:22:38.000
I mean, we might be finding out there's also think Getty, he gets the Getty


00:22:38.000 --> 00:22:38.320
images.


00:22:38.320 --> 00:22:42.240
I'm not a hundred percent sure, but I think getting images is suing one of


00:22:42.240 --> 00:22:44.560
these image generation companies.


00:22:44.560 --> 00:22:46.000
I can't remember which one I don't.


00:22:46.000 --> 00:22:47.320
Maybe mid journey.


00:22:47.320 --> 00:22:48.120
I don't think it's mid-journey.


00:22:48.120 --> 00:22:50.160
I think it's stable diffusion, but anyway, it doesn't really matter.


00:22:50.160 --> 00:22:53.160
Like there's a bunch of things that are pushing back against us.


00:22:53.160 --> 00:22:55.920
Like, wait a minute, where did you get this data?


00:22:55.920 --> 00:22:57.840
Did you have rights to use this data in this way?


00:22:57.840 --> 00:23:02.160
And I mean, what are your thoughts on this, this angle of AI these days?


00:23:02.160 --> 00:23:06.080
Yeah, I know. It sounds like I don't worry too much about it in either


00:23:06.080 --> 00:23:11.400
direction. I like, I think I believe in like, I get like personal ethics. I


00:23:11.400 --> 00:23:14.800
believe in open source things, availability of things because it just


00:23:14.800 --> 00:23:18.720
sort of like accelerates collective progress. But that said, I also believe


00:23:18.720 --> 00:23:22.360
in like, slightly different like social structures to help support people.


00:23:22.360 --> 00:23:26.520
Like, like, I am a, I guess, a personal believer in things like UBI or


00:23:26.520 --> 00:23:29.640
something like that on that direction. So when you combine


00:23:29.640 --> 00:23:31.740
those, I feel like it, you know, things sort of work out kind of


00:23:31.740 --> 00:23:34.900
well, but when we like, but it is still a thing that like, be


00:23:34.900 --> 00:23:37.300
right exists, and that there is this sense of ownership. And


00:23:37.300 --> 00:23:40.920
this is my thing. And I wanted to put licenses on it. And I


00:23:40.920 --> 00:23:44.180
think that this sort of story started, presumably, that I


00:23:44.180 --> 00:23:46.720
wasn't really having this conversation. But like, when the


00:23:46.720 --> 00:23:49.060
internet came around, and search engines happened, and like,


00:23:49.060 --> 00:23:52.320
Google could just go and pull up your thing from your page and


00:23:52.320 --> 00:23:55.900
summarize it in a little blob on the page is was that fair? What


00:23:55.900 --> 00:23:59.580
if it starts, you know, your shop and it allows you to go buy that same product from other


00:23:59.580 --> 00:24:04.780
shops like it. I think the same things are showing up and in the same way that the web


00:24:04.780 --> 00:24:08.940
like in the internet sort of it's sort of it was a large thing, but then it's sort of


00:24:08.940 --> 00:24:12.500
I don't know if it got quieter, but it sort of became in the background. We sort of found


00:24:12.500 --> 00:24:16.660
new systems. It stopped being piracy and CDs and the music industry is going to struggle


00:24:16.660 --> 00:24:21.060
and hey things like Spotify exist and streaming services exist and like I don't know what


00:24:21.060 --> 00:24:23.300
- Better than ever, basically, yeah.


00:24:23.300 --> 00:24:25.100
- So I think it's just evolution,


00:24:25.100 --> 00:24:27.400
and some things will change and adopt,


00:24:27.400 --> 00:24:30.660
some things will fall apart, and new things will be born.


00:24:30.660 --> 00:24:33.060
It's just a great, it's a good time for lots of opportunity,


00:24:33.060 --> 00:24:34.900
I guess is the part that I'm excited about.


00:24:34.900 --> 00:24:35.940
- Yeah, yeah, yeah, for sure.


00:24:35.940 --> 00:24:37.980
I think that's definitely true.


00:24:37.980 --> 00:24:38.940
Probably, you're probably right,


00:24:38.940 --> 00:24:40.700
it probably will turn out to be,


00:24:40.700 --> 00:24:43.740
old man yells at cloud, cloud doesn't care,


00:24:43.740 --> 00:24:45.900
sort of story, you know, in the end,


00:24:45.900 --> 00:24:48.060
where it's like, on the other hand,


00:24:48.060 --> 00:24:50.560
if somebody came back and said,


00:24:50.560 --> 00:24:52.840
you know, a court came back and said,


00:24:52.840 --> 00:24:55.560
you know what, actually anything trained on GPL


00:24:55.560 --> 00:24:57.560
and then you use Copilot on it, that's GPL,


00:24:57.560 --> 00:25:02.300
like that would have instantly mega effects, right?


00:25:02.300 --> 00:25:06.000
- Yeah, yeah, and I guess there's also stuff like the,


00:25:06.000 --> 00:25:07.160
I didn't actually read the article,


00:25:07.160 --> 00:25:08.040
I only saw the headline,


00:25:08.040 --> 00:25:09.160
and yeah, that's the worst thing to do


00:25:09.160 --> 00:25:10.680
is to repeat a thing, which has a headline,


00:25:10.680 --> 00:25:13.680
but there was that Italy thing that I saw about,


00:25:13.680 --> 00:25:15.520
like, I don't know the extent.


00:25:15.520 --> 00:25:16.360
- Yeah, yeah.


00:25:16.360 --> 00:25:17.520
- Yeah, that was really clickbaity,


00:25:17.520 --> 00:25:19.960
but I didn't get a time to look at it yet.


00:25:19.960 --> 00:25:22.960
- You probably asked chat to repeat a summarize for you.


00:25:22.960 --> 00:25:24.660
- If as long as it can do a Bing, I guess,


00:25:24.660 --> 00:25:25.600
get that updated.


00:25:25.600 --> 00:25:27.240
- Yeah, yeah, yeah.


00:25:27.240 --> 00:25:31.240
There's a lot of things playing in that space, right?


00:25:31.240 --> 00:25:32.200
Some different places.


00:25:32.200 --> 00:25:34.640
Okay, so yeah, very cool.


00:25:34.640 --> 00:25:37.120
But as a regular user, I would say,


00:25:37.120 --> 00:25:38.880
regardless of kind of how you feel about this,


00:25:38.880 --> 00:25:40.660
at least this is my viewpoint right now.


00:25:40.660 --> 00:25:42.480
It's like, regardless of how I feel


00:25:42.480 --> 00:25:46.220
about which side is right in these kinds of disputes,


00:25:46.220 --> 00:25:47.740
This stuff is out of the bag.


00:25:47.740 --> 00:25:49.580
It's out there and available and it's a tool


00:25:49.580 --> 00:25:50.420
and it's like saying, you know,


00:25:50.420 --> 00:25:51.500
I don't wanna use spell check


00:25:51.500 --> 00:25:55.300
or I don't wanna use some kind of like code checking.


00:25:55.300 --> 00:25:57.420
I just wanna write like in straight notepad


00:25:57.420 --> 00:25:58.500
because it's pure, right?


00:25:58.500 --> 00:26:00.180
Like, sure you could do that,


00:26:00.180 --> 00:26:01.860
but there's these tools that will help us


00:26:01.860 --> 00:26:05.100
be more productive and it's better to embrace them


00:26:05.100 --> 00:26:08.940
and know them than to just like yell at them, I suppose.


00:26:08.940 --> 00:26:10.940
- Yeah, a lot of accelerant you can get.


00:26:10.940 --> 00:26:12.660
Really speed up whatever you wanna get done.


00:26:12.660 --> 00:26:13.820
- Yeah, absolutely.


00:26:13.820 --> 00:26:16.720
All right, so speaking of speeding up things,


00:26:16.720 --> 00:26:18.300
let's talk pandas.


00:26:18.300 --> 00:26:20.560
And not even my artificial pandas,


00:26:20.560 --> 00:26:22.960
but actual programming pandas.


00:26:22.960 --> 00:26:26.920
With this project that you all have from approximate,


00:26:26.920 --> 00:26:29.500
yeah, approximate labs called Sketch.


00:26:29.500 --> 00:26:31.260
So Sketch is pretty awesome.


00:26:31.260 --> 00:26:33.660
Sketch is actually why we're talking today


00:26:33.660 --> 00:26:36.420
because I first talked about this on Python Bytes


00:26:36.420 --> 00:26:39.860
and I saw this was sent over there by Jake Furman


00:26:39.860 --> 00:26:42.300
and to me and said, "You should check this thing out.


00:26:42.300 --> 00:26:43.380
"It's awesome."


00:26:43.380 --> 00:26:46.200
And yeah, it's pretty nuts.


00:26:46.200 --> 00:26:47.980
So tell us about Sketch.


00:26:47.980 --> 00:26:51.100
- Yeah, so even though I use a Copilot,


00:26:51.100 --> 00:26:53.600
as sort of described already, and it's become a crux,


00:26:53.600 --> 00:26:55.100
I found in Jupyter Notebooks,


00:26:55.100 --> 00:26:56.500
when I wanted to work with data,


00:26:56.500 --> 00:26:59.460
it just didn't, it doesn't actually apply.


00:26:59.460 --> 00:27:02.940
So on one side, it was sort of like missing the mark at times


00:27:02.940 --> 00:27:04.220
and so it was sort of like,


00:27:04.220 --> 00:27:06.460
how can I get this integrated into my flow,


00:27:06.460 --> 00:27:08.020
the way I actually work in a Jupyter Notebook?


00:27:08.020 --> 00:27:10.620
If maybe I'm working a Jupyter Notebook on a remote server


00:27:10.620 --> 00:27:12.140
and I don't wanna set up VS Code to do it,


00:27:12.140 --> 00:27:13.620
so I don't have Copilot at all.


00:27:13.620 --> 00:27:14.900
Like there's a bunch of different reasons


00:27:14.900 --> 00:27:16.180
that I was just like in Jupyter.


00:27:16.180 --> 00:27:17.940
It's a very different IDE experience.


00:27:17.940 --> 00:27:19.380
- It is, yeah, it's super different.


00:27:19.380 --> 00:27:21.740
But also you might want to ask questions about the data,


00:27:21.740 --> 00:27:24.420
not the structure of the code that analyzes the data, right?


00:27:24.420 --> 00:27:25.260
- Exactly, yeah.


00:27:25.260 --> 00:27:27.420
And so just a bunch of that type of stuff.


00:27:27.420 --> 00:27:28.900
And then also at the other side,


00:27:28.900 --> 00:27:31.860
I was trying to find something that I could throw together


00:27:31.860 --> 00:27:34.660
that I thought was a strong demonstration


00:27:34.660 --> 00:27:37.820
of the value Approximate Labs is trying to chase,


00:27:37.820 --> 00:27:39.740
but wouldn't take me too much time to make.


00:27:39.740 --> 00:27:41.460
So it was a, oh, I could probably just go


00:27:41.460 --> 00:27:42.740
throw this together pretty quickly.


00:27:42.740 --> 00:27:45.260
I bet this is gonna be actually useful and helpful.


00:27:45.260 --> 00:27:46.660
And so let's just do that.


00:27:46.660 --> 00:27:49.900
And so through on top of the actual library I was using


00:27:49.900 --> 00:27:52.620
that was Sketch, I put this on it and then shipped it.


00:27:52.620 --> 00:27:54.820
So sort of shifted what the project was.


00:27:54.820 --> 00:27:55.640
- Yeah, yeah.


00:27:55.640 --> 00:27:58.500
So you also have this other project called Lambda Prompt.


00:27:58.500 --> 00:28:00.780
And so were you trying to play around Lambda Prompt


00:28:00.780 --> 00:28:03.140
and then like see what you could kind of apply here


00:28:03.140 --> 00:28:05.500
to leverage it or is that--


00:28:05.500 --> 00:28:06.820
- The full journey I can get into


00:28:06.820 --> 00:28:09.020
is started with a data sketches.


00:28:09.020 --> 00:28:14.020
I've left my last job to chase bringing the algorithm,


00:28:14.020 --> 00:28:16.720
like combining data sketches with AI,


00:28:16.720 --> 00:28:19.240
but just like the vague, like at that level.


00:28:19.240 --> 00:28:20.960
- Tell us what a data sketch is real quick.


00:28:20.960 --> 00:28:21.800
- Sure, yeah.


00:28:21.800 --> 00:28:24.960
So a data sketch is a probabilistic aggregation of data.


00:28:24.960 --> 00:28:27.040
So if you have, I think the most common one


00:28:27.040 --> 00:28:29.160
that people have heard of is HyperLogLog,


00:28:29.160 --> 00:28:31.380
and it's used to estimate cardinality.


00:28:31.380 --> 00:28:33.720
So estimate the number of unique values in a column.


00:28:33.720 --> 00:28:36.800
A data sketch is a class of algorithms


00:28:36.800 --> 00:28:40.920
that all sort of like use roughly fixed width in binary,


00:28:40.920 --> 00:28:44.920
usually representations, and then in a single pass,


00:28:44.920 --> 00:28:49.000
so their O N will look at each row and hash the row


00:28:49.000 --> 00:28:50.980
and then update the sketch or not necessarily hash,


00:28:50.980 --> 00:28:52.840
but they update this sketch object.


00:28:52.840 --> 00:28:55.080
Essentially, those sketch objects also have another


00:28:55.080 --> 00:28:56.880
property that they are mergeable.


00:28:56.880 --> 00:29:00.420
So you have this like really fast O N to go bring that like


00:29:00.420 --> 00:29:02.880
to aggregate up and you get this mergeability.


00:29:02.880 --> 00:29:06.200
So you can map reduce it in trivial speeds.


00:29:06.200 --> 00:29:11.080
The net result is that this like tight binary packed object can be used to


00:29:11.080 --> 00:29:15.000
approximate measures you were looking for on the original data.


00:29:15.000 --> 00:29:19.840
So you could look at if you do a few of these, they're like theta sketches.


00:29:19.840 --> 00:29:23.540
You can go and estimate not just the unique count, but you can also estimate if


00:29:23.540 --> 00:29:27.240
this one column would join well with this other column, or you can estimate,


00:29:27.240 --> 00:29:31.000
Oh, if I were to join this column to this column, then this third column that was


00:29:31.000 --> 00:29:34.760
on that other table would actually be correlated to this first column over


00:29:34.760 --> 00:29:39.760
So you get these, a bunch of different distributions.


00:29:39.760 --> 00:29:43.280
You get a whole bunch of these types of properties.


00:29:43.280 --> 00:29:45.320
And each sketch is sort of just,


00:29:45.320 --> 00:29:47.360
I would say, algorithmically engineered,


00:29:47.360 --> 00:29:49.160
like very, very engineered to be


00:29:49.160 --> 00:29:51.680
information theory optimal at solving one of those


00:29:51.680 --> 00:29:54.440
measures on the data.


00:29:54.440 --> 00:29:56.040
And so they're tight packed binary representations.


00:29:56.040 --> 00:29:59.160
- All right, so you thought about, well, that's cool,


00:29:59.160 --> 00:30:00.960
but ChatsDB is cool too.


00:30:00.960 --> 00:30:03.640
- Yeah, exactly.


00:30:00.440 --> 00:30:06.440
The core thing was, so those representations aren't usable by AI right now. And when you


00:30:06.440 --> 00:30:12.080
actually go and use GPT-3 or something like this, you have to figure out a way to build


00:30:12.080 --> 00:30:16.320
the prompt to get it to do what you want. This was especially true in a pre-instruction


00:30:16.320 --> 00:30:20.680
tuning world, you had to really like, you had to play the prompt engineer role even


00:30:20.680 --> 00:30:24.600
more than you have to now. Now you could sort of get away with describing it to ChatGPT.


00:30:24.600 --> 00:30:28.520
And one of the things that you really have to like, play the game of is how do you get


00:30:28.520 --> 00:30:33.840
all the information it's going to need into this prompt in a succinct but good enough


00:30:33.840 --> 00:30:39.340
way that it helps it do this. And so what Sketch was about was rather than just looking


00:30:39.340 --> 00:30:45.120
at the context of the data, like the metadata, the column names and the code you have, also


00:30:45.120 --> 00:30:50.360
go get some representations of representation of the content of the data, turn that into


00:30:50.360 --> 00:30:54.720
a string, and then bring that string in as part of the prompt. And then when it has that


00:30:54.720 --> 00:30:58.600
it should understand much better at actually generating code,


00:30:58.600 --> 00:31:01.800
generating answers to questions, and that's what that sketch was,


00:31:01.800 --> 00:31:03.800
a proof of concept of that, that worked very well.


00:31:03.800 --> 00:31:08.640
It really quickly showed how valuable actual data content context is.


00:31:08.640 --> 00:31:11.040
Yeah, I would say people are-- it's resonating with people.


00:31:11.040 --> 00:31:13.520
It's got 1.5 thousand stars on GitHub.


00:31:13.520 --> 00:31:18.320
It looks about six months old, so that's pretty good growth there.


00:31:18.320 --> 00:31:21.600
Yeah, January 16th was the day I posted it on Hacker News,


00:31:21.600 --> 00:31:24.560
And it had three, it was an empty repo at that point.


00:31:24.560 --> 00:31:26.680
- Okay, three stars.


00:31:26.680 --> 00:31:28.320
It's like me and my friends.


00:31:28.320 --> 00:31:29.160
Okay, cool.


00:31:29.160 --> 00:31:34.160
So this is a tool that basically patches pandas


00:31:34.160 --> 00:31:38.100
to add functionality or functions,


00:31:38.100 --> 00:31:41.440
literally, to pandas data frames


00:31:41.440 --> 00:31:44.680
that allows you to ask questions about it, right?


00:31:44.680 --> 00:31:45.520
- Yep.


00:31:45.520 --> 00:31:46.720
- So what kind of questions can you ask it?


00:31:46.720 --> 00:31:47.800
What can it help you with?


00:31:47.800 --> 00:31:50.880
- Yeah, so there's two classes of questions you can ask.


00:31:50.880 --> 00:31:53.520
you can ask it the ask type questions.


00:31:53.520 --> 00:31:56.600
These are sort of from that summary statistics data.


00:31:56.600 --> 00:32:00.960
So from the general representation of your data,


00:32:00.960 --> 00:32:02.800
ask it to like give you answers about it.


00:32:02.800 --> 00:32:03.640
Like what are the columns here?


00:32:03.640 --> 00:32:04.960
You sort of have a conversation


00:32:04.960 --> 00:32:08.480
where it sort of understands the general,


00:32:08.480 --> 00:32:11.200
like shape of the data, general distributions,


00:32:11.200 --> 00:32:13.020
things like that, number of uniques,


00:32:13.020 --> 00:32:14.740
and like give that context to it,


00:32:14.740 --> 00:32:16.800
ask questions of that system.


00:32:16.800 --> 00:32:20.000
And then the other one is ask it how to do something.


00:32:20.000 --> 00:32:23.160
So you specifically can get it to write code to solve a problem you have.


00:32:23.160 --> 00:32:25.160
You describe the problem you want and you can ask it to do that.


00:32:25.160 --> 00:32:27.000
Right. I've got this data frame.


00:32:27.000 --> 00:32:31.560
I want to plot a graph of this versus that, but color by the other thing.


00:32:31.560 --> 00:32:37.040
Yep. And in the data space world, what I sort of decided to do is like in the demo here is


00:32:37.040 --> 00:32:41.760
just sort of walk through what are some standard things people want to ask of data?


00:32:41.760 --> 00:32:48.400
Like what are those common questions that you hear like in Slack between a business team and an analyst team?


00:32:48.400 --> 00:32:50.800
and it's just sort of like, oh, can you do this?


00:32:50.800 --> 00:32:51.800
Can you get me this?


00:32:51.800 --> 00:32:53.200
Can you tell me if there's any PII?


00:32:53.200 --> 00:32:54.160
Is this safe to send?


00:32:54.160 --> 00:32:55.440
Can I send the CSV around?


00:32:55.440 --> 00:32:57.200
Can you clean up this CSV?


00:32:57.200 --> 00:32:59.160
Oh, I need to load this into our catalog.


00:32:59.160 --> 00:33:00.560
Can you describe each of these columns


00:33:00.560 --> 00:33:02.600
and check the data types all the way to,


00:33:02.600 --> 00:33:05.400
can you actually go get me analytics or plot this?


00:33:05.400 --> 00:33:07.280
- Yeah, awesome.


00:33:07.280 --> 00:33:10.160
So, and it plugs right into Jupyter Notebooks.


00:33:10.160 --> 00:33:14.880
So you can just import it and basically installing Sketch,


00:33:14.880 --> 00:33:16.960
which is a pip or conda type thing,


00:33:16.960 --> 00:33:19.220
and then you just import it and it's good to go, right?


00:33:19.220 --> 00:33:22.100
- Yep, using the Pandas extensions API,


00:33:22.100 --> 00:33:25.300
which allows you to essentially hook into their data frame,


00:33:25.300 --> 00:33:28.060
call back and register a--


00:33:28.060 --> 00:33:31.980
- Interesting, so it's not as jammed on from the outside,


00:33:31.980 --> 00:33:34.180
it's a little more, plays a little nicer with Pandas


00:33:34.180 --> 00:33:36.780
rather than just like, we're gonna go to the class


00:33:36.780 --> 00:33:37.620
and just--


00:33:37.620 --> 00:33:38.440
(laughing)


00:33:38.440 --> 00:33:41.420
- Yeah, yeah, not full monkey patching here.


00:33:41.420 --> 00:33:43.820
It's like hack supported, I think.


00:33:43.820 --> 00:33:46.820
I don't see it used often, but it is somewhere in the docs.


00:33:46.820 --> 00:33:47.240
Excellent.


00:33:47.240 --> 00:33:47.940
But here it is.


00:33:47.940 --> 00:33:52.800
So what I wanted to do for this is there's a, an example that you can do.


00:33:52.800 --> 00:33:56.720
Like if you go to the repo, which obviously I'll link to, there's a video,


00:33:56.720 --> 00:34:00.680
which I mean, mad props to you because I review so many things, especially


00:34:00.680 --> 00:34:03.580
for the Python bites podcast, where it's a bunch of news items and new


00:34:03.580 --> 00:34:04.680
things, we're just going to check out.


00:34:04.680 --> 00:34:04.800
And.


00:34:04.800 --> 00:34:09.200
Yeah, we'll, we'll find people recommending GUI frameworks that


00:34:09.200 --> 00:34:10.940
haven't not a single screenshot.


00:34:10.940 --> 00:34:13.220
Other types of things.


00:34:13.220 --> 00:34:16.600
Like I have no way to judge whether this thing even might look like,


00:34:16.600 --> 00:34:18.040
He said, "What does it even make?


00:34:18.040 --> 00:34:19.920
"I don't even know, but somebody put a lot of effort,


00:34:19.920 --> 00:34:21.760
"but they didn't bother to post an image."


00:34:21.760 --> 00:34:24.920
And you posted a minute and a half animation


00:34:24.920 --> 00:34:26.840
of it going through this process,


00:34:26.840 --> 00:34:28.040
which is really, really excellent.


00:34:28.040 --> 00:34:31.160
So people can go and watch that one minute,


00:34:31.160 --> 00:34:32.640
one minute 30 video.


00:34:32.640 --> 00:34:36.320
But there's also a Colab, open in Google Colab,


00:34:36.320 --> 00:34:40.680
which gives you a running interactive variant here.


00:34:40.680 --> 00:34:42.640
So you can just follow along, right?


00:34:42.640 --> 00:34:44.800
And play these pieces.


00:34:44.800 --> 00:34:46.360
Oh, it requires me to sign up on and run it,


00:34:46.360 --> 00:34:47.200
That's okay.


00:34:47.200 --> 00:34:49.280
Let me just talk people through some of the things it does


00:34:49.280 --> 00:34:52.680
and you can tell me what it's doing, how it's doing that,


00:34:52.680 --> 00:34:55.240
like how people might find that advantageous.


00:34:55.240 --> 00:34:59.280
So import sketch, import pandas as PD standard.


00:34:59.280 --> 00:35:01.160
And then you can say pandas read CSV


00:35:01.160 --> 00:35:05.040
and you give it one from like some example CSV


00:35:05.040 --> 00:35:08.000
that you got on one of your GitHub repos, right?


00:35:08.000 --> 00:35:08.960
Or in your account.


00:35:08.960 --> 00:35:09.980
- Yeah, I found one online


00:35:09.980 --> 00:35:12.380
and then added just random synthetic data to it.


00:35:12.380 --> 00:35:13.880
- Yeah, like, oh, here's a data dump.


00:35:13.880 --> 00:35:14.720
No, just kidding.


00:35:14.720 --> 00:35:33.720
So then you need to go to that data frame called sales data. You say .sketch.ask as a string, what columns might have PII, personal identifying information in them? Awesome. And so it comes, tell me how that works and what it's doing here.


00:35:33.720 --> 00:35:39.560
So it does, I guess, it has to build up the prompt, which is sent to GPT. So to open


00:35:39.560 --> 00:35:43.940
AI specific completion endpoint, the building up the prompt, it looks at the data frame,


00:35:43.940 --> 00:35:48.960
it does a bunch of summarization stats on it. So it calculates uniques and sums and


00:35:48.960 --> 00:35:52.900
things like that. There's two modes in the back end that either does sketches to do those


00:35:52.900 --> 00:35:58.360
or just uses like df.describe type stuff. And then it pulls those summary stats together


00:35:58.360 --> 00:36:02.560
for all the columns, throws it together with my the rest of the prompt I have, you can


00:36:02.560 --> 00:36:07.960
we could go find it. But then it sends that prompt. It also grabs some information off


00:36:07.960 --> 00:36:13.840
of inspect. So it sort of like walks the stack up to go and check the variable name because


00:36:13.840 --> 00:36:18.160
the data frame is named sales data. So it actually tries to go find that variable name


00:36:18.160 --> 00:36:22.000
in your call stack so that it can when it writes code, it writes valid code, puts all


00:36:22.000 --> 00:36:26.960
that together, send it off to open AI, gets code back, uses Python AST to parse it, check


00:36:26.960 --> 00:36:31.000
that it's valid. If it's not valid Python code, or you tried to import something that


00:36:31.000 --> 00:36:36.720
don't have, it will ask it to rewrite once. So this is sort of like an iterative process.


00:36:36.720 --> 00:36:40.440
So it takes the error or it takes the thing and it sends it back to open as it's like,


00:36:40.440 --> 00:36:45.360
hey, fix this code. And then it or in this case, I ask it actually just takes this sends


00:36:45.360 --> 00:36:50.280
that exact same prompt, but it changes the last question to can you answer this question


00:36:50.280 --> 00:36:53.920
off of the information?


00:36:53.920 --> 00:36:57.760
This portion of talk Python me is brought to you by us over at Talk Python Training


00:36:57.760 --> 00:36:59.200
with our courses.


00:36:59.200 --> 00:37:01.000
I want to tell you about a brand new one


00:37:01.000 --> 00:37:03.240
that I'm super excited about.


00:37:03.240 --> 00:37:06.560
Python web apps that fly with CDNs.


00:37:06.560 --> 00:37:07.840
If you have a Python web app,


00:37:07.840 --> 00:37:10.080
you want it to go super fast.


00:37:10.080 --> 00:37:13.120
Static resources turn out to be a huge portion


00:37:13.120 --> 00:37:14.440
of that equation.


00:37:14.440 --> 00:37:17.080
Leveraging a CDN could save you up to 75%


00:37:17.080 --> 00:37:20.040
of your server load and make your app way faster


00:37:20.040 --> 00:37:21.040
for your users.


00:37:21.040 --> 00:37:23.680
And this course is a step-by-step guide


00:37:23.680 --> 00:37:25.020
on how to do it.


00:37:25.020 --> 00:37:27.640
And using a CDN to make your Python apps faster


00:37:27.640 --> 00:37:29.920
is way easier than you think.


00:37:29.920 --> 00:37:31.680
So if you've got a Python web app


00:37:31.680 --> 00:37:34.560
and you would like to have it scaled out globally,


00:37:34.560 --> 00:37:35.840
if you would like to have your users


00:37:35.840 --> 00:37:38.080
have a much better experience


00:37:38.080 --> 00:37:39.560
and maybe even save some money


00:37:39.560 --> 00:37:41.640
on server hosting and bandwidth,


00:37:41.640 --> 00:37:45.320
check out this course over at talkpython.fm/courses.


00:37:45.320 --> 00:37:47.000
It'll be right up there at the top.


00:37:47.000 --> 00:37:49.520
And of course, the link will be in your show notes.


00:37:49.520 --> 00:37:51.480
Thank you to everyone who's taken one of our courses.


00:37:51.480 --> 00:37:53.700
It really helps support the podcast.


00:37:53.700 --> 00:37:54.760
Now back to the show.


00:37:56.520 --> 00:38:01.520
- And so that sounds very, very similar to my Aero program.


00:38:01.520 --> 00:38:05.440
Rewrite it with guarding clauses, redo it.


00:38:05.440 --> 00:38:07.200
I gave you this data and this code


00:38:07.200 --> 00:38:10.200
and I asked you this question


00:38:10.200 --> 00:38:11.360
and you can have a little conversation


00:38:11.360 --> 00:38:13.160
but at some point you're like,


00:38:13.160 --> 00:38:13.160
"All right, well we're going to take what it gives me


00:38:13.160 --> 00:38:15.680
after a couple of rounds at it."


00:38:15.680 --> 00:38:17.440
- Yeah, I take the first one that doesn't,


00:38:17.440 --> 00:38:20.000
that passes an import check and passes AST linting.


00:38:20.000 --> 00:38:24.720
When you use small models, you run into not valid Python


00:38:22.560 --> 00:38:25.200
a lot more, but with these ones, it's almost always good.


00:38:25.200 --> 00:38:30.000
It's ridiculous. Yeah, it's crazy. Okay, so it says the columns that might have


00:38:30.000 --> 00:38:36.000
PII in them are a credit card, SSN and purchase address. Okay, that's pretty


00:38:36.000 --> 00:38:41.200
excellent. And then you say, all right, sales data dot sketch dot ask, can you


00:38:41.200 --> 00:38:46.440
give me friendly name for each column and output this as an HTML list, which


00:38:46.440 --> 00:38:51.320
is parsed as HTML and rendered in Jupyter Notebook accurately, right? So it


00:38:51.320 --> 00:38:52.680
- This is index, well that's an index.


00:38:52.680 --> 00:38:53.840
- This one ends up being the same.


00:38:53.840 --> 00:38:56.240
- It's not a great, this one is not a great example


00:38:56.240 --> 00:38:58.240
because it doesn't have to like infer


00:38:58.240 --> 00:39:02.560
'cause the names are like order space date, right?


00:39:02.560 --> 00:39:05.080
Instead of order, like maybe lowercase O


00:39:05.080 --> 00:39:07.520
and then like attach the big D or whatever.


00:39:07.520 --> 00:39:09.840
But it'll give you some more information.


00:39:09.840 --> 00:39:11.600
You can like kind of ask it questions


00:39:11.600 --> 00:39:13.520
about the type of data, right?


00:39:13.520 --> 00:39:14.360
- Yeah, exactly.


00:39:14.360 --> 00:39:15.840
I found this is really good at,


00:39:15.840 --> 00:39:18.120
if you play the game and you just name all your columns,


00:39:18.120 --> 00:39:20.320
like call one, call two, call three, call four,


00:39:20.320 --> 00:39:22.160
and you ask it, "Give me new column names for all of these."


00:39:22.160 --> 00:39:23.400
It gives you something that's pretty reasonable


00:39:23.400 --> 00:39:25.160
based off of the data, so pretty useful for that.


00:39:25.160 --> 00:39:26.640
- So it's like, "Oh, these look like addresses,


00:39:26.640 --> 00:39:27.480
"so we'll call that address,


00:39:27.480 --> 00:39:29.900
"and this looks like social security numbers


00:39:29.900 --> 00:39:32.080
"and credit scores and whatnot."


00:39:32.080 --> 00:39:32.920
- Yep, so it can really help


00:39:32.920 --> 00:39:35.360
with that quick first onboarding step.


00:39:35.360 --> 00:39:37.420
- Yeah, so everyone heard it here first.


00:39:37.420 --> 00:39:40.600
Just name all your columns, one, two, three, four,


00:39:40.600 --> 00:39:41.760
and then just get help.


00:39:41.760 --> 00:39:44.680
AI, what do we call these?


00:39:44.680 --> 00:39:50.240
All right, so the next thing you did in this demo notebook


00:39:50.240 --> 00:39:55.240
was you said salesdata.sketch.


00:39:55.240 --> 00:39:57.520
And this is different before, I believe,


00:39:57.520 --> 00:39:59.560
because before you were saying ask,


00:39:59.560 --> 00:40:01.880
and now you can say how to create some derived features


00:40:01.880 --> 00:40:05.800
from the address.


00:40:05.800 --> 00:40:08.120
Tell us about that.


00:40:08.120 --> 00:40:08.880
- Yeah, this is the one that actually is the code writing.


00:40:08.880 --> 00:40:11.240
It's essentially the exact same prompt,


00:40:11.240 --> 00:40:12.980
but the change is the very end.


00:40:12.980 --> 00:40:15.280
It says, return this as Python code


00:40:15.280 --> 00:40:17.640
that you can execute to do this.


00:40:17.640 --> 00:40:19.040
So instead of answering the question directly,


00:40:15.840 --> 00:40:18.080
answer the question with code that will answer the question.


00:40:18.080 --> 00:40:20.840
- Right, write a Python line of code


00:40:20.840 --> 00:40:22.640
that will answer this question given this data,


00:40:22.640 --> 00:40:23.480
something like that.


00:40:23.480 --> 00:40:24.720
- Yep, yep, something like that.


00:40:24.720 --> 00:40:26.640
I don't remember exactly anymore, it's been a while.


00:40:26.640 --> 00:40:30.120
But yeah, I iterated a little bit until it started working


00:40:30.120 --> 00:40:31.120
and I was like, okay, cool.


00:40:31.120 --> 00:40:34.500
And so, ask it for that and then it spits back code.


00:40:34.500 --> 00:40:38.480
And that was, it sounds overly simple, but that was it.


00:40:38.480 --> 00:40:40.040
That was the moment and I was just like,


00:40:40.040 --> 00:40:42.760
oh, I could just ask it to do my analytics for me.


00:40:42.760 --> 00:40:44.360
And it's just all the, every other feature


00:40:44.360 --> 00:40:47.360
and it just sort of became like apparently solvable with this.


00:40:47.360 --> 00:40:49.360
And the more I played with it, the more it was just,


00:40:49.360 --> 00:40:53.360
I don't have to think about, I don't even have to go to Google or Stack Overflow


00:40:53.360 --> 00:40:55.360
to ask the question to get the API stuff for me.


00:40:55.360 --> 00:40:59.360
I could, from zero to I have code that's working is one step in Jupyter.


00:40:59.360 --> 00:41:01.360
- So you wrote that how-to and you gave it the question,


00:41:01.360 --> 00:41:03.360
and then it wrote the lines of code,


00:41:03.360 --> 00:41:07.360
and you just drop that into the next cell and just run it, right?


00:41:07.360 --> 00:41:11.360
And so in this example, it said, well, we can come up with city, state, and zip code


00:41:11.360 --> 00:41:15.600
and by writing a vector transform,


00:41:15.600 --> 00:41:18.440
by passing a lambda that'll pull out the city


00:41:18.440 --> 00:41:21.480
from the string that was the full address and so on, right?


00:41:21.480 --> 00:41:22.400
- Yeah. - That's pretty neat.


00:41:22.400 --> 00:41:25.000
- Yeah, it's fun to see what it does.


00:41:25.000 --> 00:41:27.000
Again, not these things are always probabilistic,


00:41:27.000 --> 00:41:29.840
but it also usually serves as a great starting point,


00:41:29.840 --> 00:41:30.880
even if it doesn't get it right.


00:41:30.880 --> 00:41:32.400
- Yeah, sure, you're like, "Oh, okay, I see.


00:41:32.400 --> 00:41:33.980
"Maybe that's not exactly right,


00:41:33.980 --> 00:41:36.000
"'cause we have Europeans and their city,


00:41:36.000 --> 00:41:39.520
"maybe their zip code are in different orders sometimes."


00:41:39.520 --> 00:41:42.360
but it gives you something to work with pretty quickly,


00:41:42.360 --> 00:41:44.680
right, by asking just, what can I do?


00:41:44.680 --> 00:41:47.200
And then another one, this one's a little more interesting.


00:41:47.200 --> 00:41:48.880
Instead of just saying, like, well,


00:41:48.880 --> 00:41:50.280
what other things can we pull out?


00:41:50.280 --> 00:41:53.200
It's like, this gets towards the analytics side, right?


00:41:53.200 --> 00:41:56.300
It says, get the top five grossing states


00:41:56.300 --> 00:41:58.800
for the stales data, right?


00:41:58.800 --> 00:42:01.200
And it writes a group by, some sorts,


00:42:01.200 --> 00:42:03.720
and then it does a head given five,


00:42:03.720 --> 00:42:04.840
and that's pretty neat.


00:42:04.840 --> 00:42:05.680
Tell us about this.


00:42:05.680 --> 00:42:06.760
I mean, I guess it's about the same, right?


00:42:06.760 --> 00:42:08.600
Just asking more deep questions.


00:42:08.600 --> 00:42:14.440
They all feel pretty similar to me. I think I guess I could jump towards like things that


00:42:14.440 --> 00:42:19.220
I wanted to put next, but I didn't we're not reliable enough to like really make the cut.


00:42:19.220 --> 00:42:24.620
I wanted to have it go like that in my question was like go build a model that predicts sales


00:42:24.620 --> 00:42:29.940
for the next six months and then plot it on a 2d plot with a dotted line for the predicted


00:42:29.940 --> 00:42:35.540
plot and like it would try but it would always do something off and I found I always had


00:42:35.540 --> 00:42:37.540
to break up the prompted smaller--


00:42:37.540 --> 00:42:39.540
>> Get in turn level code back.


00:42:39.540 --> 00:42:41.540
>> Yeah, yeah.


00:42:41.540 --> 00:42:43.540
>> It sort of works.


00:42:43.540 --> 00:42:45.540
>> It was fun getting it to train models,


00:42:45.540 --> 00:42:47.540
but it was also its own


00:42:47.540 --> 00:42:49.540
separate thing I sort of didn't play with


00:42:49.540 --> 00:42:51.540
too much. And there's another


00:42:51.540 --> 00:42:53.540
part of Sketch that I guess is not


00:42:53.540 --> 00:42:55.540
in this notebook, I didn't realize.


00:42:55.540 --> 00:42:57.540
Because you have to use the OpenAI


00:42:57.540 --> 00:42:59.540
API key, but it's the Sketch


00:42:59.540 --> 00:43:01.540
Apply. And that's the--


00:43:01.540 --> 00:43:03.540
I would say this one is


00:43:03.540 --> 00:43:08.180
another just like power tool. This one has like, I don't really talk about I don't even include it


00:43:08.180 --> 00:43:12.900
in the video, because it's not just like as plug and play, you do have to go set an environment


00:43:12.900 --> 00:43:17.140
variable. And so it's like, man, it's one step further than I want to add, it's not terrible,


00:43:17.140 --> 00:43:24.420
but it's a step. And so what it does is, it lets you apply a completion endpoint of whatever your


00:43:24.420 --> 00:43:29.860
design row wise. So every single row, you can go and apply and run something. So if every row of


00:43:29.860 --> 00:43:36.220
of your pandas data frame is a some serialized text from a PDF or some or a file in your


00:43:36.220 --> 00:43:40.540
directory structure and you just load it as a data frame you can do dot df dot sketch


00:43:40.540 --> 00:43:44.860
dot apply and it's almost the exact same as df dot apply but the thing you put in as your


00:43:44.860 --> 00:43:49.940
function is now just a jinja template that will fill in your column variables for that


00:43:49.940 --> 00:43:55.940
row and then ask gpt to continue completing so i think i i did silly ones like here's


00:43:55.940 --> 00:44:00.940
a few states and then the prompt is extract the state for it or so I think.


00:44:00.940 --> 00:44:03.340
Right, extract the capital of the state?


00:44:03.340 --> 00:44:08.740
Yeah, yeah. So that's just pure information extraction from it, but you can sort of like


00:44:08.740 --> 00:44:10.420
this grows into a lot more.


00:44:10.420 --> 00:44:15.460
So does that come out of the data or is that coming out of open AI where like it sees where


00:44:15.460 --> 00:44:21.660
is the capital of state and it sees New York, it's like, okay, well, all right, Albany.


00:44:21.660 --> 00:44:25.180
This is purely extracting out of the model weights. Essentially, this is not like a factual


00:44:25.180 --> 00:44:29.420
extraction. So this is probably a bad example because it's like it but the thing that I


00:44:29.420 --> 00:44:33.780
actually actually the better example I did once was what is like some interesting colors


00:44:33.780 --> 00:44:37.780
that are good for each state and it like just came up with a sort of like flag ish colors


00:44:37.780 --> 00:44:41.460
or sports team colors. That was sort of fun when it wrote that I was hex. You can also


00:44:41.460 --> 00:44:45.960
do things like if you have a large text document or you can actually I'll even do the more


00:44:45.960 --> 00:44:50.060
common one that I think everybody actually wants is you have messy data. You have addresses


00:44:50.060 --> 00:44:54.260
that are like syntactically messy and you could say normalize these addresses to be


00:44:54.260 --> 00:44:57.020
be in this form and you sort of just write one example,


00:44:57.020 --> 00:44:59.580
I say run.apply and you get a new column


00:44:59.580 --> 00:45:00.940
that is that cleaned up data.


00:45:00.940 --> 00:45:02.860
- Yeah, incredible.


00:45:02.860 --> 00:45:04.600
Okay, couple things here.


00:45:04.600 --> 00:45:09.500
It says I can use, can directly call OpenAI


00:45:09.500 --> 00:45:10.740
and not use your endpoints.


00:45:10.740 --> 00:45:13.500
So at the moment, it kind of proxies through


00:45:13.500 --> 00:45:15.700
web service that you all have that somehow


00:45:15.700 --> 00:45:17.540
checks stuff or what does that do?


00:45:17.540 --> 00:45:19.420
- Yeah, it was just a pure ease of use.


00:45:19.420 --> 00:45:21.420
I wanted people to be able to do pip install


00:45:21.420 --> 00:45:23.540
and import sketch and actually get it


00:45:23.540 --> 00:45:27.740
because I know how much I use things in Colab


00:45:27.740 --> 00:45:29.840
or in Jupyter notebooks on weird machines


00:45:29.840 --> 00:45:31.540
and remembering an environment variable,


00:45:31.540 --> 00:45:33.680
managing secrets, it's like this whole overhead


00:45:33.680 --> 00:45:34.820
that I don't want to deal with.


00:45:34.820 --> 00:45:38.140
And so I wanted to just offer a lightweight way


00:45:38.140 --> 00:45:39.380
if you just want to be able to use it.


00:45:39.380 --> 00:45:42.100
But I know that that's not sufficient for security.


00:45:42.100 --> 00:45:43.740
People are going to be conscious of these things


00:45:43.740 --> 00:45:46.580
and want to be able to not go through my proxy thing


00:45:46.580 --> 00:45:47.420
that's there for help.


00:45:47.420 --> 00:45:48.420
So I offered this up.


00:45:48.420 --> 00:45:49.580
- What's next?


00:45:49.580 --> 00:45:51.220
Do you have a roadmap for this?


00:45:51.220 --> 00:45:52.420
Are you happy where it is


00:45:52.420 --> 00:45:55.700
and you're just letting it be, or do you have grand plans?


00:45:55.700 --> 00:45:57.500
- I don't have much of a roadmap for this right now.


00:45:57.500 --> 00:46:00.300
I'm actually, I guess there's like grand roadmap,


00:46:00.300 --> 00:46:02.700
which is like at the company scale, what we're working on.


00:46:02.700 --> 00:46:06.220
I would say that if this, we're really trying to solve data


00:46:06.220 --> 00:46:08.300
and with AI just in general.


00:46:08.300 --> 00:46:11.700
And so these are the types of things we hope to open source


00:46:11.700 --> 00:46:12.620
and just give out there.


00:46:12.620 --> 00:46:14.680
Like actually everything we're hoping to open source.


00:46:14.680 --> 00:46:16.980
But the starting place is gonna be a bunch of these


00:46:16.980 --> 00:46:19.300
like smaller toolkits or just utility things


00:46:19.300 --> 00:46:21.580
that hopefully save people time or very useful.


00:46:21.580 --> 00:46:24.120
the grand thing we're working towards, I guess,


00:46:24.120 --> 00:46:28.200
is this more, like the, it's the full automated data stack.


00:46:28.200 --> 00:46:30.200
It's like the dream, I think, that people have wanted,


00:46:30.200 --> 00:46:32.220
where you just ask it questions and it goes


00:46:32.220 --> 00:46:34.220
and pulls the data that you need.


00:46:34.220 --> 00:46:36.600
It cleans it, it builds up the full pipeline,


00:46:36.600 --> 00:46:38.940
it executes the pipeline, it gets you to the result,


00:46:38.940 --> 00:46:40.740
and it shows you the result, and you look,


00:46:40.740 --> 00:46:42.860
you can inspect all of that, that whole DAG,


00:46:42.860 --> 00:46:44.780
and say, yes, I trust this.


00:46:44.780 --> 00:46:46.980
So we're working on getting full end-to-end.


00:46:46.980 --> 00:46:49.700
- So when Owen asked about that Arrow program,


00:46:49.700 --> 00:46:51.460
I said, I think this will still do it.


00:46:51.460 --> 00:46:54.060
I think this will probably work again.


00:46:54.060 --> 00:46:56.660
And it did, which is awesome, just the way I expected.


00:46:56.660 --> 00:47:01.660
But AI is not as deterministic as read the number seven.


00:47:01.660 --> 00:47:05.740
If seven is less than eight, do this, right?


00:47:05.740 --> 00:47:07.940
Like, what is the repeatability?


00:47:07.940 --> 00:47:10.460
What is the sort of experience of doing this?


00:47:10.460 --> 00:47:13.020
Like, I ran it, oh, I ran it again.


00:47:13.020 --> 00:47:14.340
Is it gonna be pretty much the same


00:47:14.340 --> 00:47:15.620
or is it gonna have like,


00:47:15.620 --> 00:47:19.300
what's the mood of the AI when it gets to you?


00:47:19.300 --> 00:47:20.900
- This is sort of a parameter you can,


00:47:20.900 --> 00:47:24.400
There's a little bit of a parameter you can set if you want to play that game with the temperature parameter


00:47:24.400 --> 00:47:26.900
on these models at higher and higher temperatures.


00:47:26.900 --> 00:47:29.900
You get more and more random, but it can also truly be


00:47:29.900 --> 00:47:32.500
out of left field random if you go too high temperature.


00:47:32.500 --> 00:47:35.100
- Okay, but you get maybe more creative solutions.


00:47:35.100 --> 00:47:39.100
- Yeah, you can sometimes get that. And as you move towards zero, it gets more and more deterministic.


00:47:39.100 --> 00:47:43.100
Unfortunately, for really trying to do some good, provable


00:47:43.100 --> 00:47:46.700
build chain type things with hashing and caching and stuff,


00:47:46.700 --> 00:47:49.200
it's not fully deterministic even at zero temperature.


00:47:49.200 --> 00:47:54.760
But that's just, I think it's worth thinking about, but at the same time, run it once,


00:47:54.760 --> 00:47:59.100
see the answers that it gives you comment that business out and just like put that


00:47:59.100 --> 00:48:01.480
as Markdown, you know, freeze it.


00:48:01.480 --> 00:48:06.140
It like memorialize it in Markdown because you don't need to ask it over and


00:48:06.140 --> 00:48:10.420
over what columns have PII, like, well, probably the same ones as last time.


00:48:10.420 --> 00:48:12.320
We're just kind of like, right.


00:48:12.320 --> 00:48:15.080
These columns, credit cards, social security and purchase address.


00:48:15.080 --> 00:48:16.560
They have have that.


00:48:16.560 --> 00:48:18.240
And so now, you know, right.


00:48:18.280 --> 00:48:19.640
- Yeah, there's always-- - Is that a reasonable way


00:48:19.640 --> 00:48:20.480
to think about it?


00:48:20.480 --> 00:48:22.760
- I think, yeah, if you wanna get determinism


00:48:22.760 --> 00:48:24.480
or the performance is a thing that you're worried about,


00:48:24.480 --> 00:48:26.040
yeah, you can always cache.


00:48:26.040 --> 00:48:29.000
Think however you do it, comments or actually with systems.


00:48:29.000 --> 00:48:30.480
- Sure, sure, sure.


00:48:30.480 --> 00:48:35.480
Or that like, how do I do that group by sorting business?


00:48:35.480 --> 00:48:37.320
Like, you don't have to ask that over and over.


00:48:37.320 --> 00:48:39.400
Once it gives you the answer, you just--


00:48:39.400 --> 00:48:41.000
- Yeah, my workflow when I use Sketch,


00:48:41.000 --> 00:48:43.560
definitely I ask the question, I copy the code,


00:48:43.560 --> 00:48:44.600
and then I go delete the question


00:48:44.600 --> 00:48:45.720
or ask it a different question


00:48:45.720 --> 00:48:47.240
for my next problem that I have.


00:48:47.240 --> 00:48:49.880
- Yeah. - I like, it's not code that,


00:48:49.880 --> 00:48:52.360
it is a little bit like vestigial


00:48:52.360 --> 00:48:54.160
when you like save your notebook at the end


00:48:54.160 --> 00:48:55.040
and you sort of want to go back


00:48:55.040 --> 00:48:56.960
and delete all the questions you asked


00:48:56.960 --> 00:48:58.640
because you don't need to rerun it


00:48:58.640 --> 00:49:01.280
when you actually just go to execute the notebook later.


00:49:01.280 --> 00:49:02.420
- Yeah, that makes a lot of sense.


00:49:02.420 --> 00:49:04.420
And plus you look smarter if you don't have to


00:49:04.420 --> 00:49:06.440
show how you got the answers.


00:49:06.440 --> 00:49:08.460
- Look at this beautiful code that's even commented.


00:49:08.460 --> 00:49:09.960
- Yeah, exactly.


00:49:09.960 --> 00:49:12.240
I guess you could probably ask it to comment your code,


00:49:12.240 --> 00:49:13.560
right, if you wanted to. - Yeah, you can ask it


00:49:13.560 --> 00:49:15.760
to describe, there's been some really cool things


00:49:15.760 --> 00:49:18.280
where people will throw like assembly at it


00:49:18.280 --> 00:49:20.360
and ask it to translate to different languages


00:49:20.360 --> 00:49:21.200
so they can interpret it.


00:49:21.200 --> 00:49:24.320
Or you could do really fun things like cross language,


00:49:24.320 --> 00:49:27.000
cross, I guess I'll say like levels of abstraction.


00:49:27.000 --> 00:49:28.600
You could sort of ask it to describe it


00:49:28.600 --> 00:49:29.580
like at a very top level,


00:49:29.580 --> 00:49:31.680
or you can get really precise like for this line,


00:49:31.680 --> 00:49:32.740
what are all the implications


00:49:32.740 --> 00:49:34.240
if I change a variable or something like that.


00:49:34.240 --> 00:49:35.400
- Yeah, that's really cool.


00:49:35.400 --> 00:49:36.720
I suppose you could do that here.


00:49:36.720 --> 00:49:38.960
Can you converse with it?


00:49:38.960 --> 00:49:41.120
You can say, okay, you gave me this.


00:49:41.120 --> 00:49:41.960
I guess what's the word?


00:49:41.960 --> 00:49:44.760
Does it have like tokens and context like chat.ggp does?


00:49:44.760 --> 00:49:48.920
Can you say, okay, that's cool, but I want it as integers,


00:49:48.920 --> 00:49:51.480
not as strings, or I don't know.


00:49:51.480 --> 00:49:53.020
- I did not include that in this.


00:49:53.020 --> 00:49:55.520
There was a version that had something like that,


00:49:55.520 --> 00:49:57.700
where I was sort of just keeping the last few calls around,


00:49:57.700 --> 00:50:00.120
but it quickly became, it didn't align


00:50:00.120 --> 00:50:01.720
with the Jupyter IDE experience,


00:50:01.720 --> 00:50:03.380
'cause you end up like scrolling up and down,


00:50:03.380 --> 00:50:06.680
and you have too much power over how you execute


00:50:06.680 --> 00:50:08.360
in a Jupyter notebook, so your context


00:50:08.360 --> 00:50:10.680
can change dramatically by just scrolling up


00:50:10.680 --> 00:50:13.720
and trying to, via inspect, look across


00:50:13.720 --> 00:50:15.760
different like across a Jupyter Notebook


00:50:15.760 --> 00:50:17.200
as I was just a whole other nightmare.


00:50:17.200 --> 00:50:19.960
So I didn't try and like extract the code out of the notebook


00:50:19.960 --> 00:50:21.680
so that it could understand the local context.


00:50:21.680 --> 00:50:24.000
- You could go straight to ChatsCP or something like that,


00:50:24.000 --> 00:50:26.480
take what it gave you and start asking it questions.


00:50:26.480 --> 00:50:30.320
Okay, so another question that I had here about this.


00:50:30.320 --> 00:50:33.080
So in order for it to do its magic,


00:50:33.080 --> 00:50:35.440
like you said the really important thought


00:50:35.440 --> 00:50:37.020
or breakthrough idea you had was like,


00:50:37.020 --> 00:50:39.220
not just the structure of the pandas code


00:50:39.220 --> 00:50:40.240
or anything like that,


00:50:40.240 --> 00:50:42.020
but also a little bit about the data.


00:50:42.020 --> 00:50:47.020
what is the privacy implications of me asking this question about my data?


00:50:47.020 --> 00:50:53.540
Suppose I have super duper secret CSV and should I not ask or how to on it?


00:50:53.540 --> 00:50:56.020
Or what is the story there?


00:50:56.020 --> 00:51:04.100
What's the, if I work with data, how much sharing do I do of something I might not want to share if I ask a question about it?


00:51:04.100 --> 00:51:33.980
I'd say the same discretion you'd use if you would copy like a row, a few rows of that data into a co into ChatGPT to ask it a question about it. Okay, is the level of concern, I guess you should have, like on the specifically, I am not storing these things. But I know is at least it was, it seems like they're going to start getting towards like a 30 day thing. But so there's a little bit of Yeah, I mean, you're sending your stuff over the wire, like over network, if you do this, and to use these language models until they come local until these things like


00:51:33.980 --> 00:51:37.020
llama and alpaca get good enough that they're,


00:51:37.020 --> 00:51:38.060
yeah, they're gonna be remote.


00:51:38.060 --> 00:51:39.500
Actually, that could be a fun, sorry.


00:51:39.500 --> 00:51:40.980
I just now thought, that could be a fun thing.


00:51:40.980 --> 00:51:43.940
Like, just go get alpaca working with Sketch


00:51:43.940 --> 00:51:45.220
so that it can be fully local.


00:51:45.220 --> 00:51:48.260
- Oh, interesting, like a privacy preserving type of deal.


00:51:48.260 --> 00:51:50.500
- Yeah, I hadn't actually, yeah, that's the power


00:51:50.500 --> 00:51:53.140
of these smaller models that are almost good enough.


00:51:53.140 --> 00:51:55.300
I could probably just like quickly throw that in here


00:51:55.300 --> 00:51:58.260
and see if it, you know, maybe has a wider audience.


00:51:58.260 --> 00:52:01.500
- You have an option to not get through your API


00:52:01.500 --> 00:52:03.460
but directly go to OpenAI.


00:52:03.460 --> 00:52:06.980
you could have another one to pick other options, right?


00:52:06.980 --> 00:52:07.820
Potentially.


00:52:07.820 --> 00:52:08.640
- Yep, yep, yep.


00:52:08.640 --> 00:52:11.380
The interface to these,


00:52:11.380 --> 00:52:13.380
one thing that I think is not,


00:52:13.380 --> 00:52:15.220
maybe it's talked about it more in other places,


00:52:15.220 --> 00:52:17.380
but I haven't heard as much excitement about it,


00:52:17.380 --> 00:52:20.040
is that the APIs have gotten pretty nice


00:52:20.040 --> 00:52:21.100
for this whole space.


00:52:21.100 --> 00:52:24.560
They're all, the idea of a completion endpoint


00:52:24.560 --> 00:52:25.900
is pretty straightforward.


00:52:25.900 --> 00:52:27.480
You send it some amount of text,


00:52:27.480 --> 00:52:28.820
and it will continue that text.


00:52:28.820 --> 00:52:31.020
And it's such a, it's so simple,


00:52:31.020 --> 00:52:32.340
but it's so generalizable.


00:52:32.340 --> 00:52:35.620
You could build so many tools off of just that one API endpoint, essentially.


00:52:35.620 --> 00:52:37.940
And so combine that with an embedding endpoint,


00:52:37.940 --> 00:52:41.940
and you sort of have all you need to make complex AI apps.


00:52:41.940 --> 00:52:42.620
- It's crazy.


00:52:42.620 --> 00:52:49.100
Speaking of making AI apps, maybe touch a bit on your other project, LambdaProp.


00:52:49.100 --> 00:52:50.420
- Yeah, LambdaProp.


00:52:50.420 --> 00:52:51.300
Yeah, LambdaProp.


00:52:51.300 --> 00:52:55.020
- But wait, before you get into it, mad props for like Greek letter.


00:52:55.020 --> 00:52:57.420
Like that's a true physicist or mathematician.


00:52:57.420 --> 00:52:59.180
I can appreciate that there.


00:52:59.180 --> 00:52:59.780
- Yeah, yeah.


00:52:59.780 --> 00:53:03.340
I was excited to put it everywhere, but then of course, these things don't.


00:53:03.340 --> 00:53:07.420
Playing games with character sets and websites.


00:53:07.420 --> 00:53:10.460
I'm the one that causes... I both feel the pain,


00:53:10.460 --> 00:53:13.220
have to clean the data that I also put into these systems.


00:53:13.220 --> 00:53:17.180
Yeah, yeah. People are like, "A prompt? Why is the A so italicized?"


00:53:17.180 --> 00:53:18.660
- I don't get it. - Yeah, yeah.


00:53:18.660 --> 00:53:21.740
- Okay. Tell us about this. - Yeah, so this one came...


00:53:21.740 --> 00:53:25.260
I was working with... This is pre-GPT.


00:53:25.260 --> 00:53:28.420
This was October. I guess it was right around ChatGPT coming out,


00:53:28.420 --> 00:53:31.560
like around that time, but I was really just messing around a lot with completion


00:53:31.560 --> 00:53:35.920
endpoints as we're talking, and I kept rewriting the same request boiler over


00:53:35.920 --> 00:53:39.960
and over. And then I also kept rewriting f-strings that I was trying to like


00:53:39.960 --> 00:53:44.280
send in and I was just like, Jinja template solve this already. Like there


00:53:44.280 --> 00:53:48.520
already is formatting for strings in python. Let me just use that, compose


00:53:48.520 --> 00:53:51.680
that into a function and just let me call these completion endpoints. I


00:53:51.680 --> 00:53:55.900
don't want to think of them as like a P. I. M. Point or R. P. C. Is a nice


00:53:55.900 --> 00:53:59.320
mental model, but I want to use them as functions. I want to be able to put


00:53:59.320 --> 00:54:03.940
decorators on them. I want to be able to use them both a sink or not a sink in


00:54:03.940 --> 00:54:08.380
python. I want to, I just want to have this as a thing that I can just call


00:54:08.380 --> 00:54:12.340
really quickly with one line and just do whatever I need to with it. And so


00:54:12.340 --> 00:54:16.360
through this together, it's very simple, like honest, I mean like the hardest


00:54:16.360 --> 00:54:20.980
part was just getting all the layers of there's actually two things you can


00:54:20.980 --> 00:54:25.660
make a prompt that then because I wrap any function as a prompt, so not just


00:54:25.660 --> 00:54:29.660
these calls to GPT and then I do tracing on it. So as you like


00:54:29.660 --> 00:54:32.940
get into the call stack, every input and output is you can


00:54:32.940 --> 00:54:36.380
sort of like get hooked into and trace with some like call


00:54:36.380 --> 00:54:39.500
traces. So there's a bunch of just like weird stuff to make


00:54:39.500 --> 00:54:41.820
the utility nice, but functionally as you can see


00:54:41.820 --> 00:54:45.020
here on it's you just import it. You write a Jinja template


00:54:45.020 --> 00:54:48.620
with the class and then you use that object that comes back as


00:54:48.620 --> 00:54:51.740
a function and your Jinja template variables get filled


00:54:51.740 --> 00:54:55.420
in and your result is the text string that comes back out of


00:54:55.420 --> 00:54:57.540
- Interesting, and people probably,


00:54:57.540 --> 00:54:58.860
some people might be thinking like,


00:54:58.860 --> 00:55:01.180
Jinja, okay, well I gotta create an HTML file


00:55:01.180 --> 00:55:02.740
and all that, like, not just a string


00:55:02.740 --> 00:55:04.740
that has double curlies for turning stuff


00:55:04.740 --> 00:55:06.780
into like strings within the string.


00:55:06.780 --> 00:55:09.020
Kind of a different way to do f strings


00:55:09.020 --> 00:55:10.180
as you were hinting at.


00:55:10.180 --> 00:55:11.020
- Yeah, yeah.


00:55:11.020 --> 00:55:12.740
There was two pieces here.


00:55:12.740 --> 00:55:14.580
I realized as I was doing this also,


00:55:14.580 --> 00:55:16.820
I think I sort of mentioned with Sketch,


00:55:16.820 --> 00:55:19.160
I really often was taking the output


00:55:19.160 --> 00:55:22.500
of a language model prompt, doing something in Python,


00:55:22.500 --> 00:55:24.300
or actually I can do a full example


00:55:24.300 --> 00:55:27.000
of the SQL writing like exploration we did.


00:55:27.000 --> 00:55:31.200
But we would do these things that were sort of


00:55:31.200 --> 00:55:34.920
run GPT-3 to ask it to write the SQL.


00:55:34.920 --> 00:55:37.360
You take the SQL, you go try and execute it,


00:55:37.360 --> 00:55:39.120
but it fails for whatever reason.


00:55:39.120 --> 00:55:42.280
Or you, and you take that error, you say, "Hey, rewrite it."


00:55:42.280 --> 00:55:43.640
So we talked about that sort of pattern,


00:55:43.640 --> 00:55:44.840
which is sort of like rewriting.


00:55:44.840 --> 00:55:47.440
Another one of the patterns was increase the temperature,


00:55:47.440 --> 00:55:48.700
ask it to write the SQL,


00:55:48.700 --> 00:55:50.880
you get like 10 different SQL answers.


00:55:50.880 --> 00:55:53.040
In parallel, and this is where the async


00:55:53.040 --> 00:55:55.240
was really important for this, because I just wanted to use


00:55:55.240 --> 00:55:58.400
async.io.gather and run all 10 of these truly in parallel


00:55:58.400 --> 00:56:02.240
against the OpenAI endpoint, get 10 different answers to the SQL,


00:56:02.240 --> 00:56:04.640
run all 10 queries against your database,


00:56:04.640 --> 00:56:09.040
then pool on what the most common, like of the ones that successfully ran,


00:56:09.040 --> 00:56:11.520
which ones gave the same answer the most often.


00:56:11.520 --> 00:56:13.520
And that's probably the correct answer.


00:56:13.520 --> 00:56:17.120
And just chaining that stuff, it's like very


00:56:17.120 --> 00:56:19.680
Pythonic functions, like you can really just imagine,


00:56:19.680 --> 00:56:22.440
oh, I just need to write a for loop, I just need to run this function,


00:56:22.440 --> 00:56:27.880
take the output feed into another function. Very procedural. But when you all the abstractions


00:56:27.880 --> 00:56:34.040
in the open at open AI API, the things like just everything else, there was nothing else


00:56:34.040 --> 00:56:36.920
really at the time. But even the new ones that have come out like Lang chain that have


00:56:36.920 --> 00:56:42.400
sort of like taken the space by storm now, are not really just trying to offer the minimal


00:56:42.400 --> 00:56:46.120
ingredient which is the function. And to me, it was just like if I can just offer the function,


00:56:46.120 --> 00:56:49.640
I can write a for loop I can write, I can store a variable and then keep passing it


00:56:49.640 --> 00:56:54.480
into it, you could do so many different emergent behaviors with just starting with the function


00:56:54.480 --> 00:56:57.120
and then simple Python scripting on top of it.


00:56:57.120 --> 00:57:05.240
And some interesting stuff here, Lando Prompt. So you can start, you can kind of start it,


00:57:05.240 --> 00:57:09.080
set it, I don't know, with ChatsGDP you can tell it a few things. I'm going to ask you


00:57:09.080 --> 00:57:14.200
a question about a book. Okay. The book is a choose your own adventure book. Okay. Now


00:57:14.200 --> 00:57:17.960
here I'm going to, like you kind of prepare it, right? There's probably a more formal


00:57:17.960 --> 00:57:23.120
term for that, but you can do this here. Like you can say, Hey, system, you are a type of


00:57:23.120 --> 00:57:27.000
bot and then you, that creates you an object that you can have a conversation with. And


00:57:27.000 --> 00:57:30.740
you say, what should we get for lunch? And your type of bot is pirate. And so to say,


00:57:30.740 --> 00:57:34.720
as a pirate, I would suggest we have some hearty seafood or whatever. Right? Like that's,


00:57:34.720 --> 00:57:37.880
that's beyond what you're doing with sketch. I mean, obviously this is not so much for


00:57:37.880 --> 00:57:42.520
code. This is like conversing with Python rather than in Python. I don't know. And your


00:57:42.520 --> 00:57:43.520
editor.


00:57:43.520 --> 00:57:48.960
This one was the open AI chat API endpoint came out and I was just like, Oh, I should


00:57:48.960 --> 00:57:53.200
support it. So that's what this I wanted to be able to Jinja template inside of the conversation.


00:57:53.200 --> 00:57:58.160
So you can imagine a conversation that is prepared with like seven steps back and forth.


00:57:58.160 --> 00:58:01.360
But you want to hard code with the conversation, like how the flow of the conversation was


00:58:01.360 --> 00:58:06.120
going. And you want to template it so that like on message three, it put your new context


00:58:06.120 --> 00:58:10.840
problem on message four, it put the output from another prompt that you ran on message


00:58:10.840 --> 00:58:12.940
it is this other data thing.


00:58:12.940 --> 00:58:14.880
And then you ask it to complete this,


00:58:14.880 --> 00:58:17.680
the intent of like, it's arbitrarily complex,


00:58:17.680 --> 00:58:19.680
but still something like that would be,


00:58:19.680 --> 00:58:21.720
you know, just three lines or so in Lambda prompt.


00:58:21.720 --> 00:58:23.280
The idea was that it would offer up


00:58:23.280 --> 00:58:25.040
a really simple API for this.


00:58:25.040 --> 00:58:26.400
- Well, the other thing that's interesting


00:58:26.400 --> 00:58:28.420
is you have an async and async version.


00:58:28.420 --> 00:58:29.400
So that's cool.


00:58:29.400 --> 00:58:31.420
People can check that out.


00:58:31.420 --> 00:58:35.160
Also a way to make it a hosted as a web service


00:58:35.160 --> 00:58:37.840
with say like FastAPI or something like that.


00:58:37.840 --> 00:58:38.680
- Yeah.


00:58:38.680 --> 00:58:41.800
- You can make it a decorator if you like.


00:58:41.800 --> 00:58:43.360
An app prompt decorator.


00:58:43.360 --> 00:58:45.480
- Yeah, on any function you can just throw app prompt


00:58:45.480 --> 00:58:47.600
and it wraps it with the same class


00:58:47.600 --> 00:58:50.560
so that all the magic you get from that works.


00:58:50.560 --> 00:58:53.120
The server bit is I took,


00:58:53.120 --> 00:58:56.120
so FastAPI has that sort of like inspection


00:58:56.120 --> 00:58:58.280
on the function part.


00:58:58.280 --> 00:59:00.280
I did a little bit of middleware


00:59:00.280 --> 00:59:01.960
to get the two happy together.


00:59:01.960 --> 00:59:05.000
And then all you have to do is import FastAPI


00:59:05.000 --> 00:59:07.560
and then run, you know, gunicorn that app.


00:59:07.560 --> 00:59:11.820
And it's two lines, and any prompts you have made


00:59:11.820 --> 00:59:14.900
become their own independent REST endpoint,


00:59:14.900 --> 00:59:17.580
where you can just do a GET or a POST to it,


00:59:17.580 --> 00:59:20.420
and it returns the response from calling the prompt.


00:59:20.420 --> 00:59:22.580
But these prompts can also be these chains of prompts.


00:59:22.580 --> 00:59:24.300
Like one prompt can call another prompt,


00:59:24.300 --> 00:59:25.540
which can call another prompt,


00:59:25.540 --> 00:59:27.860
and those prompts can call async to not async,


00:59:27.860 --> 00:59:29.220
back to async, and things like that,


00:59:29.220 --> 00:59:30.860
and it should work.


00:59:30.860 --> 00:59:32.620
Pretty sure.


00:59:32.620 --> 00:59:33.740
This one actually, I did test everything,


00:59:33.740 --> 00:59:34.560
as far as I know.


00:59:34.560 --> 00:59:35.940
I'm pretty sure I've got pretty good coverage.


00:59:35.940 --> 00:59:37.720
- Yeah, super cool.


00:59:37.720 --> 00:59:39.580
All right, well, getting a little short on time,


00:59:39.580 --> 00:59:42.660
but I think people are gonna really dig this,


00:59:42.660 --> 00:59:43.500
especially Sketch.


00:59:43.500 --> 00:59:46.140
I think there's a lot of folks out there doing pandas


00:59:46.140 --> 00:59:51.140
that would love an AI buddy to help them do things,


00:59:51.140 --> 00:59:55.340
like not just analyze the code, but the data as well.


00:59:55.340 --> 00:59:58.300
- Yeah, just, I think anybody's, I know it's for me,


00:59:58.300 --> 01:00:01.340
but it's just like Copilot in VS Code IDE,


01:00:01.340 --> 01:00:04.260
Sketch in your Jupyter IDE, it takes almost nothing to add,


01:00:04.260 --> 01:00:06.620
and whenever you're just sort of sitting there,


01:00:06.620 --> 01:00:08.460
you think you're about to alt tab to go to Google,


01:00:08.460 --> 01:00:10.060
you can just try the sketch.ask,


01:00:10.060 --> 01:00:12.460
and it's surprising how often that sketch.ask


01:00:12.460 --> 01:00:15.420
or sketch.howto gets you way closer to a solution


01:00:15.420 --> 01:00:16.700
without even having to leave,


01:00:16.700 --> 01:00:18.900
that you don't even have to leave your environment.


01:00:18.900 --> 01:00:20.980
- It's like a whole other level of autocomplete,


01:00:20.980 --> 01:00:23.020
for sure, and super cool.


01:00:23.020 --> 01:00:25.380
All right, now before I let you out of here,


01:00:25.380 --> 01:00:26.980
you gotta answer the final two questions.


01:00:26.980 --> 01:00:29.540
If you're gonna write some Python code,


01:00:29.540 --> 01:00:31.180
and it's not a Jupyter notebook,


01:00:31.180 --> 01:00:32.220
what editor are you using?


01:00:32.220 --> 01:00:33.820
It sounds to me like you may have just given


01:00:33.820 --> 01:00:35.820
a strong hint at what that might be.


01:00:35.820 --> 01:00:38.820
Yeah, I've switched almost entirely to VS Code


01:00:38.820 --> 01:00:41.820
and I've been really liking it with the remote development


01:00:41.820 --> 01:00:46.820
and I work across many machines, both cloud and local


01:00:46.820 --> 01:00:49.820
and some five, six different machines are my primary working machines


01:00:49.820 --> 01:00:52.820
and I use the remote VS Code thing


01:00:52.820 --> 01:00:55.820
and I have a unified environment that gives me terminal,


01:00:55.820 --> 01:00:59.820
the files and the code all in one, and copilot on all of them.


01:00:59.820 --> 01:01:01.220
- It's wild.


01:01:01.220 --> 01:01:03.740
All right, and then notable PyPI package,


01:01:03.740 --> 01:01:05.140
I mean, pip install sketch,


01:01:05.140 --> 01:01:06.580
you can throw that out there if you like.


01:01:06.580 --> 01:01:07.500
It's pretty awesome.


01:01:07.500 --> 01:01:08.660
But anything you've run across,


01:01:08.660 --> 01:01:11.180
you're like, oh, this is, people should know about this.


01:01:11.180 --> 01:01:12.300
- Yeah, let's see. - Doesn't have to be popular,


01:01:12.300 --> 01:01:13.420
just like, wow, this is cool.


01:01:13.420 --> 01:01:16.060
- In the, I guess these two are very popular,


01:01:16.060 --> 01:01:19.260
but in the data space, I really,


01:01:19.260 --> 01:01:22.980
I'm a huge fan of Ray and also Arrow.


01:01:22.980 --> 01:01:26.540
Like, I use those two tools as like my back end


01:01:26.540 --> 01:01:27.900
bread and butter for everything I do.


01:01:27.900 --> 01:01:30.900
And so those have just been really great work.


01:01:30.900 --> 01:01:32.580
- Apache Arrow, right? - Yes.


01:01:32.580 --> 01:01:35.100
- And then Ray, I'm not sure.


01:01:35.100 --> 01:01:38.660
- Ray is a distributed scheduling compute framework.


01:01:38.660 --> 01:01:41.140
It's sort of like a-- - Right, right, right.


01:01:41.140 --> 01:01:42.700
Yeah, I remember seeing about this, yeah.


01:01:42.700 --> 01:01:45.940
- This is, it is, I'm parsing,


01:01:45.940 --> 01:01:46.860
we didn't talk about other things,


01:01:46.860 --> 01:01:48.220
but I'm like parsing Common Crawl,


01:01:48.220 --> 01:01:50.020
which is like 25 petabytes of data.


01:01:50.020 --> 01:01:52.820
And Ray is great, it's just a workhorse.


01:01:52.820 --> 01:01:55.020
It's really useful.


01:01:55.020 --> 01:01:59.020
Like, I find it's so snappy and good,


01:01:59.020 --> 01:02:00.260
but it offers everything I need


01:02:00.260 --> 01:02:01.260
in a distributed environment.


01:02:01.260 --> 01:02:04.040
So I can write code that runs on 100 machines


01:02:04.040 --> 01:02:05.260
and not have to think about it.


01:02:05.260 --> 01:02:06.100
It works really well.


01:02:06.100 --> 01:02:07.620
- That's pretty nuts.


01:02:07.620 --> 01:02:10.020
Not as nuts as chat GDP and mid-journey,


01:02:10.020 --> 01:02:10.980
but still pretty nuts.


01:02:10.980 --> 01:02:12.820
So before we call it a day,


01:02:12.820 --> 01:02:15.140
do you wanna just tell people about Approximate Labs?


01:02:15.140 --> 01:02:18.020
It sounds like you guys are making some good progress.


01:02:18.020 --> 01:02:19.780
Might have some jobs for people


01:02:19.780 --> 01:02:21.340
that work in this kind of area as well.


01:02:21.340 --> 01:02:23.700
- Yeah, so we're working at the intersection


01:02:23.700 --> 01:02:25.380
of AI and tabular data.


01:02:25.380 --> 01:02:27.180
So anything related to these training,


01:02:27.180 --> 01:02:29.940
these large language models, and also tabular data.


01:02:29.940 --> 01:02:31.260
So things with columns and rows.


01:02:31.260 --> 01:02:32.940
We are trying to solve that problem,


01:02:32.940 --> 01:02:34.920
try and bridge the gap here, because there's


01:02:34.920 --> 01:02:35.900
a pretty big gap.


01:02:35.900 --> 01:02:37.980
We have three main initiatives that we're working on,


01:02:37.980 --> 01:02:40.480
which is we're trying to build up the data set of data sets.


01:02:40.480 --> 01:02:44.500
So just like the pile or the stack or Leon5b,


01:02:44.500 --> 01:02:47.180
these big data sets that we use to train all these big models,


01:02:47.180 --> 01:02:49.220
we're making our own on tabular data.


01:02:49.220 --> 01:02:50.500
We are training models.


01:02:50.500 --> 01:02:53.420
So this is actually training large language models,


01:02:53.420 --> 01:02:55.940
doing these training, these full transformer models.


01:02:55.940 --> 01:02:58.120
And then we're also building apps like Sketch,


01:02:58.120 --> 01:02:59.900
like UIs, things that are actually there


01:02:59.900 --> 01:03:01.940
to help make data more accessible to people.


01:03:01.940 --> 01:03:05.140
So anything that helps people get value from data


01:03:05.140 --> 01:03:07.260
and make it open source, that's what we're working on.


01:03:07.260 --> 01:03:09.980
We just raised our seed round,


01:03:09.980 --> 01:03:11.660
so we are now officially hiring.


01:03:11.660 --> 01:03:14.620
So looking for people who are interested in the space


01:03:14.620 --> 01:03:16.260
and who are enthusiastic about these problems.


01:03:16.260 --> 01:03:17.480
- Awesome.


01:03:17.480 --> 01:03:21.980
Well, very exciting demo libraries, I guess,


01:03:21.980 --> 01:03:26.980
however you call them, but I think these are neat.


01:03:26.980 --> 01:03:30.140
People are going to find a lot of cool uses for them.


01:03:30.140 --> 01:03:32.140
Excellent work and congrats on all the success so far.


01:03:32.140 --> 01:03:36.340
It sounds like you're just starting to take off.


01:03:36.340 --> 01:03:37.900
- Thank you.


01:03:37.900 --> 01:03:39.040
- All right, Justin, final call to action.


01:03:39.040 --> 01:03:40.500
People want to get started, let's pick Sketch.


01:03:40.500 --> 01:03:42.740
People want to get started with Sketch,


01:03:42.740 --> 01:03:43.860
what do you tell them?


01:03:43.860 --> 01:03:44.500
- Just pip install it.


01:03:44.500 --> 01:03:46.060
Give Sketch a try, pip install it, import it,


01:03:46.060 --> 01:03:49.540
and then throw it on your data frame.


01:03:49.540 --> 01:03:50.820
- Awesome.


01:03:50.820 --> 01:03:51.540
And then ask it questions or how-to's, yeah?


01:03:49.660 --> 01:03:51.500
- Yeah, yeah, whatever you want.


01:03:51.500 --> 01:03:54.260
If you really want to and you trust the model,


01:03:54.260 --> 01:03:56.780
throw some applies and have it clean your data for you.


01:03:56.780 --> 01:03:58.380
- Cool, awesome.


01:03:58.380 --> 01:04:00.860
All right, well, thanks for being on the show.


01:04:00.860 --> 01:04:02.540
Come in here and tell us about all your work.


01:04:02.540 --> 01:04:03.500
It's great. - Yeah, thank you.


01:04:03.500 --> 01:04:05.920
- Yeah, see you later. - Thanks for having me.


01:04:05.920 --> 01:04:09.180
- This has been another episode of Talk Python to Me.


01:04:09.180 --> 01:04:10.620
Thank you to our sponsors.


01:04:10.620 --> 01:04:11.980
Be sure to check out what they're offering.


01:04:11.980 --> 01:04:14.240
It really helps support the show.


01:04:14.240 --> 01:04:17.660
Stay on top of technology and raise your value to employers


01:04:17.660 --> 01:04:21.780
or just learn something fun in STEM at brilliant.org.


01:04:21.780 --> 01:04:24.580
Visit talkpython.fm/brilliant


01:04:24.580 --> 01:04:28.280
to get 20% off an annual premium subscription.


01:04:28.280 --> 01:04:29.580
Want to level up your Python?


01:04:29.580 --> 01:04:31.380
We have one of the largest catalogs


01:04:31.380 --> 01:04:33.740
of Python video courses over at Talk Python.


01:04:33.740 --> 01:04:35.780
Our content ranges from true beginners


01:04:35.780 --> 01:04:38.740
to deeply advanced topics like memory and async.


01:04:38.740 --> 01:04:41.420
And best of all, there's not a subscription in sight.


01:04:41.420 --> 01:04:44.460
Check it out for yourself at training.talkpython.fm.


01:04:44.460 --> 01:04:46.060
Be sure to subscribe to the show,


01:04:46.060 --> 01:04:49.060
Open your favorite podcast app and search for Python.


01:04:49.060 --> 01:04:50.440
We should be right at the top.


01:04:50.440 --> 01:04:53.320
You can also find the iTunes feed at /itunes,


01:04:53.320 --> 01:04:55.520
the Google Play feed at /play,


01:04:55.520 --> 01:04:59.520
and the Direct RSS feed at /rss on talkpython.fm.


01:04:59.520 --> 01:05:03.040
We're live streaming most of our recordings these days.


01:05:03.040 --> 01:05:04.200
If you want to be part of the show


01:05:04.200 --> 01:05:06.480
and have your comments featured on the air,


01:05:06.480 --> 01:05:08.320
be sure to subscribe to our YouTube channel


01:05:08.320 --> 01:05:11.320
at talkpython.fm/youtube.


01:05:11.320 --> 01:05:12.720
This is your host, Michael Kennedy.


01:05:12.720 --> 01:05:13.900
Thanks so much for listening.


01:05:13.900 --> 01:05:15.120
I really appreciate it.


01:05:15.120 --> 01:05:16.880
Now get out there and write some Python code.


01:05:16.880 --> 01:05:38.880
[MUSIC]

