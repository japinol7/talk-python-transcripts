WEBVTT

00:00:00.000 --> 00:00:03.540
When you think of Netflix as a technology company,


00:00:03.540 --> 00:00:06.080
you probably imagine them as cloud innovators.


00:00:06.080 --> 00:00:08.120
They were one of the first companies to go all in


00:00:08.120 --> 00:00:10.620
on a massive scale for cloud computing,


00:00:10.620 --> 00:00:13.220
as well as throwing that pesky chaos monkey


00:00:13.220 --> 00:00:14.580
into those servers.


00:00:14.580 --> 00:00:18.540
But they have become a hive of amazing Python activity


00:00:18.540 --> 00:00:21.840
from their CDN, their demand predictions and failover,


00:00:21.840 --> 00:00:24.460
security, machine learning, executable notebooks,


00:00:24.460 --> 00:00:25.720
and lots more.


00:00:25.720 --> 00:00:28.520
The Python at play is super interesting.


00:00:28.520 --> 00:00:30.920
And on this episode, we have Zorin Simic


00:00:30.920 --> 00:00:33.040
and Amjith Ramanujan on the show


00:00:33.040 --> 00:00:35.520
to give us this rare look inside.


00:00:35.520 --> 00:00:38.200
This is "Talk Python to Me," episode 421,


00:00:38.200 --> 00:00:41.560
recorded June 8th, 2023.


00:00:41.560 --> 00:00:44.140
(upbeat music)


00:00:44.140 --> 00:00:55.280
Welcome to "Talk Python to Me,"


00:00:55.280 --> 00:00:57.200
a weekly podcast on Python.


00:00:57.200 --> 00:00:58.960
This is your host, Michael Kennedy.


00:00:58.960 --> 00:01:01.320
Follow me on Mastodon, where I'm @mkennedy,


00:01:01.320 --> 00:01:04.040
and follow the podcast using @talkpython,


00:01:04.040 --> 00:01:06.280
both on fosstodon.org.


00:01:06.280 --> 00:01:07.880
Be careful with impersonating accounts


00:01:07.880 --> 00:01:10.120
on other instances, there are many.


00:01:10.120 --> 00:01:12.240
Keep up with the show and listen to over seven years


00:01:12.240 --> 00:01:15.620
of past episodes at talkpython.fm.


00:01:15.620 --> 00:01:17.680
We've started streaming most of our episodes


00:01:17.680 --> 00:01:19.120
live on YouTube.


00:01:19.120 --> 00:01:20.320
Subscribe to our YouTube channel


00:01:20.320 --> 00:01:22.720
over at talkpython.fm/youtube


00:01:22.720 --> 00:01:24.920
to get notified about upcoming shows


00:01:24.920 --> 00:01:27.120
and be part of that episode.


00:01:27.120 --> 00:01:29.560
This episode is brought to you by JetBrains,


00:01:29.560 --> 00:01:33.200
who encourage you to get work done with PyCharm.


00:01:33.200 --> 00:01:35.680
Download your free trial of PyCharm Professional


00:01:35.680 --> 00:01:40.520
at talkbython.fm/done-with-pycharm.


00:01:40.520 --> 00:01:42.480
And it's brought to you by InfluxDB.


00:01:42.480 --> 00:01:44.600
InfluxDB is the database purpose-built


00:01:44.600 --> 00:01:47.700
for handling time series data at a massive scale


00:01:47.700 --> 00:01:49.320
for real-time analytics.


00:01:49.320 --> 00:01:52.980
Try them for free at talkbython.fm/influxDB.


00:01:52.980 --> 00:01:55.220
Hey, Soren.


00:01:55.220 --> 00:01:56.040
Hey, MG. - Hello, Michael.


00:01:56.040 --> 00:01:56.880
- Hello, Michael.


00:01:56.880 --> 00:01:58.640
to talk Python to me, you guys.


00:01:58.640 --> 00:02:00.280
It's excellent to have you here.


00:02:00.280 --> 00:02:01.120
- Thank you very much.


00:02:01.120 --> 00:02:04.480
I'm a big fan, so it's very nice to be on the show, actually.


00:02:04.480 --> 00:02:05.480
- Awesome, yeah.


00:02:05.480 --> 00:02:07.200
We've got to meet a couple times at PyCon,


00:02:07.200 --> 00:02:10.600
which is honestly one of my favorite purposes of PyCon


00:02:10.600 --> 00:02:12.240
is to meet people and just hang out


00:02:12.240 --> 00:02:14.240
and have those experiences, you know?


00:02:14.240 --> 00:02:15.600
- Yeah, absolutely.


00:02:15.600 --> 00:02:18.000
- Yeah, and nice to have you on the show, Zorin.


00:02:18.000 --> 00:02:20.000
- Yeah, I'm a big fan as well.


00:02:20.000 --> 00:02:20.840
- Thank you very much.


00:02:20.840 --> 00:02:22.160
That's very kind of both of you.


00:02:22.160 --> 00:02:26.560
So we're gonna talk about a pretty awesome tech company,


00:02:26.560 --> 00:02:28.920
I think Netflix, you both work at Netflix,


00:02:28.920 --> 00:02:30.200
and people who are watching the video,


00:02:30.200 --> 00:02:33.040
you're coming to us from the Netflix headquarters,


00:02:33.040 --> 00:02:34.640
which I've got the chance to be there


00:02:34.640 --> 00:02:37.920
for like some Python stuff going on there before as well.


00:02:37.920 --> 00:02:40.840
Got cool posters and like sort of movie studio feel.


00:02:40.840 --> 00:02:43.760
So that's the backdrop you both have going on,


00:02:43.760 --> 00:02:44.680
which is excellent.


00:02:44.680 --> 00:02:45.520
- Yeah, yeah.


00:02:45.520 --> 00:02:49.040
It's pretty nice to work at Netflix.


00:02:49.040 --> 00:02:50.120
It's a very good company.


00:02:50.120 --> 00:02:51.600
I'm very happy.


00:02:51.600 --> 00:02:52.880
- A lot of Python we're gonna learn.


00:02:52.880 --> 00:02:53.840
- Yes, yeah.


00:02:53.840 --> 00:02:56.160
We do use a lot of Python, yeah.


00:02:56.160 --> 00:02:58.800
- Excellent, so we're gonna talk about Python and Netflix,


00:02:58.800 --> 00:03:02.000
a wide ranging sort of survey of a lot of projects


00:03:02.000 --> 00:03:03.800
you all have created, how you're using it,


00:03:03.800 --> 00:03:07.480
some other ones that both of you personally created,


00:03:07.480 --> 00:03:09.800
either tied to or not tied to Netflix,


00:03:09.800 --> 00:03:12.760
but I think people are gonna really enjoy this look inside


00:03:12.760 --> 00:03:13.680
what you all got going on.


00:03:13.680 --> 00:03:14.920
Before we get to that though,


00:03:14.920 --> 00:03:16.360
let's start with your stories.


00:03:16.360 --> 00:03:20.000
Quick introduction, how'd you get here working on Python?


00:03:20.000 --> 00:03:21.000
Sorin, you wanna go first?


00:03:21.000 --> 00:03:24.560
- Yeah, so I was hooked into programming


00:03:24.560 --> 00:03:28.280
Ever since I saw my first computer, I finished at 13 in middle school.


00:03:28.280 --> 00:03:30.320
It was an Amstrad CPC.


00:03:30.320 --> 00:03:30.680
Right.


00:03:30.680 --> 00:03:33.360
I was, yeah, that was the thing I wanted to do.


00:03:33.360 --> 00:03:36.920
So, yeah, I started programming as a hobby at first.


00:03:36.920 --> 00:03:41.480
And fun fact, way back then, later on in high school, one of my math teachers


00:03:41.480 --> 00:03:43.160
told me, Hey, do something real.


00:03:43.160 --> 00:03:44.400
Don't, don't do programming.


00:03:44.400 --> 00:03:45.920
It's like a dead end.


00:03:45.920 --> 00:03:48.120
You know, you won't be able to find a job.


00:03:49.880 --> 00:04:00.520
Did they tell you things like these drag and drop visual tools are going to replace all the programmers and all like the low code of the eighties and nineties, maybe?


00:04:00.520 --> 00:04:06.960
Yeah, back then, I guess it was very, well, didn't seem that obvious.


00:04:06.960 --> 00:04:07.640
Yeah.


00:04:07.640 --> 00:04:13.680
And then, yeah, I decided to go computer science anyway, because that's what I wanted to do.


00:04:13.680 --> 00:04:21.480
And then I spent the vast majority of my career in a language that is not very much known or used, I think, iPhone.


00:04:21.480 --> 00:04:25.580
So I spent more than a decade on doing iPhone mostly.


00:04:25.580 --> 00:04:29.620
And then I discovered Python once I joined LinkedIn in 2011.


00:04:29.620 --> 00:04:36.180
And that's when I kind of, well, got hooked and decided to do more and more things Python.


00:04:36.180 --> 00:04:41.520
And now at Netflix, even more so trying to support NetPython across the board.


00:04:41.520 --> 00:04:41.820
Yeah.


00:04:41.820 --> 00:04:46.140
You were kind of doing meta Python in the sense that your team does a lot of


00:04:46.140 --> 00:04:49.580
stuff to facilitate other people doing Python too, right?


00:04:49.580 --> 00:04:50.340
Exactly.


00:04:50.340 --> 00:04:50.700
Yes.


00:04:50.700 --> 00:04:51.180
Yeah.


00:04:51.180 --> 00:04:53.160
That's our, that's our team at Netflix.


00:04:53.160 --> 00:04:58.380
Like we enable other Python developers to be more productive by building tools or


00:04:58.380 --> 00:05:02.780
building the infrastructure necessary to ship their code faster or build their


00:05:02.780 --> 00:05:04.740
products sooner, things like that.


00:05:04.740 --> 00:05:04.980
Yeah.


00:05:04.980 --> 00:05:05.300
Cool.


00:05:05.300 --> 00:05:06.620
How about you Amjith?


00:05:06.620 --> 00:05:10.460
Oh, I got introduced to programming in high school.


00:05:10.540 --> 00:05:13.420
We had like one hour of a computer lab every week.


00:05:13.420 --> 00:05:17.320
I got to learn GW basic, that was my first language.


00:05:17.320 --> 00:05:18.280
It was fantastic.


00:05:18.280 --> 00:05:22.360
I still have fond memories of like trying to draw circles on the screen.


00:05:22.360 --> 00:05:25.600
And then I went to college, I learned C and C++.


00:05:25.600 --> 00:05:29.900
I liked those, but then after I got a job, I wanted to learn, you know, how to be a


00:05:29.900 --> 00:05:32.580
better programmer and somebody mentioned, you know, oh, functional programming is


00:05:32.580 --> 00:05:35.600
the bee's knees, you should actually, you know, if you learn how to do functional


00:05:35.600 --> 00:05:39.200
programming, your general programming will get better and the best language to


00:05:39.200 --> 00:05:41.100
learn functional programming is Haskell.


00:05:41.100 --> 00:05:44.360
And so I took a book called, learn new Haskell.


00:05:44.360 --> 00:05:47.960
And then I went through like the first few chapters and, and it was mind blowing.


00:05:47.960 --> 00:05:49.980
It was like a really fantastic language.


00:05:49.980 --> 00:05:53.880
And, and I got first introduced to a concept of REPL and like trying out


00:05:53.880 --> 00:05:57.680
like little snippets in the interpreter and getting answers and it was fantastic.


00:05:57.680 --> 00:06:02.240
And I got introduced to lists comprehension in Haskell and it was just mind blowing.


00:06:02.240 --> 00:06:05.880
It's like, you know, without having to write a, write like five lines of for loop,


00:06:05.880 --> 00:06:08.240
you could just, it's a single line thing.


00:06:08.680 --> 00:06:14.040
And I quickly realized that, you know, you can't find actual jobs writing Haskell


00:06:14.040 --> 00:06:17.000
or at least, you know, not, not, not in a good way.


00:06:17.000 --> 00:06:21.180
So, so I figured out like, what's a language that has list comprehension


00:06:21.180 --> 00:06:24.520
that is actually employable, you know, that, that I could find jobs in.


00:06:24.520 --> 00:06:28.540
That's how I found Python because I came to Python because of list comprehension.


00:06:28.540 --> 00:06:29.440
Oh, awesome.


00:06:29.440 --> 00:06:29.720
Yeah.


00:06:29.720 --> 00:06:30.080
Okay.


00:06:30.080 --> 00:06:33.240
Learn you a Haskell for great good, a beginner's guide.


00:06:33.240 --> 00:06:33.840
Is that the book?


00:06:33.840 --> 00:06:34.920
That is the book.


00:06:34.920 --> 00:06:35.280
Yeah.


00:06:35.360 --> 00:06:37.960
And it's actually still available online for free


00:06:37.960 --> 00:06:40.200
that anybody could read, I'm fairly certain.


00:06:40.200 --> 00:06:42.840
And I actually bought like a paper copy of the book.


00:06:42.840 --> 00:06:44.240
It's a good book.


00:06:44.240 --> 00:06:45.960
It's a fun one to go through.


00:06:45.960 --> 00:06:47.360
- Yeah, it looks like it's really got


00:06:47.360 --> 00:06:48.760
a playful nature to it.


00:06:48.760 --> 00:06:49.840
- Yeah, exactly.


00:06:49.840 --> 00:06:50.680
- Yeah.


00:06:50.680 --> 00:06:53.200
You know, your thoughts about less comprehensions


00:06:53.200 --> 00:06:55.800
really connects with me as well.


00:06:55.800 --> 00:06:58.220
I guess my first exposure to something like that


00:06:58.220 --> 00:07:01.440
was Link, L-I-N-Q and C#, which is,


00:07:01.440 --> 00:07:03.000
it's honestly, I think it's better


00:07:03.000 --> 00:07:04.160
than Python less comprehensions.


00:07:04.160 --> 00:07:06.680
I wish Python had just a little bit more.


00:07:06.680 --> 00:07:07.760
- Nice. - A little bit.


00:07:07.760 --> 00:07:09.360
Just one or two things more.


00:07:09.360 --> 00:07:12.240
For example, wouldn't it be nice in a list comprehension


00:07:12.240 --> 00:07:14.320
if you could specify a sort?


00:07:14.320 --> 00:07:16.760
'Cause I find myself often doing a list comprehension


00:07:16.760 --> 00:07:19.760
and then sorting the thing in the end afterwards.


00:07:19.760 --> 00:07:23.040
But if you could just say order by and give it an expression


00:07:23.040 --> 00:07:26.040
like you would to pass a lambda over to a, you know.


00:07:26.040 --> 00:07:27.680
So there's room for more.


00:07:27.680 --> 00:07:29.240
What PEP do I need to write


00:07:29.240 --> 00:07:30.760
to get sort in a list comprehension?


00:07:30.760 --> 00:07:32.560
I don't know, but I want it anyway.


00:07:32.560 --> 00:07:36.080
Yeah. So I really think that that's a cool language feature.


00:07:36.080 --> 00:07:39.360
And you know, it's also one of the areas that they're applying some of these


00:07:39.360 --> 00:07:44.200
speed-ups in the faster CPython work that's coming, they're doing, you know,


00:07:44.200 --> 00:07:48.600
list comprehensions for isolation purposes and Python three are basically


00:07:48.600 --> 00:07:52.480
hidden function calls with their own stack frame and variables that you,


00:07:52.480 --> 00:07:53.720
you don't actually see, right.


00:07:53.720 --> 00:07:56.360
You don't write it, but that's kind of the execution level.


00:07:56.360 --> 00:07:59.000
And now they're inlining those to make them a little bit faster.


00:08:00.600 --> 00:08:04.140
Yeah, I think the faster Python team is doing like a fantastic job.


00:08:04.140 --> 00:08:07.900
Like the, there was a talk that I attended at PyCon, not this year, but the previous


00:08:07.900 --> 00:08:11.040
year where they introduced like switch case, how they were doing the, the case


00:08:11.040 --> 00:08:14.160
statements, it's not the exact switch case, but you know, I coming from C and C


00:08:14.160 --> 00:08:16.000
plus plus, I knew what switch cases are.


00:08:16.000 --> 00:08:19.580
And when I saw what, what is possible with the pattern matching, like structural


00:08:19.580 --> 00:08:23.780
pattern matching in Python, it's like take switch case and then like turn it up to


00:08:23.780 --> 00:08:25.260
11 and that's what this is.


00:08:25.260 --> 00:08:26.060
And you're right.


00:08:26.060 --> 00:08:29.660
I mean, there is always more that can be done, but I think it's going in a great


00:08:29.660 --> 00:08:31.820
direction, I think it's fantastic.


00:08:31.820 --> 00:08:33.300
- Yeah, let's talk about that.


00:08:33.300 --> 00:08:36.100
I mean, we're going to dive into the details


00:08:36.100 --> 00:08:38.740
of Netflix and stuff, but just, you know,


00:08:38.740 --> 00:08:41.820
this whole Python 3.11, 3.12,


00:08:41.820 --> 00:08:45.260
these are really big performance improvements coming along.


00:08:45.260 --> 00:08:46.100
- Yeah.


00:08:46.100 --> 00:08:48.420
- Are you able yet to take advantage of those at Netflix?


00:08:48.420 --> 00:08:49.980
And is that making a big difference?


00:08:49.980 --> 00:08:52.300
You know, like, are you guys still running, you know,


00:08:52.300 --> 00:08:55.380
3.8 or are you more closer to the cutting edge


00:08:55.380 --> 00:08:56.660
in terms of releases?


00:08:56.660 --> 00:08:59.580
- So I think one of the advantages here at Netflix


00:08:59.580 --> 00:09:03.820
is that every team has the freedom to choose the tools that they need to use.


00:09:03.820 --> 00:09:06.920
And it's great and also kind of painful for central teams


00:09:06.920 --> 00:09:10.920
because now, you know, there is like a bifurcation of all kinds of different versions out there.


00:09:10.920 --> 00:09:15.920
But where I'm going with this is that every team is allowed to choose what is what they need to use


00:09:15.920 --> 00:09:17.220
in order to get their job done.


00:09:17.220 --> 00:09:21.220
And so my previous team, we were at the cutting edge, like we used 3.11,


00:09:21.220 --> 00:09:25.520
or we still use 3.11 in the projects that we built, and the services that we use.


00:09:25.520 --> 00:09:28.520
And it is a nice boost, like we could certainly see.


00:09:28.520 --> 00:09:31.360
So for instance, there is like a periodic job that runs,


00:09:31.360 --> 00:09:35.520
and it's like a sort of a cron job that runs every five minutes or so.


00:09:35.520 --> 00:09:37.520
And we had put in like so much optimization


00:09:37.520 --> 00:09:39.520
so that it will actually finish within the five minutes


00:09:39.520 --> 00:09:42.520
because we were doing a lot of data crunching and so forth.


00:09:42.520 --> 00:09:45.860
And just so we don't like stack up the cron tasks.


00:09:45.860 --> 00:09:48.320
But when we switched from, I think from,


00:09:48.320 --> 00:09:50.520
like, we did jump from 3.9 to 3.11 directly.


00:09:50.520 --> 00:09:52.320
We did not like go to 3.10.


00:09:52.320 --> 00:09:54.660
But then when we jumped, it felt like, you know,


00:09:54.660 --> 00:09:57.020
things that were taking like four minutes,


00:09:57.020 --> 00:09:58.820
we're now finishing in like two minutes.


00:09:58.820 --> 00:10:02.980
And it was like a huge improvement that you could see.


00:10:02.980 --> 00:10:04.980
And like, it felt very rewarding to see that.


00:10:04.980 --> 00:10:05.860
So yeah, absolutely.


00:10:05.860 --> 00:10:08.060
So every team gets to choose what they want to use.


00:10:08.060 --> 00:10:10.900
And our job as a central Python team


00:10:10.900 --> 00:10:12.900
that Zorin and I are currently part of


00:10:12.900 --> 00:10:15.860
is to try and enable people to use that,


00:10:15.860 --> 00:10:17.700
use whatever is the latest that is available.


00:10:17.700 --> 00:10:20.980
So, you know, whatever internal tools that we have,


00:10:20.980 --> 00:10:23.420
we have to make sure that it actually gets exercised


00:10:23.420 --> 00:10:25.860
in the latest Python version that got released


00:10:25.860 --> 00:10:28.300
and make sure that everything is building and deploying


00:10:28.300 --> 00:10:29.700
as they are supposed to do and so on.


00:10:29.700 --> 00:10:30.700
- Okay, excellent.


00:10:30.700 --> 00:10:33.660
That's pretty cool, that story of speeding up your Cron jobs.


00:10:33.660 --> 00:10:37.860
That's non-trivial, and it probably wasn't a lot of work


00:10:37.860 --> 00:10:39.380
to move from 3.9 to 3.11.


00:10:39.380 --> 00:10:42.940
I know my upgrade path was rebuild some virtual environments


00:10:42.940 --> 00:10:45.020
on the server, and now we're good to go.


00:10:45.020 --> 00:10:46.620
- Exactly, yeah.


00:10:46.620 --> 00:10:49.540
- So, René, anything you want to add about that?


00:10:49.540 --> 00:10:51.860
3.11, faster CPython side?


00:10:51.860 --> 00:10:55.220
- Oh yeah, absolutely, it's so faster.


00:10:55.220 --> 00:10:56.180
So much faster.


00:10:56.180 --> 00:10:56.380
Yeah.


00:10:56.380 --> 00:11:01.340
The main issue on when upgrading is the lack of wheels, if you're like stuck on


00:11:01.340 --> 00:11:06.400
older libraries, but we do have a, like a few numbers, like the most used right


00:11:06.400 --> 00:11:08.720
now is Python 3.10 across the board, right?


00:11:08.720 --> 00:11:10.700
It will depend on the team right now.


00:11:10.700 --> 00:11:15.700
Everybody is upgrading at their own pace and 3.11 is starting to grow a bit.


00:11:15.700 --> 00:11:19.600
But yeah, most used right now is 3.10 statically.


00:11:19.600 --> 00:11:20.260
You should look at it.


00:11:20.260 --> 00:11:23.980
- Honestly, that sounds really quite good for a company


00:11:23.980 --> 00:11:27.060
the size of Netflix and how much Python you're doing.


00:11:27.060 --> 00:11:29.100
That's pretty close to pushing the envelope.


00:11:29.100 --> 00:11:31.900
- Yeah, there are still some teams that are sort of


00:11:31.900 --> 00:11:35.380
stuck on 3.8 or 3.7, I wanna say,


00:11:35.380 --> 00:11:38.340
simply because they provide a platform


00:11:38.340 --> 00:11:40.980
that allows data scientists to write their code


00:11:40.980 --> 00:11:44.420
and they have this pre-built image


00:11:44.420 --> 00:11:47.340
with all of the necessary libraries pre-installed in there.


00:11:47.340 --> 00:11:49.900
And so they have like a pretty tight control


00:11:49.900 --> 00:11:53.660
over which libraries will get upgraded on what cadence and so on.


00:11:53.660 --> 00:11:57.900
And so for them, I think they have, they're still, you know, running on 3.7.


00:11:57.900 --> 00:12:01.100
And I'm sure when they switch to 3.10 or 3.11,


00:12:01.100 --> 00:12:03.900
it's going to be like a screaming fast improvement.


00:12:03.900 --> 00:12:06.460
So looking forward to that migration to happen.


00:12:06.460 --> 00:12:07.260
Yeah, excellent.


00:12:07.260 --> 00:12:09.100
This number is very static, right?


00:12:09.100 --> 00:12:13.380
It's a number of like short pythons across repos.


00:12:13.380 --> 00:12:15.620
But yeah, dynamically, right?


00:12:15.620 --> 00:12:19.060
Like you may have lots of instances who still run on 3.7,


00:12:19.060 --> 00:12:20.980
and they will massively move to a,


00:12:20.980 --> 00:12:24.220
so that team is moving from 3.7 to 3.10, for example.


00:12:24.220 --> 00:12:25.060
- Right, yeah.


00:12:25.060 --> 00:12:26.580
- Yeah, so upgrade paths.


00:12:26.580 --> 00:12:30.220
- This portion of Talk Python to Me


00:12:30.220 --> 00:12:33.260
is brought to you by JetBrains and PyCharm.


00:12:33.260 --> 00:12:35.180
Are you a data scientist or a web developer


00:12:35.180 --> 00:12:37.900
looking to take your projects to the next level?


00:12:37.900 --> 00:12:40.780
Well, I have the perfect tool for you, PyCharm.


00:12:40.780 --> 00:12:43.440
PyCharm is a powerful integrated development environment


00:12:43.440 --> 00:12:46.700
that empowers developers and data scientists like us


00:12:46.700 --> 00:12:50.220
to write clean and efficient code with ease.


00:12:50.220 --> 00:12:52.340
Whether you're analyzing complex data sets


00:12:52.340 --> 00:12:54.620
or building dynamic web applications,


00:12:54.620 --> 00:12:56.280
PyCharm has got you covered.


00:12:56.280 --> 00:12:58.860
With its intuitive interface and robust features,


00:12:58.860 --> 00:13:00.340
you can boost your productivity


00:13:00.340 --> 00:13:03.420
and bring your ideas to life faster than ever before.


00:13:03.420 --> 00:13:06.020
For data scientists, PyCharm offers seamless integration


00:13:06.020 --> 00:13:09.740
with popular libraries like NumPy, Pandas, and Matplotlib.


00:13:09.740 --> 00:13:13.020
You can explore, visualize, and manipulate data effortlessly,


00:13:13.020 --> 00:13:16.900
unlocking valuable insights with just a few lines of code.


00:13:16.900 --> 00:13:19.420
And for us web developers, PyCharm provides a rich set


00:13:19.420 --> 00:13:21.440
of tools to streamline your workflow.


00:13:21.440 --> 00:13:22.820
From intelligent code completion


00:13:22.820 --> 00:13:24.900
to advanced debugging capabilities,


00:13:24.900 --> 00:13:27.700
PyCharm helps you write clean, scalable code


00:13:27.700 --> 00:13:30.680
that powers stunning web applications.


00:13:30.680 --> 00:13:33.100
Plus, PyCharm support for popular frameworks


00:13:33.100 --> 00:13:36.420
like Django, FastAPI, and React make it a breeze


00:13:36.420 --> 00:13:38.900
to build and deploy your web projects.


00:13:38.900 --> 00:13:41.460
It's time to say goodbye to tedious configuration


00:13:41.460 --> 00:13:43.720
and hello to rapid development.


00:13:43.720 --> 00:13:45.160
But wait, there's more.


00:13:45.160 --> 00:13:47.420
With PyCharm, you get even more advanced features


00:13:47.420 --> 00:13:50.100
like remote development, database integration,


00:13:50.100 --> 00:13:52.000
and version control, ensuring your projects


00:13:52.000 --> 00:13:53.940
stay organized and secure.


00:13:53.940 --> 00:13:55.660
So whether you're diving into data science


00:13:55.660 --> 00:13:57.300
or shaping the future of the web,


00:13:57.300 --> 00:13:59.180
PyCharm is your go-to tool.


00:13:59.180 --> 00:14:01.060
Join me and try PyCharm today.


00:14:01.060 --> 00:14:06.060
Just visit talkpython.fm/done-with-pycharm,


00:14:06.060 --> 00:14:07.740
links in your show notes,


00:14:07.740 --> 00:14:10.140
and experience the power of PyCharm firsthand


00:14:10.140 --> 00:14:12.300
for three months free.


00:14:12.300 --> 00:14:14.740
PyCharm, it's how I get work done.


00:14:14.740 --> 00:14:21.860
Let's start by talking about kind of the broad story


00:14:21.860 --> 00:14:24.020
of Python at Netflix.


00:14:24.020 --> 00:14:27.740
Maybe we could start with what you all do day to day


00:14:27.740 --> 00:14:30.340
in terms of what's your role,


00:14:30.340 --> 00:14:32.900
'cause you kind of support other people's Python


00:14:32.900 --> 00:14:33.940
as I hinted before.


00:14:33.940 --> 00:14:35.900
So maybe we can get a sense of what you all do day to day


00:14:35.900 --> 00:14:36.740
and then we'll,


00:14:36.740 --> 00:14:38.580
Amjith you wrote a nice blog article


00:14:38.580 --> 00:14:43.380
That's a big, broad, pure survey of how Python's being used in all these


00:14:43.380 --> 00:14:44.100
different places.


00:14:44.100 --> 00:14:47.060
So maybe start with what you all do day to day on your, on your team, and


00:14:47.060 --> 00:14:47.700
then we'll go into that.


00:14:47.700 --> 00:14:48.500
Yeah, sure thing.


00:14:48.500 --> 00:14:51.120
I've been with Netflix for about six years now.


00:14:51.120 --> 00:14:55.580
And previously I was in a different team and we were doing fail overs, which


00:14:55.580 --> 00:14:59.900
was a way of running, you know, if Netflix ever goes down in one of the AWS


00:14:59.900 --> 00:15:04.060
regions, we are the team that gets paged in and we go and move all the traffic


00:15:04.060 --> 00:15:06.660
from that region to another other two regions that we run in.


00:15:07.060 --> 00:15:10.820
So that's what I was doing up until like February of this year.


00:15:10.820 --> 00:15:13.620
And let me just take a step back real quick with you.


00:15:13.620 --> 00:15:16.020
Netflix is kind of all in on AWS, right?


00:15:16.020 --> 00:15:23.120
Like there's been a lot of stories about how you all have set loose the chaos monkey into your data centers


00:15:23.120 --> 00:15:26.420
and how you worked on failover from AWS regions.


00:15:26.420 --> 00:15:30.320
And so I don't know if you all are the largest users of AWS,


00:15:30.320 --> 00:15:35.020
but certainly one of the more interesting, complicated deployments out there, right?


00:15:35.020 --> 00:15:40.460
Yeah, so I think we were the earliest adopters of cloud computing when AWS first came out.


00:15:40.460 --> 00:15:46.540
And so AWS has used as the poster child for, you know, see big companies can run in cloud,


00:15:46.540 --> 00:15:52.380
and you don't have to be on prem. And so we think of them as partners, not so much as, you know,


00:15:52.380 --> 00:15:58.060
like this client owner relationship or anything like that. So we consider AWS as our business


00:15:58.060 --> 00:16:04.260
as partners. And yes, we are full in on AWS. And Chaos Monkey, even now, yes, it


00:16:04.260 --> 00:16:09.460
is, it functions in AWS, like it goes around and just inside our VPC, it does


00:16:09.460 --> 00:16:13.420
terminate instances occasionally or not occasionally, like once every day, one


00:16:13.420 --> 00:16:15.380
instance every day on every service.


00:16:15.380 --> 00:16:20.260
So that is so wild. I mean, obviously, you don't want to set it loose on other


00:16:20.260 --> 00:16:25.980
people's AWS instances, right? Just Yeah, that's a really interesting way to force


00:16:25.980 --> 00:16:30.340
people to think about developers and infrastructure folks to think about what


00:16:30.340 --> 00:16:35.340
happens if the cloud somehow your server dies, it may be sending the clouds fall,


00:16:35.340 --> 00:16:37.900
right? It's just like, okay, there's a Linux machine running and that thing


00:16:37.900 --> 00:16:41.980
died. It could have been running anywhere. It happened to be an AWS, but to force


00:16:41.980 --> 00:16:46.060
them to think about outgoing, like we will, it's not a eventuality. This will


00:16:46.060 --> 00:16:47.580
happen. And so you plan for it.


00:16:47.580 --> 00:16:52.740
Yeah, it's even more than just the idea of like, it will happen. So we plan for


00:16:52.740 --> 00:16:59.740
It's more like, you know, it's a way of building software where you need to build software that's resilient and has enough fallbacks built in.


00:16:59.740 --> 00:17:09.740
So for instance, if you are not able to reach the database, do you have a cache in front that can sort of, you know, keep the thing going for the few network calls that are failing to reach the database?


00:17:09.740 --> 00:17:19.740
Those are like basic common things, paradigms that have become commonplace nowadays in software development where, you know, building fallbacks automatically is like standard practice these days.


00:17:19.740 --> 00:17:23.740
these days. But when Chaos Monkey was created, which was about 10 years ago,


00:17:23.740 --> 00:17:27.740
these were like new concepts that people were not using. And it was assumed


00:17:27.740 --> 00:17:31.740
that once you have a server and you put your software on the server and you run it,


00:17:31.740 --> 00:17:35.740
it's basically done. Until you do the next deploy, which takes another month or so to


00:17:35.740 --> 00:17:39.740
refresh that server, refresh that code. But that all changed once we went


00:17:39.740 --> 00:17:43.740
to cloud, where we started doing deployments on a daily basis or maybe even more


00:17:43.740 --> 00:17:47.740
hourly basis and things like that. And so when you are doing that, when you are shutting down


00:17:47.740 --> 00:17:51.700
one server with old version and bringing up the new server with a new version,


00:17:51.700 --> 00:17:54.340
how are you going to make sure that the connections are not going to fall?


00:17:54.340 --> 00:17:58.000
And how are you going to make sure that the network continuity continues and so forth?


00:17:58.000 --> 00:18:02.440
So yeah, Chaos Monkey was just introduced as a way to ensure that people are


00:18:02.440 --> 00:18:04.940
building software in a way that is resilient.


00:18:04.940 --> 00:18:09.300
And this is just a way to sort of test that on an ongoing basis.


00:18:09.300 --> 00:18:11.500
Yeah, it's quite an operational challenge.


00:18:11.500 --> 00:18:13.800
I mean, I don't recall seeing Netflix saying,


00:18:13.800 --> 00:18:17.300
our scheduled maintenance is coming up on Sunday, we'll be down for five hours.


00:18:17.300 --> 00:18:19.300
Not acceptable is it?


00:18:19.300 --> 00:18:21.300
It just makes you laugh to even think about it.


00:18:21.300 --> 00:18:23.300
Especially not on a Sunday.


00:18:23.300 --> 00:18:27.300
I've even seen government sites, I can't remember which government it was,


00:18:27.300 --> 00:18:29.300
saying that the website was closed,


00:18:29.300 --> 00:18:31.300
like the website had business hours.


00:18:31.300 --> 00:18:32.300
That's a different deal.


00:18:32.300 --> 00:18:34.300
Like, you came at night, like, "Oh, you can't come here right now."


00:18:34.300 --> 00:18:37.300
It's like, "What? It's the web. I don't understand what's going on."


00:18:37.300 --> 00:18:41.300
All right. So let's go through this blog post that you wrote here,


00:18:41.300 --> 00:18:44.300
entitled just Python at Netflix on the Netflix technology blog.


00:18:44.300 --> 00:18:45.380
- Technology blog.


00:18:45.380 --> 00:18:48.540
Yeah, so you wrote this in preparation of PyCon.


00:18:48.540 --> 00:18:50.460
This is PyCon 2023?


00:18:50.460 --> 00:18:52.180
- No, this was 2019 actually.


00:18:52.180 --> 00:18:56.500
So this is old by at least two or three years now.


00:18:56.500 --> 00:18:58.900
- Okay, yeah, you had pointed out before we press record


00:18:58.900 --> 00:19:00.500
that some of these projects mentioned here


00:19:00.500 --> 00:19:03.420
that used to be internal things are now also open source.


00:19:03.420 --> 00:19:05.580
So there's a little more access to these


00:19:05.580 --> 00:19:07.260
than the blog posts might indicate.


00:19:07.260 --> 00:19:09.140
- Yeah, some of the things that are mentioned here, yes,


00:19:09.140 --> 00:19:11.220
they have been open source since then.


00:19:11.220 --> 00:19:13.340
So specifically the one that I remember right now


00:19:13.340 --> 00:19:17.020
is Metaflow, which is an infrastructure,


00:19:17.020 --> 00:19:21.220
it's like a platform orchestration infrastructure framework


00:19:21.220 --> 00:19:24.540
that is used by our machine learning organization


00:19:24.540 --> 00:19:27.500
where scientists would try and build their model


00:19:27.500 --> 00:19:30.100
or they use existing models from like XGBoost


00:19:30.100 --> 00:19:33.500
or like tons of other Python libraries.


00:19:33.500 --> 00:19:37.220
And their interest and their expertise lies


00:19:37.220 --> 00:19:40.500
in crafting those models, training those models


00:19:40.500 --> 00:19:42.340
and building the correct algorithm


00:19:42.340 --> 00:19:44.100
to do the predictions and so on.


00:19:44.100 --> 00:19:46.680
They are not so interested in making sure


00:19:46.680 --> 00:19:49.520
that enough compute is available to run these models,


00:19:49.520 --> 00:19:51.180
or they're not interested in making sure


00:19:51.180 --> 00:19:53.220
that the plumbing works, or this model's data


00:19:53.220 --> 00:19:56.580
is now going to the next step of this algorithm,


00:19:56.580 --> 00:19:58.940
or even getting it deployed and making it available


00:19:58.940 --> 00:20:00.200
in the production environment.


00:20:00.200 --> 00:20:04.660
So that's all that abstraction is taken care of by Metaflow.


00:20:04.660 --> 00:20:07.340
So Metaflow is a project that was mentioned here,


00:20:07.340 --> 00:20:09.160
and that allows you to make it easy


00:20:09.160 --> 00:20:12.300
for machine learning folks to get their system running


00:20:12.300 --> 00:20:15.140
and as well as deploying it out to production.


00:20:15.140 --> 00:20:16.980
And now that is now open sourced


00:20:16.980 --> 00:20:19.240
and it is available for folks to use.


00:20:19.240 --> 00:20:21.140
And I think some other companies have actually adopted


00:20:21.140 --> 00:20:22.620
to using that as well.


00:20:22.620 --> 00:20:23.460
So, yeah.


00:20:23.460 --> 00:20:27.860
- It kind of operate like a DevOps automation


00:20:27.860 --> 00:20:29.180
for machine learning.


00:20:29.180 --> 00:20:31.100
So the people they're writing,


00:20:31.100 --> 00:20:32.420
creating the models and the data scientists


00:20:32.420 --> 00:20:34.300
don't have to also be DevOps people.


00:20:34.300 --> 00:20:36.660
- Right, it's slightly more than DevOps as well


00:20:36.660 --> 00:20:38.780
because it also does the pipelining work


00:20:38.780 --> 00:20:41.140
to make it possible for someone to, you know,


00:20:41.140 --> 00:20:45.140
bring the data from this database and load it in,


00:20:45.140 --> 00:20:46.900
all of that work is already taken care of,


00:20:46.900 --> 00:20:48.700
or at least there are libraries that are built


00:20:48.700 --> 00:20:50.980
into Metaflow that makes it possible to bring those in.


00:20:50.980 --> 00:20:53.220
And then it allows you to also do orchestration.


00:20:53.220 --> 00:20:55.340
So for instance, machine learning models


00:20:55.340 --> 00:20:58.060
typically happen in multi-steps and multi-stages.


00:20:58.060 --> 00:20:59.980
And so the data gets processed by this function,


00:20:59.980 --> 00:21:01.860
and then it gets moved on to this other function,


00:21:01.860 --> 00:21:04.500
and then it gets moved on to this other thing and so forth.


00:21:04.500 --> 00:21:06.140
And so it does the plumbing to make sure


00:21:06.140 --> 00:21:08.780
that the data can flow through this topology


00:21:08.780 --> 00:21:10.980
and actually produce results and so on.


00:21:10.980 --> 00:21:12.580
- Yeah, you probably have enough data


00:21:12.580 --> 00:21:14.860
that that's a lot of data to move, so.


00:21:14.860 --> 00:21:16.580
(laughing)


00:21:16.580 --> 00:21:17.940
All right, a quick question from the audience


00:21:17.940 --> 00:21:19.500
before we dive into the topics here.


00:21:19.500 --> 00:21:21.500
Diego asks, "On such a big platform


00:21:21.500 --> 00:21:22.960
"with so many software engineers


00:21:22.960 --> 00:21:24.280
"with different coding practices,


00:21:24.280 --> 00:21:27.360
"do you all get together and follow some set norms


00:21:27.360 --> 00:21:30.940
"by Netflix, or is it more team by team basis?"


00:21:30.940 --> 00:21:32.820
- It is very much team by team basis.


00:21:32.820 --> 00:21:34.260
So each team has their style


00:21:34.260 --> 00:21:35.940
and the areas that they focus on.


00:21:35.940 --> 00:21:38.160
So for instance, like machine learning engineers


00:21:38.160 --> 00:21:40.660
are not going to care too much about


00:21:40.660 --> 00:21:45.160
how do I make this production grade super heavily fortified or whatever?


00:21:45.160 --> 00:21:48.360
And security engineers might be focusing on completely different things.


00:21:48.360 --> 00:21:49.960
So it is different.


00:21:49.960 --> 00:21:53.100
But at the same time, I do want to mention that there are certain


00:21:53.100 --> 00:21:55.960
norms that are common across the entire company where, you know,


00:21:55.960 --> 00:21:58.400
so for instance, Chaos Monkey is one of those things where


00:21:58.400 --> 00:22:01.660
since Netflix operates in a way where, you know,


00:22:01.660 --> 00:22:06.960
every team is given the freedom to choose and operate the way they see fit,


00:22:06.960 --> 00:22:10.500
there is no edict that can come from a VP or a president that says,


00:22:10.500 --> 00:22:13.000
like you must write code in this way, like that doesn't happen.


00:22:13.000 --> 00:22:15.800
And so what that means is, how are you going to enforce,


00:22:15.800 --> 00:22:17.700
like, you know, you have to write resilient software,


00:22:17.700 --> 00:22:20.700
or how are you going to make sure that your software will continue to run


00:22:20.700 --> 00:22:24.200
if one of the servers out of the hundred servers has gone down?


00:22:24.200 --> 00:22:26.300
And so there is not a good way to enforce that.


00:22:26.300 --> 00:22:29.400
And Chaos Monkey was created as a way to enforce that,


00:22:29.400 --> 00:22:32.500
which is, yes, we're not going to be able to tell you how to write software,


00:22:32.500 --> 00:22:35.000
but this particular service that exists,


00:22:35.000 --> 00:22:36.900
it's going to go around killing servers.


00:22:36.900 --> 00:22:39.600
And so you better make sure that your software is actually resilient


00:22:39.600 --> 00:22:41.140
to servers going down.


00:22:41.140 --> 00:22:44.640
So that's a way in which we influence people


00:22:44.640 --> 00:22:47.140
to write the--to produce the right outcome


00:22:47.140 --> 00:22:48.640
without telling them how to do it.


00:22:48.640 --> 00:22:50.940
- I see. So sort of,


00:22:50.940 --> 00:22:54.640
you agree on a common principle of design for failure


00:22:54.640 --> 00:22:56.140
and design for resiliency,


00:22:56.140 --> 00:22:58.640
and then it's up to people how to make that happen.


00:22:58.640 --> 00:23:02.480
- Yes, and also, we have the concept of paved paths,


00:23:02.480 --> 00:23:05.440
or paved road, which is we have certain libraries


00:23:05.440 --> 00:23:08.180
that are made to operate within our infrastructure.


00:23:08.180 --> 00:23:11.540
So there is an internal discovery tool, and there is an internal metrics collection tool,


00:23:11.540 --> 00:23:15.620
and there is an internal, you know, like a failure recovery tool and so forth.


00:23:15.620 --> 00:23:19.620
And these libraries that are provided in these languages,


00:23:19.620 --> 00:23:24.020
they make it really that simple to just integrate with these services.


00:23:24.020 --> 00:23:27.940
And so it makes it the obvious choice for people to start using those libraries


00:23:27.940 --> 00:23:30.660
rather than, you know, paving their own path, for instance.


00:23:30.660 --> 00:23:34.580
So we try and make it as easy as possible to do the right thing.


00:23:34.580 --> 00:23:38.780
And so people generally fall into that paved road solutions that we have.


00:23:38.780 --> 00:23:39.180
Excellent.


00:23:39.180 --> 00:23:43.540
And we try to make it also now, especially as a central Python team,


00:23:43.540 --> 00:23:46.620
to promote good practices, right?


00:23:46.620 --> 00:23:50.220
Like, you should have a pipeline, you should choose a release strategy,


00:23:50.220 --> 00:23:53.780
you should have tests, and we help.


00:23:53.780 --> 00:23:59.980
If you don't, we can help you set that up and choose a good relevant release strategy for you.


00:23:59.980 --> 00:24:01.900
Excellent. Yeah, that's really good.


00:24:01.900 --> 00:24:03.900
So let's dive into this blog post.


00:24:03.900 --> 00:24:08.220
Now it was written by Amjit, but Soren, jump in as well as we talk about, please.


00:24:08.220 --> 00:24:12.380
So the first one is related to bandwidth.


00:24:12.380 --> 00:24:15.700
To somewhat like delivering the content.


00:24:15.700 --> 00:24:19.060
And there's some interesting articles and stuff that says how much of the


00:24:19.060 --> 00:24:21.100
internet's bandwidth does Netflix use?


00:24:21.100 --> 00:24:25.380
And I don't know how accurate this is, but maybe give us a sense of like, you


00:24:25.380 --> 00:24:26.780
got to have a lot of traffic, right?


00:24:26.780 --> 00:24:27.340
Yes.


00:24:27.340 --> 00:24:32.620
So I think when I first joined Netflix, I was told that we use about one third of


00:24:32.780 --> 00:24:35.880
all of internet's bandwidth, but that was back in 2017.


00:24:35.880 --> 00:24:38.980
So things have changed quite a bit since then.


00:24:38.980 --> 00:24:43.380
Our use of bandwidth is slightly interesting in the sense,


00:24:43.380 --> 00:24:45.480
the actual, when somebody goes to their website


00:24:45.480 --> 00:24:47.020
and they're browsing around,


00:24:47.020 --> 00:24:50.320
all of that data is served directly from AWS servers.


00:24:50.320 --> 00:24:52.620
And so we have servers running in AWS


00:24:52.620 --> 00:24:54.020
that does the search functionality,


00:24:54.020 --> 00:24:55.940
the thumbs up, the thumbs down,


00:24:55.940 --> 00:24:59.020
you're selecting something and reading the review


00:24:59.020 --> 00:25:01.320
or looking at related things and whatnot.


00:25:01.380 --> 00:25:05.320
But as soon as they click on the play button on a particular video,


00:25:05.320 --> 00:25:09.280
the actual video file itself is not streaming from AWS,


00:25:09.280 --> 00:25:12.720
but instead it's coming from a CDN called Open Connect.


00:25:12.720 --> 00:25:16.780
And this is a proprietary thing that we built


00:25:16.780 --> 00:25:20.860
where we ship these CDNs to various internet exchanges


00:25:20.860 --> 00:25:24.020
that are already filled with the right videos


00:25:24.020 --> 00:25:26.920
and they get populated with the correct videos


00:25:26.920 --> 00:25:30.560
that are getting released overnight or on a regular basis.


00:25:30.620 --> 00:25:34.020
The reason we do that is because we want the videos to stream from the


00:25:34.020 --> 00:25:36.500
closest possible place for the end user.


00:25:36.500 --> 00:25:40.460
And so when a end user in Florida clicks on it, it's coming from an internet


00:25:40.460 --> 00:25:42.140
exchange that is located in Florida.


00:25:42.140 --> 00:25:45.620
And that's why you don't see a lot of buffering when videos are playing from


00:25:45.620 --> 00:25:50.020
Netflix is because there's, you know, it's inside their, their network to a large


00:25:50.020 --> 00:25:51.900
extent, that's our open connect team.


00:25:51.900 --> 00:25:53.020
And that's, that's what they do.


00:25:53.020 --> 00:25:53.900
And yeah.


00:25:53.900 --> 00:25:54.260
Yeah.


00:25:54.260 --> 00:25:56.220
That's, CDNs are awesome.


00:25:56.380 --> 00:25:59.300
And they really are just, they're kind of a bit


00:25:59.300 --> 00:26:03.180
of magic performance dust you can sprinkle on sites.


00:26:03.180 --> 00:26:08.180
That works for CSS and JavaScript and stuff,


00:26:08.180 --> 00:26:10.280
but when it comes to large content,


00:26:10.280 --> 00:26:12.340
then it makes all the difference.


00:26:12.340 --> 00:26:15.660
So in the blog post you write, let's see,


00:26:15.660 --> 00:26:17.580
yeah, it says, "Various software systems


00:26:17.580 --> 00:26:19.080
"are needed to design, build, and operate


00:26:19.080 --> 00:26:21.620
"the CDN infrastructure, and a big part of them


00:26:21.620 --> 00:26:23.380
"are written in Python.


00:26:23.380 --> 00:26:25.980
"The network devices that underlie a large portion of it


00:26:25.980 --> 00:26:28.140
are mostly managed by Python and so on.


00:26:28.140 --> 00:26:33.180
Give us a sense of where Python fits in this Open Connect CDN that you all run.


00:26:33.180 --> 00:26:38.780
Sure. Yeah. So the CDNs themselves run like high performance code to stream the video.


00:26:38.780 --> 00:26:41.260
Obviously that software is not written in Python.


00:26:41.260 --> 00:26:45.100
But the software, all the software that orchestrates and makes sure that these CDNs


00:26:45.100 --> 00:26:50.380
are remaining healthy, getting metrics out of them, as well as managing them and forecasting


00:26:50.380 --> 00:26:54.940
like what sort of videos are going to be going into these CDNs and so forth.


00:26:54.940 --> 00:26:57.580
those are all orchestrated using Python applications.


00:26:57.580 --> 00:26:59.140
So these are all internal tools.


00:26:59.140 --> 00:27:00.620
There's like an OC tools team.


00:27:00.620 --> 00:27:01.980
OC stands for the Open Connect,


00:27:01.980 --> 00:27:03.180
which is the name of the CDN.


00:27:03.180 --> 00:27:05.700
And OC tools team is the one that builds that.


00:27:05.700 --> 00:27:07.700
And they use quite a lot of Python


00:27:07.700 --> 00:27:09.820
for not just tracking our CDNs,


00:27:09.820 --> 00:27:11.980
but also for projecting, you know,


00:27:11.980 --> 00:27:14.380
which videos and what shapes they should be going into.


00:27:14.380 --> 00:27:16.300
So for instance, like to give you a quick example,


00:27:16.300 --> 00:27:18.420
like if we are launching, let's say like Stranger Things,


00:27:18.420 --> 00:27:19.660
like the newest season,


00:27:19.660 --> 00:27:22.420
we know for a fact that these videos are going to be,


00:27:22.420 --> 00:27:24.740
you know, they're either going to be streamed


00:27:24.740 --> 00:27:29.940
like 90% of the time from television, like a 4k definition television, or people are going to be


00:27:29.940 --> 00:27:35.140
watching on their iPhone. So all these videos get encoded in different formats, like for,


00:27:35.140 --> 00:27:40.420
for different resolutions. And how much do we put into the CDNs and how do we get them prepared?


00:27:40.420 --> 00:27:45.540
Do we need like multiple copies so that multiple streams can be read without having to, to have


00:27:45.540 --> 00:27:49.860
contention and so on. Things like those kinds of projections, those are all done using Python


00:27:49.860 --> 00:27:50.660
applications. Yeah.


00:27:50.660 --> 00:27:56.260
You probably can't put every version of every video at every location all the time, right?


00:27:56.260 --> 00:28:00.660
I don't know how much that is, but that's a large amount of video content, large load of files.


00:28:00.660 --> 00:28:02.660
You probably got to predict, right?


00:28:02.660 --> 00:28:08.260
These we can fall back to, you know, letting them stream from some higher upstream thing,


00:28:08.260 --> 00:28:10.660
but then it'll get cached after it gets viewed a little bit.


00:28:10.660 --> 00:28:12.660
But these were pre-loading, right?


00:28:12.660 --> 00:28:19.260
Yeah, yeah. Actually, Zorin used to work in the team that did all the encoding in different shapes and sizes.


00:28:19.260 --> 00:28:21.260
and they use quite a bit of Python as well,


00:28:21.260 --> 00:28:23.260
he'd be able to tell you more about that stuff.


00:28:23.260 --> 00:28:25.260
Yeah, did you just have like a huge office,


00:28:25.260 --> 00:28:27.260
like a whole building full of GPUs


00:28:27.260 --> 00:28:30.260
and just go in the whole time?


00:28:30.260 --> 00:28:32.260
Encoding is a lot of work. Yeah, tell us about this.


00:28:32.260 --> 00:28:34.260
Yeah, encoding is a lot of work.


00:28:34.260 --> 00:28:36.260
That was my original start here


00:28:36.260 --> 00:28:38.260
and we do a lot of Python as well.


00:28:38.260 --> 00:28:41.260
And yeah, we sum it up, we kind of try and scour,


00:28:41.260 --> 00:28:45.260
scavenge as many instances that we can put our hands on.


00:28:45.260 --> 00:28:48.260
So if we have any, say, AWS reservations,


00:28:48.260 --> 00:28:52.020
that it so happens that nobody's using right now,


00:28:52.020 --> 00:28:56.260
we come and grab them and spawn our workers


00:28:56.260 --> 00:28:58.980
dynamically on it as much as we can.


00:28:58.980 --> 00:29:00.980
- Interesting, almost like grid computing,


00:29:00.980 --> 00:29:02.460
like a steady at home.


00:29:02.460 --> 00:29:03.460
- Yeah, exactly.


00:29:03.460 --> 00:29:04.860
- Like steady at home, yeah.


00:29:04.860 --> 00:29:07.220
- And if we do have something like


00:29:07.220 --> 00:29:08.500
we have this high priority,


00:29:08.500 --> 00:29:09.820
well, you know, there's not enough,


00:29:09.820 --> 00:29:11.540
like kind of workers laying around,


00:29:11.540 --> 00:29:14.140
then we can go and get some on the spot,


00:29:14.140 --> 00:29:17.940
you know, market or, well, get to grab more reservations


00:29:17.940 --> 00:29:23.620
if need be. So that is the, the encoding is basically we take these big master


00:29:23.620 --> 00:29:28.380
files, right? Like the, these originals and we encode them for every single


00:29:28.380 --> 00:29:31.740
variation where it makes sense, like for this TV, for that phone, for, you


00:29:31.740 --> 00:29:33.180
know, Android phone, iOS phone.


00:29:33.180 --> 00:29:36.740
What is the product of all the different resolutions and different platforms?


00:29:36.740 --> 00:29:40.820
How many video files do you have to make for how many formats do you have to


00:29:40.820 --> 00:29:42.580
have for one movie?


00:29:42.580 --> 00:29:43.180
Do you know?


00:29:43.180 --> 00:29:44.620
That changes per need.


00:29:44.620 --> 00:29:51.500
And, you know, we kind of keep fine tuning how we want the smallest files with the best quality.


00:29:51.500 --> 00:29:51.740
Right.


00:29:51.740 --> 00:29:53.360
So that keeps evolving.


00:29:53.360 --> 00:29:57.580
And sometimes we re-encode the full catalog because now we have like a better way of


00:29:57.580 --> 00:30:04.140
encoding, say, anime things versus, you know, action movies versus like, it gets to us.


00:30:04.140 --> 00:30:04.460
I see.


00:30:04.460 --> 00:30:10.460
You might choose a different encoder for a cartoon like thing versus the planet earth type of.


00:30:10.460 --> 00:30:11.060
Yes.


00:30:11.060 --> 00:30:11.460
Yeah.


00:30:11.460 --> 00:30:11.860
Okay.


00:30:11.860 --> 00:30:12.300
Yeah.


00:30:12.300 --> 00:30:12.580
Yeah.


00:30:12.580 --> 00:30:17.920
And all of this, basically by way of a product of all of this ends up on OpenConnect.


00:30:17.920 --> 00:30:20.080
I mean S3, but also OpenConnect.


00:30:20.080 --> 00:30:21.920
Yep. Excellent.


00:30:21.920 --> 00:30:26.220
One thing in there that is mentioned on my team, very interesting project called vMath.


00:30:26.220 --> 00:30:28.980
So that is written in Python, it's machine learning.


00:30:28.980 --> 00:30:36.420
And once you have encoded, right, like let's say you're trying a new way of encoding to make the files even smaller, right?


00:30:36.420 --> 00:30:40.180
You want to know during, while you're researching, right?


00:30:40.180 --> 00:30:44.460
you want to know, did you come up with a very good, better encoder than before?


00:30:44.460 --> 00:30:50.420
So VMAF is like a little bot that will look at encoded new file and give it a


00:30:50.420 --> 00:30:56.140
human-like score, like what quality would the human assess this to be?


00:30:56.140 --> 00:31:01.460
And it has to be, you know, basically excellent quality, get a high score, I


00:31:01.460 --> 00:31:06.060
think 90 out of a hundred, roughly, to pass.


00:31:06.060 --> 00:31:07.660
And then this is better, right?


00:31:07.700 --> 00:31:11.660
Like we have a smaller file, but the quality is still excellent and perceptibly


00:31:11.660 --> 00:31:14.660
it's as good as before, but just a slightly smaller.


00:31:14.660 --> 00:31:17.460
Then we could decide and re-encode the full catalog.


00:31:17.460 --> 00:31:20.100
I see. That's really interesting.


00:31:20.100 --> 00:31:25.020
So what you're telling me is you have an AI that you just make watch Netflix movies all the time.


00:31:25.020 --> 00:31:26.020
All the time.


00:31:26.020 --> 00:31:27.020
All the time.


00:31:27.020 --> 00:31:33.700
And we have other AIs that watch the whole catalog, for example, and find where text appears, say.


00:31:33.700 --> 00:31:37.380
you know, so that when we put subtitles, we can move them up or down, you know, to not


00:31:37.380 --> 00:31:42.820
put text on text and all kinds of metadata, like, where can we find landscapes? Where does


00:31:42.820 --> 00:31:48.820
broad pitch show up? Things like that. Incredible. I had no idea. People are always full of a lot of


00:31:48.820 --> 00:31:55.700
surprises. This portion of Talk Python to Me is brought to you by InfluxData, the makers of


00:31:55.700 --> 00:32:02.900
InfluxDB. InfluxDB is a database purpose built for handling time series data at a massive scale


00:32:02.900 --> 00:32:08.900
for real-time analytics. Developers can ingest, store, and analyze all types of time series data,


00:32:08.900 --> 00:32:14.180
metrics, events, and traces in a single platform. So, dear listener, let me ask you a question.


00:32:14.180 --> 00:32:19.140
How would boundless cardinality and lightning-fast SQL queries impact the way that you develop


00:32:19.140 --> 00:32:25.220
real-time applications? InfluxDB processes large time series datasets and provides low-latency


00:32:25.220 --> 00:32:30.260
SQL queries, making it the go-to choice for developers building real-time applications


00:32:30.260 --> 00:32:36.020
and seeking crucial insights. For developer efficiency, InfluxDB helps you create IoT


00:32:36.020 --> 00:32:42.040
analytics and cloud applications using timestamped data rapidly and at scale. It's designed to


00:32:42.040 --> 00:32:48.120
ingest billions of data points in real time with unlimited cardinality. InfluxDB streamlines


00:32:48.120 --> 00:32:53.200
building once and deploying across various products and environments from the edge on


00:32:53.200 --> 00:32:59.720
premise and to the cloud. Try it for free at talkpython.fm/influxdb. The link is in


00:32:59.720 --> 00:33:07.120
your podcast player show notes. Thanks to Influx Data for supporting the show.


00:33:07.120 --> 00:33:11.480
And I think the VMAF software that's written in Python, I believe that is open source,


00:33:11.480 --> 00:33:12.480
right Zorin?


00:33:12.480 --> 00:33:13.960
It is. It is open source. Yes.


00:33:13.960 --> 00:33:18.240
And I think it's one of the Emmy award winning software. I did not know that software could


00:33:18.240 --> 00:33:24.960
win Emmy awards before this one. And it's kind of, it, it apparently won an Emmy award for something


00:33:24.960 --> 00:33:32.560
videography or something. Probably. Yeah. Wow. Yeah. That's awesome. All right. The next major


00:33:32.560 --> 00:33:37.600
section is demand engineering. Yeah. This is kind of like DevOps type stuff, right? Keeping things


00:33:37.600 --> 00:33:43.120
running capacity plan. Yes, that is exactly right. Yeah. That was the team that I was in previously.


00:33:43.120 --> 00:33:47.440
And the regional fail overs is the one where I mentioned where you could traffic from one of the


00:33:47.440 --> 00:33:49.120
of the AWS regions into the other two regions.


00:33:49.120 --> 00:33:52.240
So we run in three separate AWS regions,


00:33:52.240 --> 00:33:54.960
and any time any of those regions is having a difficulty,


00:33:54.960 --> 00:33:56.920
we can easily move the traffic to the other two regions


00:33:56.920 --> 00:34:00.040
without users even noticing that there was a glitch


00:34:00.040 --> 00:34:02.520
or any kind of issue there.


00:34:02.520 --> 00:34:03.480
- How long does it take?


00:34:03.480 --> 00:34:06.020
If you say you've got to move 50% of the traffic


00:34:06.020 --> 00:34:11.000
out of US East, Virginia, to somewhere else,


00:34:11.000 --> 00:34:13.240
is that hours, minutes?


00:34:13.240 --> 00:34:16.240
- So the fastest we have done is,


00:34:16.240 --> 00:34:19.320
So on average, it takes about seven minutes to do all of that.


00:34:19.320 --> 00:34:20.440
And that was our target.


00:34:20.440 --> 00:34:22.480
So when I first joined, I was given as a target.


00:34:22.480 --> 00:34:24.480
It used to be around 45 minutes at the time.


00:34:24.480 --> 00:34:28.200
And we built some, you know, interesting things to make it possible


00:34:28.200 --> 00:34:29.640
to run it inside seven minutes.


00:34:29.640 --> 00:34:33.120
But the fastest we've done is like around five minutes in like an emergency


00:34:33.120 --> 00:34:37.360
where, you know, oh God, the entire region is tanked and people in the US


00:34:37.360 --> 00:34:38.440
are not happy about this.


00:34:38.440 --> 00:34:40.400
Let's, let's move as fast as we can.


00:34:40.400 --> 00:34:41.680
We can do it in five minutes.


00:34:41.680 --> 00:34:45.520
Doesn't happen often, but you know, when it happens, especially, you know,


00:34:45.520 --> 00:34:50.360
when AWS Virginia goes down because a quarter of the internet stops working.


00:34:50.360 --> 00:34:52.000
Sure.


00:34:52.000 --> 00:34:54.480
But it's not just AWS that goes down.


00:34:54.480 --> 00:34:58.200
Sometimes sometimes we shoot ourselves in the foot.


00:34:58.200 --> 00:35:05.200
One of the interesting things to make sure that we release software that is safe is we do something called regionally staggered releases.


00:35:05.200 --> 00:35:15.040
And so when a new software or when a new version gets released, since it's like hundreds of microservices that are running inside of Netflix to make it all possible, every service will deploy.


00:35:15.080 --> 00:35:18.280
and when they start to deploy, they deploy it into a single region,


00:35:18.280 --> 00:35:21.780
wait about like five to ten minutes to make sure that nothing bad has happened,


00:35:21.780 --> 00:35:24.180
and then they proceed to the next one and then the next one.


00:35:24.180 --> 00:35:26.780
And so when they release it to the first region,


00:35:26.780 --> 00:35:30.080
they can either, if they find out that it's bad,


00:35:30.080 --> 00:35:32.280
they can either quickly roll it back,


00:35:32.280 --> 00:35:34.580
or we could just evacuate out of that region,


00:35:34.580 --> 00:35:36.980
because we can do that in like under seven minutes.


00:35:36.980 --> 00:35:39.480
And so if the rollback takes longer than seven minutes,


00:35:39.480 --> 00:35:41.680
then a call will be made by the core team,


00:35:41.680 --> 00:35:43.480
which will say, "Let's evacuate out.


00:35:43.480 --> 00:35:45.400
we haven't figured out what the problem is.


00:35:45.400 --> 00:35:48.800
So and then, you know, we evacuate and then we'll debug, you know,


00:35:48.800 --> 00:35:53.440
oh, which service did a release and what do we need to roll back and so on.


00:35:53.440 --> 00:35:57.240
Because there are like hundreds of services that are simultaneously releasing at the same time.


00:35:57.240 --> 00:36:02.040
So it's like quickly trying to identify which service that we need to roll back can sometimes be tricky.


00:36:02.040 --> 00:36:04.080
So we have used failovers for that as well.


00:36:04.080 --> 00:36:06.200
Yeah, so it's not just AWS's fault.


00:36:06.200 --> 00:36:07.200
Yeah, sure.


00:36:07.200 --> 00:36:11.560
And I don't mean to pick on AWS, because all these data centers go down.


00:36:11.560 --> 00:36:15.900
The difference is when AWS goes down, it's like the internet goes down, you know,


00:36:15.900 --> 00:36:17.860
it's like the observability of it.


00:36:17.860 --> 00:36:18.680
So why?


00:36:18.680 --> 00:36:20.920
Cause so much runs on there.


00:36:20.920 --> 00:36:23.500
It's like that in CloudFlare when they go down to you're like, Oh,


00:36:23.500 --> 00:36:24.420
I see everything's broken.


00:36:24.420 --> 00:36:24.700
Okay.


00:36:24.700 --> 00:36:25.340
Yeah.


00:36:25.340 --> 00:36:29.920
And when, when sites go down in production, even for places way smaller than


00:36:29.920 --> 00:36:34.700
Netflix, it's really stressful and you might make it worse by trying to fix it.


00:36:34.700 --> 00:36:38.380
So the ability to just go, let's buy ourselves some time to figure this out


00:36:38.380 --> 00:36:40.940
and just get everyone out and then we're going to look at it and then we'll


00:36:40.940 --> 00:36:41.780
we can bring them back.


00:36:41.780 --> 00:36:42.980
That's pretty cool.


00:36:42.980 --> 00:36:44.580
You did write an article called


00:36:44.580 --> 00:36:47.100
how Netflix does failovers in seven minutes flat,


00:36:47.100 --> 00:36:48.220
which I'll put in the show notes


00:36:48.220 --> 00:36:50.220
so people can read more about that if they want.


00:36:50.220 --> 00:36:51.060
- Thanks.


00:36:51.060 --> 00:36:54.100
- So this demand engineering side,


00:36:54.100 --> 00:36:56.740
talk about obviously tools are primarily


00:36:56.740 --> 00:36:58.260
built in Python there.


00:36:58.260 --> 00:37:00.220
You got some NumPy and SciPy


00:37:00.220 --> 00:37:02.660
and even the B Python shell.


00:37:02.660 --> 00:37:04.620
Tell us about some of the Python stuff going on here.


00:37:04.620 --> 00:37:06.580
- Before I joined Netflix,


00:37:06.580 --> 00:37:09.060
like when I actually first started learning Python,


00:37:09.060 --> 00:37:13.360
I loved the REPL, but I always felt like the REPL did not have auto-completion in it.


00:37:13.360 --> 00:37:19.160
And that, like, BPython is an alternate REPL for Python that provides you with, like, auto-completion


00:37:19.160 --> 00:37:21.220
and syntax highlighting and all that stuff.


00:37:21.220 --> 00:37:24.060
So I am a huge fan of BPython.


00:37:24.060 --> 00:37:27.900
One of the things that we have done, like, demand engineering specifically, is, you know,


00:37:27.900 --> 00:37:32.900
we get paged and we have to go in and try and rescue our traffic out of that region


00:37:32.900 --> 00:37:34.740
into the other two regions.


00:37:34.740 --> 00:37:39.980
And sometimes our software itself will not work because if an entire region is down,


00:37:39.980 --> 00:37:43.620
let's say it's because of a network connectivity issue or something, then the things that we


00:37:43.620 --> 00:37:48.480
call out to in order to make these, you know, changes to scale up the other regions and


00:37:48.480 --> 00:37:52.100
like evacuate and make DNS changes or whatever, that itself might be broken.


00:37:52.100 --> 00:37:57.060
And when that's broken, like we're literally SSH into the box and we will open up like


00:37:57.060 --> 00:38:01.220
a shell, Python shell, and do whatever we need to do.


00:38:01.220 --> 00:38:04.220
that has not happened in like the last four years, I would say,


00:38:04.220 --> 00:38:07.220
but six years ago, yeah, that was a thing that we used to do.


00:38:07.220 --> 00:38:10.720
And I wanted to call out bPython specifically in this particular case


00:38:10.720 --> 00:38:13.720
because it was so much more useful than trying to remember,


00:38:13.720 --> 00:38:16.220
"Oh, I remember I wrote this function. What is it?"


00:38:16.220 --> 00:38:19.220
Instead of opening my IDE to try to find out what that function is,


00:38:19.220 --> 00:38:21.720
I just import the module and then I do the module.


00:38:21.720 --> 00:38:23.720
And it lists me all the functions.


00:38:23.720 --> 00:38:26.220
And I could invoke it, and yeah, it's such a time saver.


00:38:26.220 --> 00:38:30.220
Yeah, Python REPL is cool, but it leaves a lot to be desired


00:38:30.220 --> 00:38:36.700
in terms of history or even if you want to edit a function that is five lines long,


00:38:36.700 --> 00:38:39.100
it's hard to go through.


00:38:39.100 --> 00:38:39.780
>> It becomes cumbersome.


00:38:39.780 --> 00:38:44.300
>> Another one is PT Python that I'm also a fan of that one.


00:38:44.300 --> 00:38:44.900
>> Yes.


00:38:44.900 --> 00:38:46.740
>> They're the same category.


00:38:46.740 --> 00:38:49.260
>> Yeah. Prompt Toolkit, the one that powered


00:38:49.260 --> 00:38:51.700
PT Python written by Jonathan Slenders actually,


00:38:51.700 --> 00:38:54.420
and it's a fantastic library.


00:38:54.420 --> 00:38:57.540
Kudos to Jonathan for doing that.


00:38:57.540 --> 00:38:58.940
It's a fantastic library.


00:38:58.940 --> 00:38:59.300
Yeah.


00:38:59.300 --> 00:38:59.900
Awesome.


00:38:59.900 --> 00:39:04.980
So are you, you got a particular enhancement there for your, your


00:39:04.980 --> 00:39:05.300
REPL?


00:39:05.300 --> 00:39:07.820
I'm not like that big of a user of REPL.


00:39:07.820 --> 00:39:12.380
In the terminal, we do like, you know, ask questions for generating new projects,


00:39:12.380 --> 00:39:12.740
et cetera.


00:39:12.740 --> 00:39:14.500
I'm much more of a PyCharm user myself.


00:39:14.500 --> 00:39:16.340
Like I go in there over there.


00:39:16.340 --> 00:39:19.700
As you bring that up, you know, one of the really nice Python REPLs is the,


00:39:19.700 --> 00:39:23.900
what I guess it's called probably the Python console in PyCharm, right?


00:39:23.900 --> 00:39:27.100
Because if you go to that and you get the Python REPL, but you get PyCharm's


00:39:27.100 --> 00:39:30.140
auto-complete and type consistency,


00:39:30.140 --> 00:39:32.460
and it automatically modifies the path


00:39:32.460 --> 00:39:33.300
to import your project.


00:39:33.300 --> 00:39:34.940
So yeah, you got one in there.


00:39:34.940 --> 00:39:35.780
- Yeah.


00:39:35.780 --> 00:39:36.600
- That one's yours, huh?


00:39:36.600 --> 00:39:39.260
All right, let's see the core team,


00:39:39.260 --> 00:39:42.180
alerting and statistical work.


00:39:42.180 --> 00:39:43.100
What's this one about?


00:39:43.100 --> 00:39:44.880
- Core team is our frontline SRE.


00:39:44.880 --> 00:39:47.620
So demand team is like building tools


00:39:47.620 --> 00:39:50.620
that the core team will leverage to get us out of trouble.


00:39:50.620 --> 00:39:52.980
So core team is the one that anytime there is,


00:39:52.980 --> 00:39:55.140
like they monitor a lot of metrics,


00:39:55.140 --> 00:39:58.900
not just streaming metrics, but also things like error rates


00:39:58.900 --> 00:40:01.900
between services that are happening and how many requests


00:40:01.900 --> 00:40:04.060
are successfully coming back and so forth.


00:40:04.060 --> 00:40:06.980
They obviously use Python to kind of keep tabs on,


00:40:06.980 --> 00:40:09.020
like obviously a person can't be sitting in front


00:40:09.020 --> 00:40:11.220
of a dashboard, just monitoring it themselves.


00:40:11.220 --> 00:40:13.980
And so they use quite a bit of Python to analyze the data


00:40:13.980 --> 00:40:17.140
from all of the hundreds of microservices and between them,


00:40:17.140 --> 00:40:19.380
the inter-process communication that actually happens


00:40:19.380 --> 00:40:21.540
and the metrics that come through and so forth.


00:40:21.540 --> 00:40:23.940
So they use Python for alerting.


00:40:23.940 --> 00:40:25.940
And so actually they use the monitoring,


00:40:25.940 --> 00:40:27.940
the next section that's right there


00:40:27.940 --> 00:40:30.240
is monitoring, alerting, and auto-remediation.


00:40:30.240 --> 00:40:33.340
We have an internal observability organization


00:40:33.340 --> 00:40:35.840
that has built our own time series database


00:40:35.840 --> 00:40:39.580
that's not in Python, but it's open source, called Atlas.


00:40:39.580 --> 00:40:42.980
And that uses, that collects all of the time series data


00:40:42.980 --> 00:40:44.520
from all of these services,


00:40:44.520 --> 00:40:46.840
and then they try and do alerting


00:40:46.840 --> 00:40:48.440
and remediation, auto-remediation.


00:40:48.440 --> 00:40:50.780
So when a particular alert condition is met,


00:40:50.780 --> 00:40:56.260
you can run a small Python script inside of a framework called Winston,


00:40:56.260 --> 00:40:59.540
that's again internal, that allows you to do more complicated things.


00:40:59.540 --> 00:41:05.860
So for instance, if you have like this one bad instance in like this collection of 20 instances,


00:41:05.860 --> 00:41:08.260
instead of a user going and terminating that instance,


00:41:08.260 --> 00:41:11.060
you can now automate that by writing a script that says,


00:41:11.060 --> 00:41:15.220
you know, automatically restart that instance or just kill it, and so on.


00:41:15.220 --> 00:41:16.100
That's our--


00:41:16.100 --> 00:41:18.860
Cool, that's part of the auto remediation of it.


00:41:18.860 --> 00:41:24.100
And it says it's built on G-Unicorn, Flask, and Flask Rest Plus.


00:41:24.100 --> 00:41:28.200
I'm familiar with the first batch, but the Flask Rest Plus,


00:41:28.200 --> 00:41:33.200
this is an extension for Flask that adds support for quickly building REST APIs.


00:41:33.200 --> 00:41:34.300
Okay, interesting.


00:41:34.300 --> 00:41:36.060
Because Flask itself already does REST.


00:41:36.060 --> 00:41:40.900
So REST Plus, I think, provides things like Swagger endpoints automatically,


00:41:40.900 --> 00:41:44.360
so you could try it out on the browser and so on.


00:41:44.360 --> 00:41:48.400
I have not used Flask Rest Plus myself, but that team uses it quite a bit.


00:41:48.400 --> 00:41:49.740
- Yeah, cool.


00:41:49.740 --> 00:41:52.660
Probably some of the, some similarities to like


00:41:52.660 --> 00:41:54.780
what FastAPI kind of brings in addition


00:41:54.780 --> 00:41:56.180
to standard Flask, I'd imagine.


00:41:56.180 --> 00:41:57.860
- Exactly, yeah, yeah.


00:41:57.860 --> 00:42:00.180
- We use more FastAPI nowadays.


00:42:00.180 --> 00:42:01.020
- Yes. - Oh yeah?


00:42:01.020 --> 00:42:02.940
- Yeah, we're using quite a bit of FastAPI


00:42:02.940 --> 00:42:05.020
in most of our internal tools actually.


00:42:05.020 --> 00:42:06.820
- Yeah, just from reading through this article,


00:42:06.820 --> 00:42:08.980
it sounds like there's a lot of APIs


00:42:08.980 --> 00:42:11.620
and just a lot of connectivity through,


00:42:11.620 --> 00:42:14.100
there's probably a lot of JSON going around Netflix.


00:42:14.100 --> 00:42:18.340
- Yes, yeah, so some of the heavier data stuff


00:42:18.340 --> 00:42:21.100
or like high streaming services,


00:42:21.100 --> 00:42:22.340
like that are in the streaming path


00:42:22.340 --> 00:42:24.140
are all typically written in Java.


00:42:24.140 --> 00:42:25.860
And they use for enterprise communication,


00:42:25.860 --> 00:42:28.500
they use gRPC and that uses Protobuf


00:42:28.500 --> 00:42:30.180
to communicate and so forth.


00:42:30.180 --> 00:42:33.620
But most of our internal tools that are written in Python,


00:42:33.620 --> 00:42:35.340
either use JSON directly,


00:42:35.340 --> 00:42:38.180
or sometimes they need to talk to a gRPC service.


00:42:38.180 --> 00:42:41.260
And so they use Python gRPC to get the work done.


00:42:41.260 --> 00:42:42.100
- Cool.


00:42:42.100 --> 00:42:44.220
Maybe we'll have some time to come back to gRPC.


00:42:44.220 --> 00:42:45.220
I'm not sure.


00:42:45.220 --> 00:42:47.260
We got a lot of things to talk about here.


00:42:47.260 --> 00:42:49.700
- Yeah, we don't have to go through every section here.


00:42:49.700 --> 00:42:53.140
- No, I know, there's just so many interesting angles, right?


00:42:53.140 --> 00:42:56.740
And so the next one here is information security,


00:42:56.740 --> 00:42:59.660
which obviously, if you just put anything on the internet


00:42:59.660 --> 00:43:02.420
and just tail the log of it, within minutes,


00:43:02.420 --> 00:43:05.820
you'll see a request for wpadmin.php.


00:43:05.820 --> 00:43:08.780
Like it's already just constantly being,


00:43:08.780 --> 00:43:12.540
people are just after it, right?


00:43:12.540 --> 00:43:14.460
One of the things you have here that looks interesting


00:43:14.460 --> 00:43:17.500
is security monkey written in Python,


00:43:17.500 --> 00:43:20.500
which is I guess like chaos monkey, but.


00:43:20.500 --> 00:43:22.180
- It is kind of like chaos monkey.


00:43:22.180 --> 00:43:24.420
I think this project may have been archived


00:43:24.420 --> 00:43:28.120
or it's not actively in development.


00:43:28.120 --> 00:43:31.740
It tries to scan our infrastructure for unsafe practices.


00:43:31.740 --> 00:43:34.380
That's like an umbrella term to try to add


00:43:34.380 --> 00:43:37.060
like whatever is like good practices


00:43:37.060 --> 00:43:39.880
that should exist from the security standpoint.


00:43:39.880 --> 00:43:41.600
- Yeah, okay, so people can check it out.


00:43:41.600 --> 00:43:43.580
Maybe it's not totally active anymore,


00:43:43.580 --> 00:43:45.420
but they can take it as inspiration, right?


00:43:45.420 --> 00:43:46.260
- Yeah.


00:43:46.260 --> 00:43:48.860
Like back in 2019, it was one of our most active projects


00:43:48.860 --> 00:43:49.700
that have happened.


00:43:49.700 --> 00:43:50.540
(laughing)


00:43:50.540 --> 00:43:52.260
2023 is a different world.


00:43:52.260 --> 00:43:53.420
- It is a different world.


00:43:53.420 --> 00:43:56.780
And one of the areas in which 2023 is a different world


00:43:56.780 --> 00:43:59.940
is really the AI/ML side.


00:43:59.940 --> 00:44:01.860
And you all are doing a lot of stuff


00:44:01.860 --> 00:44:03.740
with personalization algorithms,


00:44:03.740 --> 00:44:06.420
recommendation engines, machine learning.


00:44:06.420 --> 00:44:09.540
And you talked about Metaflow, which is now available.


00:44:09.540 --> 00:44:10.940
- Yeah, the personalization one,


00:44:10.940 --> 00:44:13.380
I think we've just mentioned a bunch of things


00:44:13.380 --> 00:44:14.980
that we use from the open-source world here.


00:44:14.980 --> 00:44:19.080
So I think XGBoost is a library that does machine learning.


00:44:19.080 --> 00:44:22.080
So personally, I am not in this field.


00:44:22.080 --> 00:44:26.380
So I just went and interviewed the team and asked them to give me a blurb.


00:44:26.380 --> 00:44:30.940
So I wouldn't be able to talk in detail about any of the personalization stuff here.


00:44:30.940 --> 00:44:36.520
But this is just a showcase of how much this team relies on Python


00:44:36.520 --> 00:44:40.540
and the open-source ecosystem that comes with Python in general.


00:44:40.620 --> 00:44:45.780
So it's like heavy users of Panda, TensorFlow, and PyTorch and so on.


00:44:45.780 --> 00:44:46.180
Yeah.


00:44:46.180 --> 00:44:52.940
So, Aron, let me ask you, is it your, both of your team supports Python developers


00:44:52.940 --> 00:44:55.900
and Python applications indirectly in that way,


00:44:55.900 --> 00:45:00.860
but is it different to support the data scientists than it is to support, say, software developers?


00:45:00.860 --> 00:45:03.700
Like, do you have to think about that differently? How so?


00:45:03.700 --> 00:45:08.500
Yes, yes, we do have like a team that is dedicated to supporting all the data scientists.


00:45:08.500 --> 00:45:11.460
And we're like the team that supports the team who supports for data science.


00:45:11.460 --> 00:45:12.660
And shit.


00:45:12.660 --> 00:45:13.660
Right now.


00:45:13.660 --> 00:45:19.980
So, yeah, we're definitely like now in 2023, you know, betting more on Python.


00:45:19.980 --> 00:45:24.020
Before Python was more like, if it makes sense for you because of freedom and


00:45:24.020 --> 00:45:27.860
responsibility, if it makes sense to use Python in your team, you use Python, you


00:45:27.860 --> 00:45:31.420
know, and now we're trying to provide basically like a better paced path.


00:45:31.420 --> 00:45:35.220
This is me and MG with this new team that we started.


00:45:35.220 --> 00:45:40.580
And we're trying to kind of enhance this space path better and better for all these teams.


00:45:40.580 --> 00:45:46.580
And we, you know, it's hard to know all the specifics in every single team, but we're


00:45:46.580 --> 00:45:51.160
trying to provide them with as good practices and automation as possible.


00:45:51.160 --> 00:45:55.300
So I think you asked, like, how is it different supporting one versus the other?


00:45:55.300 --> 00:46:00.760
I think we built, so when we first started the team, we met with 10 different organizations


00:46:00.760 --> 00:46:03.520
inside of Netflix to find out how they use Python,


00:46:03.520 --> 00:46:06.300
and we found that there were some commonalities,


00:46:06.300 --> 00:46:09.800
but the way, for instance, algorithms engineering uses Python


00:46:09.800 --> 00:46:13.060
is very different from the way a SRE team uses Python,


00:46:13.060 --> 00:46:16.920
and it's very, very different from how our animation studio uses Python.


00:46:16.920 --> 00:46:22.260
So our VFX animation uses Python in a way where once they start...


00:46:22.260 --> 00:46:25.360
This is apparently common in all of the movie industry,


00:46:25.360 --> 00:46:28.000
which is once they start a particular project,


00:46:28.000 --> 00:46:30.360
whatever they have chosen at the start of that project,


00:46:30.420 --> 00:46:32.760
they will stick to it until that project is completed.


00:46:32.760 --> 00:46:35.420
So if that movie takes two years to finish,


00:46:35.420 --> 00:46:38.420
you cannot upgrade anything inside of that particular


00:46:38.420 --> 00:46:40.760
hermetically sealed environment,


00:46:40.760 --> 00:46:42.220
development environment that you have.


00:46:42.220 --> 00:46:44.100
So that is very different from like another,


00:46:44.100 --> 00:46:46.720
like a machine learning person who's interested in like,


00:46:46.720 --> 00:46:48.800
you know, I just want to write my algorithm.


00:46:48.800 --> 00:46:50.980
Like I don't care about how pip works


00:46:50.980 --> 00:46:52.640
or like how I pip install.


00:46:52.640 --> 00:46:55.020
Like I don't want to worry about like virtual environments


00:46:55.020 --> 00:46:55.940
and things like that.


00:46:55.940 --> 00:46:57.680
Whereas a person who is writing internal tools,


00:46:57.680 --> 00:47:00.580
they want to own the entire tool chain.


00:47:00.580 --> 00:47:03.780
It's like, I not only want to maintain virtual environment,


00:47:03.780 --> 00:47:07.980
I also want this thing to work with a front-end that is written in React.


00:47:07.980 --> 00:47:10.440
And so I would like you to be able to make it possible


00:47:10.440 --> 00:47:14.880
to do NPM and pip to coexist and live together.


00:47:14.880 --> 00:47:17.840
That's not a hard thing to do, but it's one of those things


00:47:17.840 --> 00:47:20.280
where it's like, if I'm trying to solve a problem,


00:47:20.280 --> 00:47:23.140
let's say I'm bringing in Python dependency locking


00:47:23.140 --> 00:47:25.940
as a mechanism to help these web developers,


00:47:26.020 --> 00:47:28.460
because they don't want to automatically upgrade


00:47:28.460 --> 00:47:29.960
any time they build their system


00:47:29.960 --> 00:47:32.160
and suddenly break in production.


00:47:32.160 --> 00:47:34.560
Now, that might be completely useless


00:47:34.560 --> 00:47:36.560
for someone who's working in machine learning.


00:47:36.560 --> 00:47:38.920
And so they're like, "Why are you solving that problem?


00:47:38.920 --> 00:47:42.460
"This, you bringing locking to packaging


00:47:42.460 --> 00:47:43.560
"doesn't help me in any way.


00:47:43.560 --> 00:47:44.760
"Why are you wasting your time?"


00:47:44.760 --> 00:47:47.520
And so we had to sort of build personas


00:47:47.520 --> 00:47:50.920
for various ways in which Python is used inside of Netflix


00:47:50.920 --> 00:47:53.020
so that when we are working on a particular feature,


00:47:53.020 --> 00:47:55.420
we can tell them, "We are now targeting this persona.


00:47:55.420 --> 00:47:59.020
We are working towards making life easy for animation engineers.


00:47:59.020 --> 00:48:01.520
So if it doesn't work for you, that's fine.


00:48:01.520 --> 00:48:03.420
You know, that's fine. We will get to you.


00:48:03.420 --> 00:48:06.420
It's just that our persona that we're targeting right now is not yours.


00:48:06.420 --> 00:48:08.920
So that's how it's different, I'd say.


00:48:08.920 --> 00:48:10.020
Yeah.


00:48:10.020 --> 00:48:14.620
Data scientists have a lot less legacy code that's just still cranking along


00:48:14.620 --> 00:48:17.420
because a lot of times once they get, they discover an insight,


00:48:17.420 --> 00:48:18.920
they don't need to run it again, right?


00:48:18.920 --> 00:48:21.420
Or the algorithms are changing so fast, they can just,


00:48:21.420 --> 00:48:26.140
Well, now we're using L large language models instead of whatever, you know?


00:48:26.140 --> 00:48:27.420
Yeah. There you go. Yeah.


00:48:27.420 --> 00:48:32.740
Yeah. Whereas once you get a web app running, you might not touch that thing if it doesn't need touching. Right.


00:48:32.740 --> 00:48:36.420
So you just exactly stability is what you need there.


00:48:36.420 --> 00:48:40.500
So anything else you want to call out out of this article before we move on?


00:48:40.500 --> 00:48:42.900
We don't have time left, honestly, but


00:48:42.900 --> 00:48:48.460
No, no, I think this was a great article, but yeah, a few things.


00:48:48.460 --> 00:49:03.060
But with regard to this, let's just leave people with this idea that we only touched on a small part of what is laid out here and all the projects and all the ways in which it's being used. So certainly check out the article just called Python at Netflix. It'll put in the show notes.


00:49:03.060 --> 00:49:05.860
It's hard to cover it all in just one hour.


00:49:05.860 --> 00:49:15.060
It sure is. It sure is. So let's maybe talk for a minute here about this project that you're involved with Soren called Portable Python.


00:49:15.060 --> 00:49:20.660
You know, I not long ago had Nathaniel Smith on to talk about PEP 711,


00:49:20.660 --> 00:49:27.300
distributing Python binaries and maybe treating like CPython runtimes as wheels almost.


00:49:27.300 --> 00:49:34.180
And you guys also have a way that you've been using for a while internally to package up Python


00:49:34.180 --> 00:49:37.540
into something that can run as well called portable Python, which is open source.


00:49:37.540 --> 00:49:38.820
You want to talk a bit about that?


00:49:38.820 --> 00:49:41.860
Yes, that is indeed PEP 711.


00:49:41.860 --> 00:49:44.580
I discovered it by listening to your podcast.


00:49:44.580 --> 00:49:50.580
Right around Python, I think, yes, it would be very interesting to see if we could partner up once this is.


00:49:50.580 --> 00:49:57.220
So Portable Python is, we want to provide Python, of course, to all Python developers inside, right?


00:49:57.220 --> 00:50:01.060
Like you can always grab your own Python via all kinds of ways, right?


00:50:01.060 --> 00:50:03.380
PyEnv, Docker image, et cetera.


00:50:03.380 --> 00:50:08.180
But we also provide builds of Python inside to be used internally.


00:50:08.180 --> 00:50:11.300
So Portable Python is trying to solve just that.


00:50:11.300 --> 00:50:16.180
Well, one particular issue, how do you go and distribute Python on laptops?


00:50:16.180 --> 00:50:20.340
So the end goal is we want to provide a tarball,


00:50:20.340 --> 00:50:23.780
just like that Pep says, like a wheel,


00:50:23.780 --> 00:50:27.540
a tarball that you can download and drop somewhere,


00:50:27.540 --> 00:50:32.980
typically in a user's own folder, tilde slash, you know, myPythons,


00:50:32.980 --> 00:50:34.980
and we want it to work from there.


00:50:34.980 --> 00:50:39.300
So you could use PyEnv for that, but with PyEnv, you need to wait for it to build.


00:50:39.300 --> 00:50:46.460
And we want to basically build it ahead of time and as soon as it's available and, you know, make it available internally.


00:50:46.460 --> 00:50:51.460
So what Portable Python is designed to do is to do such a build, which we call portable,


00:50:51.460 --> 00:50:58.340
and drop it in our factory and then our tooling can just go fetch that real quick, unzip, and it's ready to go.


00:50:58.340 --> 00:51:03.820
So your tooling, the Portable Python tooling basically says I'm on this platform.


00:51:03.820 --> 00:51:06.820
So I'm on macOS and it's Apple Silicon.


00:51:06.820 --> 00:51:09.740
So here's the, and they want this version of Python.


00:51:09.740 --> 00:51:12.500
So that means this binary, let's go grab it.


00:51:12.500 --> 00:51:12.980
Right.


00:51:12.980 --> 00:51:13.460
Right.


00:51:13.460 --> 00:51:16.780
So portable Python is invoked by our building machinery.


00:51:16.780 --> 00:51:25.180
There is a one worker on macOS, x86, macOS M1, Linux, x86, Linux, ARM 64.


00:51:25.180 --> 00:51:30.500
And there's some external internal tooling that kind of detects that the new open


00:51:30.500 --> 00:51:33.300
source version is available using portable Python.


00:51:33.300 --> 00:51:38.340
So Portable Python can report you what is the latest, 3.11, for example,


00:51:38.340 --> 00:51:41.440
by looking at the ftp.python.org, basically.


00:51:41.440 --> 00:51:43.680
Okay, so the latest is 3.11.3.


00:51:43.680 --> 00:51:45.540
Let's see, do we have it internally? No.


00:51:45.540 --> 00:51:46.740
Okay, let's kick off a build.


00:51:46.740 --> 00:51:51.720
So we kick off one build for M1, one build for Linux, etc.


00:51:51.720 --> 00:51:55.520
And with Portable Python, with its configuration,


00:51:55.520 --> 00:51:59.460
we say we want OpenSSL, that version, we want SQLite, that version,


00:51:59.460 --> 00:52:03.200
and Portable Python goes ahead and does the build, produces a tarball,


00:52:03.200 --> 00:52:05.480
We take that more and publish it.


00:52:05.480 --> 00:52:06.440
That's interesting.


00:52:06.440 --> 00:52:09.700
So you can control a little bit, some of the internals as well, like the open


00:52:09.700 --> 00:52:13.040
SSL version and SQLite version, maybe a bit more carefully.


00:52:13.040 --> 00:52:13.520
Yes.


00:52:13.520 --> 00:52:13.760
Yes.


00:52:13.760 --> 00:52:18.560
And since it's written in Python, then we met like, it's able to also inspect,


00:52:18.560 --> 00:52:23.320
say, any Python, like you could run portable Python, inspect path to this


00:52:23.320 --> 00:52:27.280
installation and it will tell you, okay, it has a sound, that version SQLite,


00:52:27.280 --> 00:52:32.520
that version it does it use like homebrew a library of shared libraries or, or what.


00:52:32.840 --> 00:52:34.600
it can report on that.


00:52:34.600 --> 00:52:38.680
And, oh yeah, it generates a thing that I find very important,


00:52:38.680 --> 00:52:40.680
like a little file that says,


00:52:40.680 --> 00:52:42.280
it's called manifest.yaml.


00:52:42.280 --> 00:52:44.120
So every time it builds anything,


00:52:44.120 --> 00:52:47.680
it generates that manifest.yaml where it says,


00:52:47.680 --> 00:52:51.760
well, I did a build with --LTO optimization--


00:52:51.760 --> 00:52:54.240
like it says everything that was used


00:52:54.240 --> 00:52:56.360
to inform what the build had,


00:52:56.360 --> 00:52:59.320
and which worker it ran on, what time,


00:52:59.320 --> 00:53:00.720
what was the platform,


00:53:00.720 --> 00:53:02.280
like a little bit of metadata,


00:53:02.280 --> 00:53:06.300
which sometimes you could even see things like what C compiler optimization


00:53:06.300 --> 00:53:08.760
flags were enabled when you created it, for example, right?


00:53:08.760 --> 00:53:09.640
Yes.


00:53:09.640 --> 00:53:09.920
Okay.


00:53:09.920 --> 00:53:11.640
And there is one additional thing.


00:53:11.640 --> 00:53:15.240
So portable Python does not install Python on your system for you.


00:53:15.240 --> 00:53:19.960
So it, it is a builder, so it builds them and produces tarballs that


00:53:19.960 --> 00:53:21.560
can be used in a standalone manner.


00:53:21.560 --> 00:53:25.520
And so if you want to bring Python onto your system, you just download the


00:53:25.520 --> 00:53:29.720
tarball from our internal artifact storage and then expand it.


00:53:29.720 --> 00:53:32.240
And that we have another tool that automatically does that.


00:53:32.240 --> 00:53:36.860
And so when somebody bootstraps a brand new Python project and they say, I would


00:53:36.860 --> 00:53:42.580
like to use 3.11.3, which 3.11.4, I think that got released yesterday, then we will


00:53:42.580 --> 00:53:46.780
already have a binary ready for them that is in the artifactory, in our internal


00:53:46.780 --> 00:53:47.420
artifactory.


00:53:47.420 --> 00:53:51.640
And when they run their build for the very first time, it will bring the


00:53:51.640 --> 00:53:55.780
appropriate Python version that they have specified in either pyproject.toml or in


00:53:55.780 --> 00:53:57.500
their talks.ini or somewhere.


00:53:57.700 --> 00:53:59.960
and it will bring that appropriate Python,


00:53:59.960 --> 00:54:02.360
install it or expand it in a known location,


00:54:02.360 --> 00:54:05.200
and it will use that for building their project and so forth.


00:54:05.200 --> 00:54:08.200
So it's a way to make it easy for people


00:54:08.200 --> 00:54:12.100
to not have to manage their Python on their laptop individually.


00:54:12.100 --> 00:54:16.000
And also, this can build Python with a specific prefix.


00:54:16.000 --> 00:54:18.960
So on servers, on our internal servers,


00:54:18.960 --> 00:54:21.960
what we do is we install Python in a specific location.


00:54:21.960 --> 00:54:26.200
Like, we always put it inside, let's say, for example, /app/python, for example.


00:54:26.200 --> 00:54:29.800
it will build it in a way that it makes it easy for Debian to be built.


00:54:29.800 --> 00:54:33.700
And when you install the Debian, it will put the Python in a specific location.


00:54:33.700 --> 00:54:39.240
And also, it has other benefits, such as it tries to make the Python binary


00:54:39.240 --> 00:54:40.740
as small as possible,


00:54:40.740 --> 00:54:45.800
because we're trying to deploy it out to like hundreds of thousands or 100,000 servers.


00:54:45.800 --> 00:54:50.100
So we would try to reduce the amount that we need to put on that server.


00:54:50.100 --> 00:54:53.640
It does that, the final product that Zorin checked yesterday,


00:54:53.640 --> 00:54:57.080
I believe it was only 50 megabytes compared to what other like


00:54:57.080 --> 00:55:00.040
PI and other things are producing, which was 200 megabytes.


00:55:00.040 --> 00:55:03.200
It does it by a few tricks, like it removes the test folder,


00:55:03.200 --> 00:55:05.600
because, you know, once you have built it, like, you know, having


00:55:05.600 --> 00:55:08.120
the test folder as part of your final artifact makes no sense.


00:55:08.120 --> 00:55:10.320
That was like a hundred megabytes savings right there.


00:55:10.320 --> 00:55:14.920
So things like that, some optimizations that we do that is custom for our work.


00:55:14.920 --> 00:55:16.720
Yeah, that's a really interesting system.


00:55:16.720 --> 00:55:21.800
I think there's increasing momentum around having some kind of tool that is


00:55:21.840 --> 00:55:25.400
outside of Python for managing Python, right?


00:55:25.400 --> 00:55:29.600
So far, primarily what we've had is things like Pip, PipX,


00:55:29.600 --> 00:55:31.560
so when you have a project called Piccoli,


00:55:31.560 --> 00:55:33.920
it's all about like, okay, you have Python,


00:55:33.920 --> 00:55:35.240
now how do you go forward?


00:55:35.240 --> 00:55:37.440
But I think a lot of people are realizing like,


00:55:37.440 --> 00:55:39.960
wait, that assumption that I have Python, now what?


00:55:39.960 --> 00:55:41.760
Is not a great assumption, right?


00:55:41.760 --> 00:55:44.540
And so people are starting to look at tools like RustUp,


00:55:44.540 --> 00:55:46.160
which actually is kind of like Pip,


00:55:46.160 --> 00:55:48.520
but it brings Rust also over.


00:55:48.520 --> 00:55:50.600
Yeah, so we're gonna see something there, I think.


00:55:50.600 --> 00:55:52.360
I don't know what it is, but it'll be interesting.


00:55:52.360 --> 00:55:54.360
Yeah. Did you see the one Rai?


00:55:54.360 --> 00:55:57.720
Rai is the package manager that Armin wrote.


00:55:57.720 --> 00:56:00.040
Yeah, from Armin Roenicker.


00:56:00.040 --> 00:56:00.360
Yeah.


00:56:00.360 --> 00:56:02.520
He, that brings Python for you.


00:56:02.520 --> 00:56:05.640
That he, his inspiration is from Rust up apparently.


00:56:05.640 --> 00:56:07.960
So Rai is actually written in Rust.


00:56:07.960 --> 00:56:12.440
And it does all the things that Poetry and PDM and other package managers does.


00:56:12.440 --> 00:56:15.320
But in addition to that, it also brings Python for you.


00:56:15.320 --> 00:56:19.080
And it's using a different Python called standalone Python


00:56:19.080 --> 00:56:21.580
or something that you already had a link for, I forgot,


00:56:21.580 --> 00:56:25.480
but it brings Python from there to expand it into your system.


00:56:25.480 --> 00:56:28.480
Yeah, Python build standalone, that's the project that it uses.


00:56:28.480 --> 00:56:31.580
Yeah, I've heard of that. I haven't done anything with it, but it looks interesting.


00:56:31.580 --> 00:56:32.080
Yeah.


00:56:32.080 --> 00:56:34.180
All right, I think we have time. We're getting short on time here.


00:56:34.180 --> 00:56:36.480
I think we have time for one more really quick thing,


00:56:36.480 --> 00:56:39.680
something that you're participating in, Amjith.


00:56:39.680 --> 00:56:41.280
I'm sure, and I don't know if you are as well,


00:56:41.280 --> 00:56:45.680
but command line database clients with autocomplete and syntax highlighting.


00:56:45.680 --> 00:56:47.880
Tell us about this. This looks cool.


00:56:47.880 --> 00:56:51.200
Yeah, this is just my personal project that I wrote before.


00:56:51.200 --> 00:56:57.000
This was a while back, but the idea is at the time I was trying to learn Postgres and I


00:56:57.000 --> 00:57:01.280
didn't know how to do like, I was, I was learning Postgres and I was using PSQL to do


00:57:01.280 --> 00:57:01.540
this.


00:57:01.540 --> 00:57:05.880
And every time I, I come to like a table, I'd be like, you know, Oh, what columns were


00:57:05.880 --> 00:57:06.100
there?


00:57:06.100 --> 00:57:10.000
I forgot the exact name of the column and I tried to find it and so forth.


00:57:10.000 --> 00:57:15.320
And so finally, you know, I just, I broke down and decided to write like a shell for,


00:57:15.520 --> 00:57:19.060
for Postgres called PGCLI that uses actually from toolkit,


00:57:19.060 --> 00:57:21.900
like the same toolkit that's used by PT Python.


00:57:21.900 --> 00:57:24.220
- I was going to say, it looks a lot like PT Python.


00:57:24.220 --> 00:57:25.760
It's got that Emacs mode.


00:57:25.760 --> 00:57:26.600
- Yep.


00:57:26.600 --> 00:57:28.360
- You've got autocomplete for basically


00:57:28.360 --> 00:57:31.860
the whole SQL language, but also the database schema


00:57:31.860 --> 00:57:32.860
that you're connected to, right?


00:57:32.860 --> 00:57:33.720
- Yes, that is correct.


00:57:33.720 --> 00:57:36.820
So it reads the tables and the columns in that database,


00:57:36.820 --> 00:57:38.060
and then it tries to autocomplete


00:57:38.060 --> 00:57:39.860
as part of the SQL segment.


00:57:39.860 --> 00:57:42.920
So after a WHERE clause, it'll only suggest columns,


00:57:42.920 --> 00:57:45.600
And after a from clause, it'll only suggest tables and so on.


00:57:45.600 --> 00:57:46.120
Wow.


00:57:46.120 --> 00:57:50.400
So after PGCLI, people wanted something for MySQL.


00:57:50.400 --> 00:57:55.160
So I created MyCLI and then Microsoft came over and said, like, we would like to fork


00:57:55.160 --> 00:57:58.760
PGCLI to make one for Microsoft's MS SQL server.


00:57:58.760 --> 00:58:00.440
So they did that themselves.


00:58:00.440 --> 00:58:03.760
Like we didn't, so they, they took PGCLI source code and then they created that.


00:58:03.760 --> 00:58:07.640
And then I, another person created light CLI, which is for SQLite.


00:58:07.640 --> 00:58:08.520
And yeah.


00:58:08.520 --> 00:58:09.960
And there's other things now.


00:58:09.960 --> 00:58:13.240
I-Redis is like for a Redis client that's similar to these things,


00:58:13.240 --> 00:58:17.500
but there's a lot more, like more friendlier shells for databases in general.


00:58:17.500 --> 00:58:18.240
- Excellent.


00:58:18.240 --> 00:58:20.080
All right, this looks really cool, I think.


00:58:20.080 --> 00:58:22.240
- Yeah, this has got nothing to do with Netflix.


00:58:22.240 --> 00:58:24.960
It's mostly just like, hey, it's my personal project,


00:58:24.960 --> 00:58:28.380
and, you know, just what I do in my free time sort of a thing.


00:58:28.380 --> 00:58:28.920
- Yeah.


00:58:28.920 --> 00:58:31.180
Well, it looks really helpful for people


00:58:31.180 --> 00:58:34.880
because talking to databases just in your terminal,


00:58:34.880 --> 00:58:35.800
it can be tricky, right?


00:58:35.800 --> 00:58:36.840
And having auto-complete,


00:58:36.840 --> 00:58:41.120
especially not so much, you know, the select and where people get that pretty


00:58:41.120 --> 00:58:44.740
quick, but the database schema understanding keeps you in your flow


00:58:44.740 --> 00:58:45.260
pretty well.


00:58:45.260 --> 00:58:45.580
Right.


00:58:45.580 --> 00:58:45.960
Yeah.


00:58:45.960 --> 00:58:49.160
Again, inspired by B Python actually took inspiration from them.


00:58:49.160 --> 00:58:49.680
Yeah.


00:58:49.680 --> 00:58:50.180
Excellent.


00:58:50.180 --> 00:58:50.760
All right.


00:58:50.760 --> 00:58:52.280
Well, that'll be in the show notes as well.


00:58:52.280 --> 00:58:55.080
Guys, I think that is it for time that we have today.


00:58:55.080 --> 00:58:59.200
So I'm going to have to wrap it up with the final two questions here and


00:58:59.200 --> 00:58:59.960
recommendations.


00:58:59.960 --> 00:59:02.680
Let's start with a PyPI project.


00:59:02.680 --> 00:59:05.220
Not necessarily the most popular one, but something that you're like, Oh,


00:59:05.220 --> 00:59:05.820
this is awesome.


00:59:05.820 --> 00:59:06.720
People should know about it.


00:59:06.720 --> 00:59:08.720
Soren, got a recommendation for folks?


00:59:08.720 --> 00:59:11.040
I'm going to say PICLI, go check out PICLI.


00:59:11.040 --> 00:59:14.560
PICLI, okay, so give us the elevator pitch on PICLI.


00:59:14.560 --> 00:59:18.800
It's a CLI tool that allows you to install other CLI tools,


00:59:18.800 --> 00:59:21.120
very similar to PIPX in that sense.


00:59:21.120 --> 00:59:25.120
The main difference is being that if you PICLI install Poetry,


00:59:25.120 --> 00:59:29.120
every time you run Poetry, it will keep itself up to date in the background.


00:59:29.120 --> 00:59:32.000
So it will keep self-upgrading by default.


00:59:32.000 --> 00:59:35.760
You can tell it also not to do that, but that's its main useful thing.


00:59:35.760 --> 00:59:40.480
- Cool, so when you launch it, basically you're launching like a shim that says,


00:59:40.480 --> 00:59:43.360
"Run this," and then the background check for update, and when it exits,


00:59:43.360 --> 00:59:44.720
if there's an update, just update it.


00:59:44.720 --> 00:59:47.200
- Yes, you can take a look at the little shell script,


00:59:47.200 --> 00:59:49.200
shell wrapper that it wraps it with.


00:59:49.200 --> 00:59:49.680
- Yes.


00:59:49.680 --> 00:59:50.880
- All right, Pickly, awesome.


00:59:50.880 --> 00:59:51.360
Amjith?


00:59:51.360 --> 00:59:54.320
- Oh, I guess I could plug again for BPython.


00:59:54.320 --> 00:59:57.360
Like good design aesthetics, I think, yeah,


00:59:57.360 --> 00:59:59.520
it's an overall better shell than Python shell.


00:59:59.520 --> 00:59:59.760
- Yeah.


00:59:59.760 --> 01:00:03.840
- Oh, actually, PDB++, that's the one that I would actually recommend.


01:00:03.840 --> 01:00:07.840
So if you ever use PDB, and you wish that PDB had auto-completion,


01:00:07.840 --> 01:00:10.740
PDB, it's PDB PP in PyPy.


01:00:10.740 --> 01:00:13.340
You don't have to change your thing at all.


01:00:13.340 --> 01:00:15.740
All you have to do is pip install PDB PP,


01:00:15.740 --> 01:00:18.040
and then any time you do a breakpoint,


01:00:18.040 --> 01:00:19.640
and it stops you there,


01:00:19.640 --> 01:00:22.140
you can do like, you know, variable dot,


01:00:22.140 --> 01:00:23.540
and it'll give you auto-completion.


01:00:23.540 --> 01:00:26.040
And yeah, I don't know, I'm a huge fan of auto-completion.


01:00:26.040 --> 01:00:29.240
Yeah, I was gonna say, you and I are kindred spirits.


01:00:29.240 --> 01:00:31.240
I am all about the auto-completion.


01:00:31.240 --> 01:00:33.920
I'm like, this tool is broken if it doesn't give me auto-complete.


01:00:33.920 --> 01:00:39.720
Because it sends you into the documentation, you'll be like, Oh, I need to create one of these, client libraries.


01:00:39.720 --> 01:00:40.300
What does it take?


01:00:40.300 --> 01:00:42.340
Oh, star org, star star KW orgs.


01:00:42.340 --> 01:00:42.760
Great.


01:00:42.760 --> 01:00:43.900
Now what am I supposed to do?


01:00:43.900 --> 01:00:44.160
Right?


01:00:44.160 --> 01:00:49.320
Like, you know, the auto-complete it, it really makes you more productive.


01:00:49.320 --> 01:00:49.620
All right.


01:00:49.620 --> 01:00:55.000
And then, if you're gonna write some Python code, what editor, if you're not in the ripple, are you using?


01:00:55.000 --> 01:00:56.800
Oh, for me, it's a PyCharm.


01:00:57.040 --> 01:01:02.640
Python, mostly, Sublime Text, and VI if I'm messaging somewhere.


01:01:02.640 --> 01:01:04.040
Excellent. And Amjit?


01:01:04.040 --> 01:01:05.440
Vim all the way.


01:01:05.440 --> 01:01:08.540
You know, even if I don't know how to quit it, I can restart my computer.


01:01:08.540 --> 01:01:11.540
[laughter]


01:01:11.540 --> 01:01:16.040
That is the source of, the endless source of jokes, you know, like,


01:01:16.040 --> 01:01:20.440
I saw some laptop, a picture of a laptop, and it was just smashed to pieces.


01:01:20.440 --> 01:01:22.540
And it said, "Finally figured out how to quit Vim."


01:01:22.540 --> 01:01:25.040
[laughter]


01:01:25.040 --> 01:01:30.960
>> For the longest time, actually, I had colon Q as a way to quit out of PGCLI because I,


01:01:30.960 --> 01:01:34.360
by instinct, just kept hitting colon Q and, yeah.


01:01:34.360 --> 01:01:35.360
>> That's amazing.


01:01:35.360 --> 01:01:36.840
All right, you guys.


01:01:36.840 --> 01:01:39.560
Well, it's been great to have you on the show.


01:01:39.560 --> 01:01:40.640
Thanks for being here.


01:01:40.640 --> 01:01:44.440
Thanks for giving us this look at what you're all doing up over at Netflix and in your personal


01:01:44.440 --> 01:01:45.440
projects.


01:01:45.440 --> 01:01:46.440
>> Yeah, thank you, Michael.


01:01:46.440 --> 01:01:51.040
I just would like to mention that we have a lot of jobs at Netflix that require Python.


01:01:51.040 --> 01:01:55.600
So if you are at all interested, please go to jobs.netflix.com and type in Python and


01:01:55.600 --> 01:01:58.920
you should get all of the Python job openings that are available.


01:01:58.920 --> 01:01:59.920
There's a wide variety.


01:01:59.920 --> 01:02:02.080
If you want to do infrastructures up, there's that.


01:02:02.080 --> 01:02:04.360
If you want to do data science, there's that, right?


01:02:04.360 --> 01:02:05.360
Like a lot of coolers.


01:02:05.360 --> 01:02:06.360
Yes, absolutely.


01:02:06.360 --> 01:02:07.360
All right.


01:02:07.360 --> 01:02:08.360
Have a great day, guys.


01:02:08.360 --> 01:02:09.360
Thank you.


01:02:09.360 --> 01:02:10.360
Bye.


01:02:10.360 --> 01:02:11.360
Bye.


01:02:11.360 --> 01:02:14.840
This has been another episode of Talk Python to Me.


01:02:14.840 --> 01:02:15.840
Thank you to our sponsors.


01:02:15.840 --> 01:02:17.560
Be sure to check out what they're offering.


01:02:17.560 --> 01:02:20.040
It really helps support the show.


01:02:20.040 --> 01:02:24.600
The folks over at JetBrains encourage you to get work done with PyCharm.


01:02:24.600 --> 01:02:30.320
PyCharm Professional understands complex projects across multiple languages and technologies,


01:02:30.320 --> 01:02:36.080
so you can stay productive while you're writing Python code and other code like HTML or SQL.


01:02:36.080 --> 01:02:41.840
Download your free trial at talkpython.fm/donewithpycharm.


01:02:41.840 --> 01:02:45.000
Influx data encourages you to try InfluxDB.


01:02:45.000 --> 01:02:50.800
InfluxDB is a database purpose-built for handling time series data at a massive scale for real-time


01:02:50.800 --> 01:02:51.800
analytics.


01:02:51.800 --> 01:02:53.300
Try it for free at talkpython.fm/influxdb.


01:02:53.300 --> 01:02:57.260
Want to level up your Python?


01:02:57.260 --> 01:03:01.360
We have one of the largest catalogs of Python video courses over at Talk Python.


01:03:01.360 --> 01:03:06.460
Our content ranges from true beginners to deeply advanced topics like memory and async.


01:03:06.460 --> 01:03:09.020
And best of all, there's not a subscription in sight.


01:03:09.020 --> 01:03:12.100
Check it out for yourself at training.talkpython.fm.


01:03:12.100 --> 01:03:13.880
Be sure to subscribe to the show.


01:03:13.880 --> 01:03:18.480
your favorite podcast app and search for Python. We should be right at the top. You can also


01:03:18.480 --> 01:03:24.320
find the iTunes feed at /itunes, the Google Play feed at /play, and the Direct RSS feed


01:03:24.320 --> 01:03:30.760
at /rss on talkpython.fm. We're live streaming most of our recordings these days. If you


01:03:30.760 --> 01:03:34.920
want to be part of the show and have your comments featured on the air, be sure to subscribe


01:03:34.920 --> 01:03:40.520
to our YouTube channel at talkpython.fm/youtube. This is your host, Michael Kennedy. Thanks


01:03:40.520 --> 01:03:42.600
so much for listening. I really appreciate it.


01:03:42.600 --> 01:03:44.480
Now, get out there and write some Python code.


01:03:44.480 --> 01:04:06.480
[MUSIC]

