WEBVTT

00:00:00.000 --> 00:00:03.840
By now, surely you've heard how awesome Pydantic version 2 is.


00:00:03.840 --> 00:00:07.720
The team led by Simuil Kolvin spent almost a year refactoring and reworking the core


00:00:07.720 --> 00:00:12.640
into a high-performance Rust version while keeping the public API in Python and largely


00:00:12.640 --> 00:00:13.640
unchanged.


00:00:13.640 --> 00:00:18.320
The main benefit of this has been massive speedups for the frameworks and devs using


00:00:18.320 --> 00:00:19.680
Pydantic.


00:00:19.680 --> 00:00:25.600
But just how much work is it to take a framework deeply built on Pydantic and make that migration?


00:00:25.600 --> 00:00:26.800
And what are some of the pitfalls?


00:00:26.800 --> 00:00:31.480
On this episode, we welcome back Roman Wright to talk about his experience converting Beanie,


00:00:31.480 --> 00:00:37.180
the popular MongoDB async framework based on Pydantic, from Pydantic 1 to 2.


00:00:37.180 --> 00:00:40.200
And we'll have some fun talking about MongoDB while we're at it.


00:00:40.200 --> 00:00:45.280
This is Talk Python to Me, episode 432, recorded August 16th, 2023.


00:00:45.280 --> 00:00:58.280
[Music]


00:00:58.280 --> 00:01:01.780
Welcome to Talk Python To Me, a weekly podcast on Python.


00:01:01.780 --> 00:01:03.640
This is your host, Michael Kennedy.


00:01:03.640 --> 00:01:08.520
Follow me on Mastodon, where I'm @mkennedy, and follow the podcast using @talkpython,


00:01:08.520 --> 00:01:10.820
both on fosstodon.org.


00:01:10.820 --> 00:01:13.560
Be careful with impersonating accounts on other instances.


00:01:13.560 --> 00:01:14.560
There are many.


00:01:14.560 --> 00:01:20.160
Keep up with the show and listen to over seven years of past episodes at talkpython.fm.


00:01:20.160 --> 00:01:23.920
We've started streaming most of our episodes live on YouTube.


00:01:23.920 --> 00:01:29.760
Subscribe to our YouTube channel over at talkpython.fm/youtube to get notified about upcoming shows and be


00:01:29.760 --> 00:01:32.000
part of that episode.


00:01:32.000 --> 00:01:35.760
This episode is brought to you by Studio 3T.


00:01:35.760 --> 00:01:40.380
Studio 3T is the IDE that gives you full visual control of your MongoDB data.


00:01:40.380 --> 00:01:45.100
With the drag and drop visual query builder and multi-language query code generator, new


00:01:45.100 --> 00:01:47.860
users will find they're up to speed in no time.


00:01:47.860 --> 00:01:54.120
Try Studio 3T for free at talkpython.fm/studio2023.


00:01:54.120 --> 00:01:57.380
And it's brought to you by us over at Talk Python Training.


00:01:57.380 --> 00:02:01.180
Did you know we have over 250 hours of Python courses?


00:02:01.180 --> 00:02:04.220
And we have special offers for teams as well.


00:02:04.220 --> 00:02:06.300
Check us out over at talkpython.fm/courses.


00:02:06.300 --> 00:02:11.300
Roman, welcome back to Talk Python to Me.


00:02:11.300 --> 00:02:12.300
Hi.


00:02:12.300 --> 00:02:14.020
Hey, so good to have you back on the show.


00:02:14.020 --> 00:02:15.020
Good to see you again.


00:02:15.020 --> 00:02:16.020
Yeah, you as well.


00:02:16.020 --> 00:02:17.020
Thank you.


00:02:17.020 --> 00:02:18.020
How have you been?


00:02:18.020 --> 00:02:24.140
So it was a nice adventure for me, like these two years of building Python projects, of


00:02:24.140 --> 00:02:25.820
moving to other countries.


00:02:25.820 --> 00:02:26.820
So yeah.


00:02:26.820 --> 00:02:27.820
Are you up for sharing that with people?


00:02:27.820 --> 00:02:28.820
What you're up to?


00:02:28.820 --> 00:02:29.820
Sorry?


00:02:29.820 --> 00:02:30.820
Are you up for sharing where you've moved to?


00:02:30.820 --> 00:02:33.020
When last time we spoke, you were in Berlin, I believe.


00:02:33.020 --> 00:02:34.420
I was in Germany.


00:02:34.420 --> 00:02:35.420
And now I'm in Africa.


00:02:35.420 --> 00:02:36.260
- Africa.


00:02:36.260 --> 00:02:37.540
(laughing)


00:02:37.540 --> 00:02:38.380
- So completely different country.


00:02:38.380 --> 00:02:39.220
- Somewhere new?


00:02:39.220 --> 00:02:40.980
- Completely different continent.


00:02:40.980 --> 00:02:42.420
- Yeah, are you enjoying your time there?


00:02:42.420 --> 00:02:45.060
- Yeah, so I like it so much.


00:02:45.060 --> 00:02:46.900
Honestly, I like Germany too.


00:02:46.900 --> 00:02:48.860
So Germany is a great country,


00:02:48.860 --> 00:02:50.860
but I like different things.


00:02:50.860 --> 00:02:52.420
- Yeah, but you're probably looking forward


00:02:52.420 --> 00:02:54.140
to not freezing cold winters.


00:02:54.140 --> 00:02:55.500
- I want to try, honestly.


00:02:55.500 --> 00:02:57.300
I don't know if I will like it or not,


00:02:57.300 --> 00:03:00.740
but I want to try it in just a few years, for example.


00:03:00.740 --> 00:03:04.660
- I moved to San Diego, California a long time ago.


00:03:04.660 --> 00:03:08.020
I didn't really enjoy the fact that there was no winters


00:03:08.020 --> 00:03:08.860
and there was no fall.


00:03:08.860 --> 00:03:11.180
It was just always nice, always.


00:03:11.180 --> 00:03:13.260
Until one day I realized, you know what?


00:03:13.260 --> 00:03:15.800
We just headed out mountain biking in the mountains


00:03:15.800 --> 00:03:18.180
and the weather was perfect and it was February


00:03:18.180 --> 00:03:21.100
and we didn't even check if it was gonna rain or be nice


00:03:21.100 --> 00:03:22.020
'cause it's always nice.


00:03:22.020 --> 00:03:22.860
You know what?


00:03:22.860 --> 00:03:24.220
That's a good trade-off.


00:03:24.220 --> 00:03:25.460
You could do a lot of cool stuff


00:03:25.460 --> 00:03:26.420
when you live in a place like that.


00:03:26.420 --> 00:03:29.260
So I'm glad to hear that.


00:03:29.260 --> 00:03:30.940
You'll have to let us know how it goes.


00:03:30.940 --> 00:03:35.640
And Beanie has been going really well as well, right?


00:03:35.640 --> 00:03:37.320
So when we first spoke,


00:03:37.320 --> 00:03:39.920
Beanie was just kind of a new project.


00:03:39.920 --> 00:03:42.820
And the thing that caught my eye about it


00:03:42.820 --> 00:03:47.020
was two really cool aspects, asynchronous and Pydantic.


00:03:47.020 --> 00:03:48.320
I'm like, oh, those things together,


00:03:48.320 --> 00:03:50.440
plus MongoDB sound pretty awesome.


00:03:50.440 --> 00:03:52.520
And so it's been really fun to watch it grow


00:03:52.520 --> 00:03:53.480
over the last two years


00:03:53.480 --> 00:03:55.440
and it's gaining quite a bit of popularity.


00:03:55.440 --> 00:03:57.220
- I don't know, it's kind of popular,


00:03:57.220 --> 00:04:00.700
but not that much as Pydantic itself as FastAPI.


00:04:00.700 --> 00:04:03.260
but yeah, still popular in context of MongoDB.


00:04:03.260 --> 00:04:04.340
- I think it's a little bit different


00:04:04.340 --> 00:04:06.500
than a web framework, potentially, right?


00:04:06.500 --> 00:04:08.340
Like it's hard to say, you know,


00:04:08.340 --> 00:04:11.020
is it as popular as FastAPI or Flask


00:04:11.020 --> 00:04:12.100
or something like that, right?


00:04:12.100 --> 00:04:14.020
Because those things, you know,


00:04:14.020 --> 00:04:16.220
those are the contexts in which this is used,


00:04:16.220 --> 00:04:17.460
but not everyone uses Mongo,


00:04:17.460 --> 00:04:20.060
not everybody cares about AsyncMongo, all that, right?


00:04:20.060 --> 00:04:22.060
There's a lot of filters down, but it's,


00:04:22.060 --> 00:04:23.560
I think you've done a really great job


00:04:23.560 --> 00:04:25.180
shepherding this project.


00:04:25.180 --> 00:04:27.460
I think you've been really responsive to people.


00:04:27.460 --> 00:04:29.860
I know I've seen the issues coming back and forth.


00:04:29.860 --> 00:04:32.180
I've seen lots of releases on it.


00:04:32.180 --> 00:04:34.900
And I guess the biggest news is around,


00:04:34.900 --> 00:04:35.740
yeah, you're welcome.


00:04:35.740 --> 00:04:38.000
I think the biggest news is around, you know,


00:04:38.000 --> 00:04:40.320
when Pydantic 2 came out,


00:04:40.320 --> 00:04:41.900
that kind of changed so many things.


00:04:41.900 --> 00:04:45.560
I mean, you know, I spoke to Sam McCulvin


00:04:45.560 --> 00:04:46.940
about his plan there.


00:04:46.940 --> 00:04:50.300
I spoke to Sebastian Ramirez from FastAPI


00:04:50.300 --> 00:04:53.780
about like what he was thinking and where that was going.


00:04:53.780 --> 00:04:56.180
And it sounded like it was not too much work


00:04:56.180 --> 00:04:57.360
for people using Pydantic,


00:04:57.360 --> 00:04:59.020
but quite a bit of work for people like you


00:04:59.020 --> 00:05:02.100
that was like deep inside of Pydantic, yeah?


00:05:02.100 --> 00:05:05.500
- Yeah, so honestly, I have a Discord channel


00:05:05.500 --> 00:05:06.980
for support Beanie users.


00:05:06.980 --> 00:05:10.100
And there I was talking with other guys,


00:05:10.100 --> 00:05:11.820
like probably, I'm sorry,


00:05:11.820 --> 00:05:14.060
but probably I will not support both versions


00:05:14.060 --> 00:05:14.900
in the same time.


00:05:14.900 --> 00:05:17.780
Maybe I will have two different branches of Beanie


00:05:17.780 --> 00:05:19.780
with v1 and v2 supporting.


00:05:19.780 --> 00:05:22.580
But finally I am ended, you know,


00:05:22.580 --> 00:05:24.420
to in a single branch.


00:05:24.420 --> 00:05:27.460
And this was very challenging, honestly, because--


00:05:27.460 --> 00:05:28.300
- Okay, interesting.


00:05:28.300 --> 00:05:30.660
I didn't realize you were going backwards


00:05:30.660 --> 00:05:32.940
in that maintainability there


00:05:32.940 --> 00:05:35.620
for the people who didn't want to move to Pydantic 2.


00:05:35.620 --> 00:05:38.340
- Yeah, there are legacy stuff.


00:05:38.340 --> 00:05:42.220
It must support new features for Pydantic V1 also,


00:05:42.220 --> 00:05:44.420
definitely, because it may be,


00:05:44.420 --> 00:05:46.660
maybe people want to move to Pydantic V2,


00:05:46.660 --> 00:05:48.860
but they could be stuck on other libraries


00:05:48.860 --> 00:05:51.060
that support only V1, for example.


00:05:51.060 --> 00:05:54.060
And it can go for a while, like months.


00:05:54.060 --> 00:05:57.220
And even for me, it took like three weeks


00:05:57.220 --> 00:05:59.380
So to make, to make it work.


00:05:59.380 --> 00:06:04.020
So just so people know, talk python.fm and Python by set up him.


00:06:04.020 --> 00:06:07.340
Both of those are based on MongoDB and Beanie.


00:06:07.340 --> 00:06:13.060
And when you came out with the new one, I saw when the release for V2 came out,


00:06:13.060 --> 00:06:15.900
like, all right, how long until Beanie supports this, you know, and I saw that


00:06:15.900 --> 00:06:18.940
you were like right on top of it and working on that was great.


00:06:18.940 --> 00:06:23.260
And then when I went to upgrade it, it was really easy, right?


00:06:23.260 --> 00:06:29.260
I use pip tools and I use pip compile to just get all the latest versions of the dependencies and update the requirements.


00:06:29.260 --> 00:06:35.260
So then I install the new one and it wouldn't run because there's not because of anything that Beanie did,


00:06:35.260 --> 00:06:37.260
but just some changes to Pydantic 2.


00:06:37.260 --> 00:06:44.260
For example, if I had a, let's say there's a database field that was URL and it was an optional string.


00:06:44.260 --> 00:06:50.260
In Pydantic 1, you could say URL colon optional bracket str, that's it.


00:06:50.260 --> 00:06:56.420
That's it. But there's no default value explicitly set. So in Pydantic 2, that's not accepted,


00:06:56.420 --> 00:07:00.660
right? It says, no, no, no. If you want it to be none by default, you have to set it to be


00:07:00.660 --> 00:07:05.460
none explicitly. So I had to go through and like find all my database documents. Basically,


00:07:05.460 --> 00:07:08.980
anytime there's an optional something, set it equal to none. And then that was it. That was


00:07:08.980 --> 00:07:13.940
the upgrade process. And now the website runs faster. Thank you. Welcome. Yeah, I meant it


00:07:13.940 --> 00:07:20.620
at a middleware, like a few classes and functions that just check if you use


00:07:20.620 --> 00:07:25.740
Pydentic V1 or Pydentic V2 and based on this, uses different kind of backends,


00:07:25.740 --> 00:07:28.460
but interface is the same for both.


00:07:28.460 --> 00:07:31.580
So I'm a unified interface inside of Mini.


00:07:31.580 --> 00:07:35.700
So, before we get too far down this conversation, give us two quick


00:07:35.700 --> 00:07:37.220
bits of background information here.


00:07:37.220 --> 00:07:39.340
First of all, why MongoDB?


00:07:39.700 --> 00:07:46.300
There's a lot of excitement around things like MySQL, but especially Postgres,


00:07:46.300 --> 00:07:49.980
relational databases, MongoDB's document database.


00:07:49.980 --> 00:07:52.900
Give us the elevator pitch. Why do you like to work with Mongo?


00:07:52.900 --> 00:07:54.800
Honestly, I like to work with all the databases.


00:07:54.800 --> 00:07:57.500
I mean, BigMap database is fun and nerd.


00:07:57.500 --> 00:07:59.900
So I like them all.


00:07:59.900 --> 00:08:02.380
But yeah, MongoDB is a document database,


00:08:02.380 --> 00:08:08.100
and it means the schema, the data schema is much more flexible than in SQL databases.


00:08:08.100 --> 00:08:10.740
because in SQL you use tables, plain tables,


00:08:10.740 --> 00:08:14.340
while in MongoDB you use actual documents,


00:08:14.340 --> 00:08:21.420
which could be nested, and the level of this nestedness could be really high.


00:08:21.420 --> 00:08:24.020
There are some trade-offs based on this.


00:08:24.020 --> 00:08:30.620
The relation system for plain tables could be implemented much simpler than for documents,


00:08:30.620 --> 00:08:35.620
because this flexi structure, it's hard to make nice relations.


00:08:35.620 --> 00:08:44.340
But I'd say it's much more useful for if you use nested data structures in your applications,


00:08:44.340 --> 00:08:49.300
it's much simpler to keep this same data structure in your database.


00:08:49.300 --> 00:08:57.220
And this makes all the processes of development much more easy and more simple to understand it, I'd say.


00:08:57.220 --> 00:09:02.420
You don't have the so-called object relational impedance mismatch, where it's like,


00:09:02.420 --> 00:09:07.020
Well, you break it all apart like this in the database and you reassemble it into an object hierarchy over here


00:09:07.020 --> 00:09:10.660
and then you do it again in the other way and like all that stuff.


00:09:10.660 --> 00:09:12.220
It's kind of just mirrored the same, right?


00:09:12.220 --> 00:09:16.620
True. And I really like MongoDB to make like small projects.


00:09:16.620 --> 00:09:21.620
I mean, when I just want to play with something and I play with data structures a lot


00:09:21.620 --> 00:09:26.060
and using Postgres or MySQL, I have to do a lot of migrations


00:09:26.060 --> 00:09:30.700
because, you know, when I change the type of field or just number of fields,


00:09:30.700 --> 00:09:35.500
I have to do this stuff and this kind of annoying because I just want to make fun and to play.


00:09:35.500 --> 00:09:37.220
Yes, exactly.


00:09:37.220 --> 00:09:38.220
Exactly.


00:09:38.220 --> 00:09:41.420
For me, it's easy to make MongoDB fast.


00:09:41.420 --> 00:09:45.140
And it's operationally almost trivial, right?


00:09:45.140 --> 00:09:50.380
If I want to add a field to some collection, I just add it to the class and start using


00:09:50.380 --> 00:09:51.380
it.


00:09:51.380 --> 00:09:54.340
And it just, it appears, you know, it just shows up and you want adding nested object,


00:09:54.340 --> 00:09:55.340
use addit.


00:09:55.340 --> 00:09:58.660
And it just, you don't have to keep running migrations and having server downtime and


00:09:58.660 --> 00:09:59.660
all that.


00:09:59.660 --> 00:10:00.660
It's just, it's glorious.


00:10:00.660 --> 00:10:04.020
So that's the background where people maybe haven't done anything with Mongo.


00:10:04.020 --> 00:10:05.100
What about Beanie?


00:10:05.100 --> 00:10:06.820
What is Beanie really quick for people?


00:10:06.820 --> 00:10:10.500
We talked about a bit, but give us the quick rundown on Beanie and why you built it.


00:10:10.500 --> 00:10:13.420
Like there were other things that talked to MongoDB and Python before.


00:10:13.420 --> 00:10:15.540
Yeah, so there's a lot of tools.


00:10:15.540 --> 00:10:18.060
There is Mongo engine, which is nice and which is official.


00:10:18.060 --> 00:10:19.140
Yeah, I like the Mongo engine too.


00:10:19.140 --> 00:10:19.500
Yeah.


00:10:19.500 --> 00:10:23.460
Yeah, but one day I was playing again with new technologies


00:10:23.460 --> 00:10:26.740
and FastAPI was super new that time.


00:10:26.740 --> 00:10:30.580
It was like, it wasn't that famous at that time, like three years ago.


00:10:30.580 --> 00:10:32.580
and already was super nice.


00:10:32.580 --> 00:10:37.980
And I wanted to play with it before I can use it in my production projects.


00:10:37.980 --> 00:10:44.860
And I found that there is no nice, let's say, connector to MongoDB from FastAPI


00:10:44.860 --> 00:10:51.180
because there is nothing that could support and Pydentic and asynchronous MongoDB driver motor.


00:10:51.180 --> 00:10:55.380
And I decided, like, why? I think I can implement it myself. Why not?


00:10:55.380 --> 00:10:58.420
And I made a very small, tiny ODM.


00:10:58.420 --> 00:11:01.780
I even thought it would be tiny all the time.


00:11:01.780 --> 00:11:05.300
Like, you know, it could support only models of the documents.


00:11:05.300 --> 00:11:06.660
It could insert them.


00:11:06.660 --> 00:11:13.380
And all the operations of MongoDB, it wasn't hidden inside of Beanie.


00:11:13.380 --> 00:11:17.540
You had to use MQL, Mongo Query Language, there.


00:11:17.540 --> 00:11:19.140
So I just released this.


00:11:19.140 --> 00:11:23.620
And somehow in one month it got not that popular.


00:11:23.620 --> 00:11:27.300
But people just came to me and like, "I like what you did.


00:11:27.300 --> 00:11:32.980
"Could you please add this feature and that feature? And this part works wrongly, so please fix this."


00:11:32.980 --> 00:11:36.980
And I was like, "Whoa, whoa, I didn't know, but I made an open source product."


00:11:36.980 --> 00:11:38.020
Wow.


00:11:38.020 --> 00:11:42.500
Yeah, that's cool. Some weird podcaster guy goes, "This is great, except for where are the indexes?"


00:11:42.500 --> 00:11:47.220
Yeah, this was like first, maybe second week after I published it. And yeah,


00:11:47.220 --> 00:11:52.420
you came to my GitHub issues. "Could you add indexes?" And I was like, "I forgot about indexes."


00:11:52.420 --> 00:11:54.580
I have to add them.


00:11:54.580 --> 00:11:56.740
Yeah, indexes are like database magic.


00:11:56.740 --> 00:11:57.940
It's they're just awesome.


00:11:57.940 --> 00:12:00.260
So yeah, and this was kind of playground project.


00:12:00.260 --> 00:12:01.620
And now this is nice.


00:12:01.620 --> 00:12:02.180
Oh, damn.


00:12:02.180 --> 00:12:03.060
Oh, I'm gonna be.


00:12:03.060 --> 00:12:06.180
It's been really, really reliable for all the work that we've been doing.


00:12:06.180 --> 00:12:07.860
So good work on that.


00:12:07.860 --> 00:12:08.820
Let's see.


00:12:08.820 --> 00:12:10.980
I guess there's two angles to go here.


00:12:10.980 --> 00:12:17.860
One, if we go over the releases, the big release is this 1.21.0,


00:12:17.860 --> 00:12:20.500
which says Pydantic v2 support.


00:12:20.500 --> 00:12:22.740
So I want to spend a lot of time talking to you about like,


00:12:22.740 --> 00:12:25.460
What was your experience going from Pydantic one to two?


00:12:25.460 --> 00:12:30.340
Because as you said, there's the really famous ones like FastAPI and others,


00:12:30.340 --> 00:12:34.660
but there's many, many projects out there that use Pydantic.


00:12:34.660 --> 00:12:36.660
I wonder if we could get it to show it.


00:12:36.660 --> 00:12:42.980
So, you know, GitHub has that feature where it shows used by 229,000 projects.


00:12:42.980 --> 00:12:45.940
228,826 projects.


00:12:45.940 --> 00:12:47.940
Yeah, they all use Pydantic now, right?


00:12:47.940 --> 00:12:49.300
Exactly.


00:12:49.300 --> 00:12:51.780
Just on GitHub, use Pydantic.


00:12:51.780 --> 00:12:57.060
So, you know, many of them still haven't necessarily done this work to move to two.


00:12:57.060 --> 00:12:59.780
And so I want to make that the focus of our conversation.


00:12:59.780 --> 00:13:04.540
However, since we had a nice episode on Beanie before, before we get into that


00:13:04.540 --> 00:13:08.620
aspect, let's just do a catch up on like what's happened with Beanie in the last


00:13:08.620 --> 00:13:08.880
two years.


00:13:08.880 --> 00:13:12.160
What are some of the cool new features and things that you want to highlight for


00:13:12.160 --> 00:13:12.580
folks?


00:13:12.580 --> 00:13:17.540
I added a lot of features, honestly, but there were a few really big.


00:13:17.540 --> 00:13:18.860
I really like one.


00:13:18.900 --> 00:13:24.180
I didn't know that it could be needed for anybody, but I was continuously asked about


00:13:24.180 --> 00:13:30.820
"please add this" and I didn't want to add, but finally I added. And now I love this so much.


00:13:30.820 --> 00:13:38.260
This is called inheritance. You can inherit documents, so you can make a big inherited


00:13:38.260 --> 00:13:45.620
structure like car, then vehicle, then from vehicle you can inherit bicycle, bike, car,


00:13:45.620 --> 00:13:49.300
and from current here it's something else. And the thing is,


00:13:49.300 --> 00:13:53.780
everything will be stored in the same collection, in the same MongoDB


00:13:53.780 --> 00:13:59.380
collection, and if you want to make statistics over all the types, you can do


00:13:59.380 --> 00:14:03.460
it. And when you need to operate only with a


00:14:03.460 --> 00:14:07.700
type or subtype, you can do it as well. You can choose what you want to do.


00:14:07.700 --> 00:14:10.900
And I know this feature is used in productions now


00:14:10.900 --> 00:14:14.020
in many projects, and this is nice, this kind of...


00:14:14.020 --> 00:14:15.400
Yeah, this is really cool.


00:14:15.400 --> 00:14:20.380
So when I first heard about it, my first impression was, okay, so instead


00:14:20.380 --> 00:14:24.360
of deriving from beanie.document, you create some class that has some


00:14:24.360 --> 00:14:28.200
common features, maybe properties and validation and stuff, and then


00:14:28.200 --> 00:14:29.980
other documents can derive from it.


00:14:29.980 --> 00:14:35.080
So like you said, bicycle versus car, but in my mind, those would still


00:14:35.080 --> 00:14:37.080
go into different collections, right?


00:14:37.080 --> 00:14:39.560
They would go in different collections and that would just be a simpler way


00:14:39.560 --> 00:14:43.480
to have the code that would have a significant bit of reuse, but the fact


00:14:43.480 --> 00:14:48.680
they all go into the same collection and the documents are kind of supersets of each other.


00:14:48.680 --> 00:14:51.720
I think that's pretty interesting. I hadn't really thought about how I'd use that.


00:14:51.720 --> 00:14:59.880
This portion of Talk Python to me is brought to you by Studio 3T. Do you use MongoDB for your apps?


00:14:59.880 --> 00:15:04.840
As you may know, I'm a big fan of Mongo and it powers all the Talk Python web apps and APIs.


00:15:04.840 --> 00:15:10.040
I recently created a brand new course called MongoDB with AsyncPython. This course is an


00:15:10.040 --> 00:15:13.880
end-to-end journey on getting fully up to speed with Mongo and Python.


00:15:13.880 --> 00:15:19.080
When writing this course, I had to choose a GUI query and management tool to use and recommend.


00:15:19.080 --> 00:15:24.120
I chose Studio 3T. It strikes a great balance between being easy to use,


00:15:24.120 --> 00:15:28.920
very functional, and remaining true to the native MongoDB Shell CLI experience.


00:15:28.920 --> 00:15:33.080
That's why I'm really happy that Studio 3T has joined the show as a sponsor.


00:15:33.080 --> 00:15:37.960
Their IDE gives you full visual control of your data, plus with a drag-and-drop visual


00:15:37.960 --> 00:15:42.560
query builder and a multi-language code generator, new users will find they're up to speed in


00:15:42.560 --> 00:15:43.860
no time.


00:15:43.860 --> 00:15:48.380
For your team members who don't know MongoDB query syntax but are familiar with SQL, they


00:15:48.380 --> 00:15:54.720
can even query MongoDB directly with Studio 3T using SQL, and migrate tabular data from


00:15:54.720 --> 00:15:57.800
relational databases into MongoDB documents.


00:15:57.800 --> 00:16:01.800
Recently, Studio 3T has made it even easier to collaborate, too.


00:16:01.800 --> 00:16:05.600
Their brand new team sharing feature allows you to drag and drop queries, scripts, and


00:16:05.600 --> 00:16:09.040
and connections into permission-based shared folders.


00:16:09.040 --> 00:16:10.920
Save days of onboarding team members


00:16:10.920 --> 00:16:12.760
and tune queries faster than ever.


00:16:12.760 --> 00:16:17.760
Try Studio 3T today by visiting talkpython.fm/studio2023,


00:16:17.760 --> 00:16:21.360
the links in your podcast player show notes,


00:16:21.360 --> 00:16:23.840
and download the 30-day trial for free.


00:16:23.840 --> 00:16:26.520
Studio 3T, it's the MongoDB management tool


00:16:26.520 --> 00:16:27.760
I use for Talk Python.


00:16:27.760 --> 00:16:31.640
- You can do even two different,


00:16:31.640 --> 00:16:34.200
if you want to count all the vehicles,


00:16:34.200 --> 00:16:38.200
You can do it without, you know, without making requests to each of the collections


00:16:38.200 --> 00:16:40.200
because everything in the same collection.


00:16:40.200 --> 00:16:43.800
And you can do this with different fields there as well.


00:16:43.800 --> 00:16:45.800
And you can make aggregations over all of them.


00:16:45.800 --> 00:16:48.500
And even over cars separately.


00:16:48.500 --> 00:16:49.300
This is nice.


00:16:49.300 --> 00:16:50.300
And yeah, I like it.


00:16:50.300 --> 00:16:53.800
Does the record have something, some kind of indicator of what...


00:16:53.800 --> 00:16:55.300
Yeah, inside there is...


00:16:55.300 --> 00:16:56.200
What class it is.


00:16:56.200 --> 00:16:58.500
It's like, I'm a car class, I'm a bike class.


00:16:58.500 --> 00:17:00.800
Yeah, yeah. You can specify...


00:17:00.800 --> 00:17:04.780
Originally it is called class name or something like this with underscore, but


00:17:04.780 --> 00:17:07.660
you can specify which fields would work for this.


00:17:07.660 --> 00:17:09.420
So we can specify the name of this field.


00:17:09.420 --> 00:17:14.340
And in this field, it stores not only the name of the class, but the structure itself.


00:17:14.340 --> 00:17:19.060
Like for bus, it will keep vehicle, car, bus.


00:17:19.060 --> 00:17:19.540
Yeah.


00:17:19.540 --> 00:17:24.500
So in this field, that's why it will be able to, even on the database level, it


00:17:24.500 --> 00:17:27.300
will understand the hierarchy of this object.


00:17:27.300 --> 00:17:27.560
Right.


00:17:27.560 --> 00:17:31.160
And so if you want to do data science-y things, you could use the aggregation


00:17:31.160 --> 00:17:34.720
framework to run a bunch of those types of queries on it, right?


00:17:34.720 --> 00:17:34.960
Yeah.


00:17:34.960 --> 00:17:38.160
And it's, it's better to do all this stuff on the database layer because,


00:17:38.160 --> 00:17:41.160
because Python is not that fast with iterations.


00:17:41.160 --> 00:17:43.240
While MongoDB is super fast.


00:17:43.240 --> 00:17:43.680
Yeah.


00:17:43.680 --> 00:17:46.840
And plus, you know, you don't need necessarily to pull all the data back


00:17:46.840 --> 00:17:49.880
just to read some field or whatever.


00:17:49.880 --> 00:17:50.160
Right.


00:17:50.160 --> 00:17:51.400
So yeah, that's really cool.


00:17:51.400 --> 00:17:55.480
This is not what I expected when I first heard about it, but this is quite cool.


00:17:55.560 --> 00:18:00.560
First time I heard this about this feature, I was like, nobody wants this.


00:18:00.560 --> 00:18:02.200
Why do you try to?


00:18:02.200 --> 00:18:05.880
But then I found how flexible this is getting to be.


00:18:05.880 --> 00:18:07.880
And so yeah, this is nice.


00:18:07.880 --> 00:18:11.920
The reason I guess it's a surprise to me is it leverages an aspect of MongoDB


00:18:11.920 --> 00:18:14.480
that's in document databases in general that are interesting,


00:18:14.480 --> 00:18:20.080
but that I don't find myself using very much is in that you don't have to have,


00:18:20.080 --> 00:18:22.080
there's not a real structured schema.


00:18:22.080 --> 00:18:24.880
And a lot of people say that and kind of get a sense for it.


00:18:24.880 --> 00:18:27.840
For me, that's always meant like, well, the database doesn't control the schema,


00:18:27.840 --> 00:18:30.680
but my code does, and that's probably going to be the same, right?


00:18:30.680 --> 00:18:36.520
So there's kind of an implicit static schema at any given time that matches the code.


00:18:36.520 --> 00:18:41.600
But you can do things like put different records into the same collection.


00:18:41.600 --> 00:18:45.960
You wouldn't do it just like, well, here's a user and here's a blog post and just put


00:18:45.960 --> 00:18:46.800
them in the same collection.


00:18:46.800 --> 00:18:47.640
That would be insane.


00:18:47.640 --> 00:18:52.160
But there's, you know, if you have this commonality of this base class, I can see


00:18:52.160 --> 00:18:52.920
why you might do this.


00:18:52.920 --> 00:18:53.560
It's interesting.


00:18:53.600 --> 00:18:56.800
Yeah, in this context, blog post or video post could be


00:18:56.800 --> 00:18:59.760
different by structure but could be stored in a single collection.


00:18:59.760 --> 00:19:02.720
One other thing on the page here that we could maybe talk about is link.


00:19:02.720 --> 00:19:04.400
I want to tell people about what link.


00:19:04.400 --> 00:19:10.240
MongoDB is a non-relational database, but you can force it to work with relations.


00:19:10.240 --> 00:19:16.480
And there is a data type in MongoDB called dbRef, dbReference,


00:19:16.480 --> 00:19:21.200
which is used to work with this link type in Beanie.


00:19:21.200 --> 00:19:26.160
So in Beanie with this generic type link, you can put inside of the link any


00:19:26.160 --> 00:19:29.200
document type. It can make relations based on this link.


00:19:29.200 --> 00:19:33.040
So you can fetch linked documents from another collection


00:19:33.040 --> 00:19:36.160
using just standard find operations in Beanie.


00:19:36.160 --> 00:19:39.840
There is kind of magic under the hood. I use,


00:19:39.840 --> 00:19:43.200
instead of using find operations, MongoDB find operations,


00:19:43.200 --> 00:19:46.720
I use aggregation framework of MongoDB, but it is hidden


00:19:46.720 --> 00:19:51.200
under the hood of Beanie and so yeah. And you can use relations then.


00:19:51.200 --> 00:19:55.200
And the nice thing about new features, because LINQ


00:19:55.200 --> 00:19:58.560
already was implemented, I think, two years ago. But


00:19:58.560 --> 00:20:02.240
again, I don't come up with my own features, I think.


00:20:02.240 --> 00:20:08.400
Every feature somebody asked me for. And I was asked for another feature to


00:20:08.400 --> 00:20:12.560
make backtracking, back references for these links. Like if you have a


00:20:12.560 --> 00:20:15.120
link from one document to another, another document


00:20:15.120 --> 00:20:19.460
should be able to have to fetch this relation backwards.


00:20:19.460 --> 00:20:23.460
So in this case, you've got an owner which has a list of vehicles,


00:20:23.460 --> 00:20:26.800
but given a vehicle, you would like to ask who is its owner, right?


00:20:26.800 --> 00:20:30.760
True. And I implemented this, I named it backlinks,


00:20:30.760 --> 00:20:34.860
backlink, and it can just fetch it in reverse direction.


00:20:34.860 --> 00:20:35.460
That's cool.


00:20:35.460 --> 00:20:40.620
And the nice thing about this is it only uses the magic of aggregations


00:20:40.620 --> 00:20:45.260
and it doesn't store anything for backlink fields in the collection itself.


00:20:45.260 --> 00:20:45.760
Okay.


00:20:45.760 --> 00:20:49.660
So, in a MongoDB document, you never will find these fields for backlink


00:20:49.660 --> 00:20:52.300
because everything you need is on the link.


00:20:52.300 --> 00:20:53.340
And this is nice.


00:20:53.340 --> 00:20:54.620
Yeah, that is really cool.


00:20:54.620 --> 00:20:56.940
In the queries, in the find statement,


00:20:56.940 --> 00:21:00.860
you add fetch_link=true and that's kind of like a join.


00:21:00.860 --> 00:21:01.740
Is that how that works?


00:21:01.740 --> 00:21:02.380
There are options.


00:21:02.380 --> 00:21:04.700
Eager versus lazy loading type of thing.


00:21:04.700 --> 00:21:07.500
When you find without this option, default it is false.


00:21:07.500 --> 00:21:09.980
You will see in the field, in the link at field,


00:21:09.980 --> 00:21:11.980
you will see only link itself.


00:21:11.980 --> 00:21:15.820
It will be linked with ID inside of the object.


00:21:15.820 --> 00:21:18.900
But if you put fetch and you can fetch it manually


00:21:18.900 --> 00:21:21.980
like with method .fetch it will work.


00:21:21.980 --> 00:21:24.740
But when you put fetch links through


00:21:24.740 --> 00:21:28.220
it will fetch it everything automatically on the database layer.


00:21:28.220 --> 00:21:30.580
And yeah, it will return all the linked documents.


00:21:30.580 --> 00:21:31.420
That's really cool.


00:21:31.420 --> 00:21:31.980
Other one?


00:21:31.980 --> 00:21:33.220
Lazy parsing.


00:21:33.220 --> 00:21:34.620
I mean, we all want to be lazy.


00:21:34.620 --> 00:21:35.620
But what are we doing here?


00:21:35.620 --> 00:21:36.260
What is this one?


00:21:36.260 --> 00:21:37.980
Yeah, so this is...


00:21:37.980 --> 00:21:44.540
In some cases, Beanie could be used for really high-load projects, and sometimes you need to fetch


00:21:44.540 --> 00:21:51.980
like thousands of documents in a moment. And the nature of Pydentic is synchronous,


00:21:51.980 --> 00:21:57.900
not asynchronous, because it uses CPU-bound operations there. And when you fetch hundreds


00:21:57.900 --> 00:22:03.340
of documents, or even thousands of documents, you completely block your system, because a lot of


00:22:03.340 --> 00:22:06.860
loops to parse data, to validate data, and etc.


00:22:06.860 --> 00:22:12.540
And if you use it in asynchronous framework, this is not behavior that you like to have.


00:22:12.540 --> 00:22:14.540
And to fix this problem...


00:22:14.540 --> 00:22:18.780
Maybe even in asynchronous framework, it might be the behavior you don't want to have as well.


00:22:18.780 --> 00:22:19.100
Yeah.


00:22:19.100 --> 00:22:19.980
Right? Even then. Yeah.


00:22:19.980 --> 00:22:23.500
This is true. But even in asynchronous, you don't accept it.


00:22:23.500 --> 00:22:28.060
Yeah, exactly. But it's totally reasonable to think, well, I'm going to do a query against this


00:22:28.060 --> 00:22:32.780
document and it's got some nested stuff. Maybe it's a big sort of complex one,


00:22:32.780 --> 00:22:35.820
but you really just want three fields in this case.


00:22:35.820 --> 00:22:38.220
Now, you can use projections, right?


00:22:38.220 --> 00:22:40.220
Like that is the purpose of projections,


00:22:40.220 --> 00:22:42.220
but it limits the flexibility


00:22:42.220 --> 00:22:44.860
because you only have those fields that were projected.


00:22:44.860 --> 00:22:46.860
And in different situations,


00:22:46.860 --> 00:22:50.700
maybe you don't really know what parts you're going to use, right?


00:22:50.700 --> 00:22:51.980
You can have a complicated load.


00:22:51.980 --> 00:22:54.700
Yeah, so this kind of lets the consumer of the query


00:22:54.700 --> 00:22:56.060
use only what they need, right?


00:22:56.060 --> 00:22:59.420
Yeah, and so when you use this lazy parsing,


00:22:59.420 --> 00:23:02.140
Pydentic doesn't parse anything on the initial call.


00:23:02.140 --> 00:23:07.900
Like, you receive everything and store everything in a raw format in dictionaries, in Python dictionaries there.


00:23:07.900 --> 00:23:16.600
And when you call any field of the document, just parse it using Pydantic tools to parse as Pydantic do it internally.


00:23:16.600 --> 00:23:22.340
So is this lazy parse primarily implemented by Pydantic or is this something you've done on top of Pydantic?


00:23:22.340 --> 00:23:26.600
I implemented my own library for this. Like, it's on top of Pydantic for sure.


00:23:26.600 --> 00:23:33.320
but it uses... In pedantic, there are tools different in v1 and v2. The name of this tool is different, but you can


00:23:33.320 --> 00:23:39.640
parse something into type, not into a base model, but just into type. You can provide a type and


00:23:39.640 --> 00:23:46.520
the value to be parsed into this type, and it can parse it. So I use this, and additionally, I had


00:23:46.520 --> 00:23:52.600
to handle with all the validator stuff, because this is a very important part of pedantic, and you


00:23:52.600 --> 00:23:59.560
have to be able to validate things. And with lazy parsing, if it sees that there are root validators,


00:23:59.560 --> 00:24:04.600
then it will validate it against any field. Or if there is a field-specific validator, it will


00:24:04.600 --> 00:24:10.440
validate it against the field if this field was called. So yeah, I had to do some magic with


00:24:10.440 --> 00:24:18.600
pedantic there. But especially with pedantic v1, which was slower than v2, significantly slower,


00:24:18.600 --> 00:24:25.400
It was very helpful for people who have to fetch really big amounts of documents


00:24:25.400 --> 00:24:28.600
and to not block their pipeline in this step.


00:24:28.600 --> 00:24:30.360
This is a nice feature also.


00:24:30.360 --> 00:24:32.280
Yeah, I think this is a really nice feature.


00:24:32.280 --> 00:24:33.080
What's the harm?


00:24:33.080 --> 00:24:37.640
Does it make certain things slower if you're going to use every field?


00:24:37.640 --> 00:24:41.240
Why not just turn this on all the time, right?


00:24:41.240 --> 00:24:42.040
That's my question.


00:24:42.040 --> 00:24:43.160
Yes, for sure.


00:24:43.160 --> 00:24:44.440
There are trade-offs.


00:24:44.440 --> 00:24:51.800
if you will use this all the time, it would be like around twice slower than just pedantic


00:24:51.800 --> 00:24:57.480
validation if you will use all the fields. If you will use just a few fields, it would be faster.


00:24:57.480 --> 00:25:03.000
But I didn't turn it on by default because in general case, when people just want to fetch


00:25:03.000 --> 00:25:06.920
10, maybe 20 documents and use all the fields of them, it would be slower.


00:25:06.920 --> 00:25:11.400
That's kind of what I expected. But if you've got a really complicated document and you only use a


00:25:11.400 --> 00:25:15.400
few fields here and there, then it seems like a real win, but you're going to use everything anyway.


00:25:15.400 --> 00:25:21.320
And especially for Pydentic V2, when all the validation happens on the Rust layer,


00:25:21.320 --> 00:25:25.880
but here I cannot do this, because I cannot put the logic into the Rust layer, because there is


00:25:25.880 --> 00:25:31.560
no Rust layer for Beanie. And if you will fetch all the fields of the documents using this lazy


00:25:31.560 --> 00:25:36.280
parsing, everything will happen on the Python layer instead of the Rust layer, and it will be


00:25:36.280 --> 00:25:39.120
as slow as we won. So we will not see a benefit.


00:25:39.120 --> 00:25:43.480
So it's interesting, even in the V1 version of Pydantic, but now with


00:25:43.480 --> 00:25:48.120
Pydantic 2 being roughly 22 times faster that all of a sudden that you want to


00:25:48.120 --> 00:25:49.880
let Pydantic do its thing if it can.


00:25:49.880 --> 00:25:50.280
Yeah.


00:25:50.280 --> 00:25:56.620
Speaking of Pydantic getting some speed up from Rust, is any part of Beanie some


00:25:56.620 --> 00:26:00.520
other runtime compilation story than pure Python?


00:26:00.520 --> 00:26:04.720
Is there like a Cython thing or a Numba or any of those?


00:26:04.780 --> 00:26:09.740
The thing about the speed of Beanie is, Beanie is not about...


00:26:09.740 --> 00:26:15.660
So, as Pydentic is very CPU-bound, all the stuff happens on the CPU layer.


00:26:15.660 --> 00:26:21.580
While Beanie uses mostly input-output operations, because it interacts with the database.


00:26:21.580 --> 00:26:28.140
And for this, just default, I think, await pattern of Python works the best.


00:26:28.140 --> 00:26:33.900
And all the time, if there are any delays, it's most likely about this


00:26:33.900 --> 00:26:37.420
interaction process between application and MongoDB.


00:26:37.420 --> 00:26:38.460
It could be network.


00:26:38.460 --> 00:26:42.820
It could be, could be just delay from the query and et cetera, but not, not


00:26:42.820 --> 00:26:45.180
Beanie because Beanie doesn't, doesn't compute anything.


00:26:45.180 --> 00:26:47.300
Beanie doesn't do very much, I guess.


00:26:47.300 --> 00:26:47.540
Right.


00:26:47.540 --> 00:26:53.380
It's it coordinates motor, the asynchronous engine from MongoDB and it


00:26:53.380 --> 00:26:57.740
coordinates by Pydantic and it kind of clicks those together using async and


00:26:57.740 --> 00:27:00.740
a nice query API that you put together.


00:27:00.740 --> 00:27:03.740
And so, right, it's more about letting


00:27:03.740 --> 00:27:05.740
motor be fast and letting pydantic be fast


00:27:05.740 --> 00:27:07.740
and getting out of the way, I suppose.


00:27:07.740 --> 00:27:08.740
This is true, yeah.


00:27:08.740 --> 00:27:10.740
Beanie is mostly about making some magic


00:27:10.740 --> 00:27:14.740
and convert Python syntax into MongoDB syntax.


00:27:14.740 --> 00:27:16.740
Thank you for that. That's really nice.


00:27:16.740 --> 00:27:18.740
It's super nice the way that the syntax works, right?


00:27:18.740 --> 00:27:21.740
The fact that you're able to use native operators,


00:27:21.740 --> 00:27:22.740
for example, right?


00:27:22.740 --> 00:27:24.740
To do the queries. I really like that.


00:27:24.740 --> 00:27:25.740
Yeah, it was.


00:27:25.740 --> 00:27:29.780
It is, I don't like when somebody uses this in production applications.


00:27:29.780 --> 00:27:34.140
I mean, when, because it is hard to find problems, but when we are talking


00:27:34.140 --> 00:27:37.740
about libraries, this is really nice when it supports Python syntax.


00:27:37.740 --> 00:27:39.140
So that's why I decided to implement it.


00:27:39.140 --> 00:27:42.180
People shouldn't get too crazy with overloading their own operators,


00:27:42.180 --> 00:27:44.440
but as an API, it's really good.


00:27:44.440 --> 00:27:47.820
So for example, in this case, you have a sample document and it has a number.


00:27:47.820 --> 00:27:49.900
And so the query is sample dot find.


00:27:49.900 --> 00:27:54.480
And then the argument is sample dot number equal equal 10, right?


00:27:54.480 --> 00:27:57.120
which is exactly the way you would do it in an if statement.


00:27:57.120 --> 00:27:59.120
You'll contrast that with other languages


00:27:59.120 --> 00:28:02.320
or other frameworks such as Mongo engine


00:28:02.320 --> 00:28:04.560
which I used previously and is nice


00:28:04.560 --> 00:28:11.040
but you would say sample.find and then just number_eq=10


00:28:11.040 --> 00:28:13.280
You're like, "I know what that means."


00:28:13.280 --> 00:28:16.240
But it's not speaking to me the same way


00:28:16.240 --> 00:28:19.440
as if I was just doing a raw database query or


00:28:19.440 --> 00:28:20.960
writing pure Python, right?


00:28:20.960 --> 00:28:23.520
Yeah, it sounds like you have to learn another one of English, right?


00:28:23.520 --> 00:28:26.960
Exactly. You've got to, like, if you want to do a nested thing, it's the double


00:28:26.960 --> 00:28:31.760
underscore, you know, it'd be like number double underscore item, underscore


00:28:31.760 --> 00:28:35.280
EQ equals 10. You're like, oh my goodness. So yeah, that's kind of tricky.


00:28:35.280 --> 00:28:42.960
Okay. Well, let's talk about this, this upgrading story for the 22, 229,000 other


00:28:42.960 --> 00:28:48.000
folks out there who maybe haven't done this. So a while ago, back in 2022, almost


00:28:48.000 --> 00:28:53.440
exactly to the day a year ago I had Samuel Colvin on to talk about the plan


00:28:53.440 --> 00:28:57.880
to move to Pydantic v2 why he did it it was really interesting so that's worth


00:28:57.880 --> 00:29:01.160
listening to people want to learn more as well as I had Sebastian Ramirez and


00:29:01.160 --> 00:29:06.000
Samuel Colvin on to talk about it live at PyCon and that was fun too so people


00:29:06.000 --> 00:29:10.680
want background on what is the story of Pydantic 2, they can check that out. But the


00:29:10.680 --> 00:29:15.040
big announcement was on June 30th a couple months ago I guess that's a month


00:29:15.040 --> 00:29:21.540
than a half ago. Pydantic v2 is here after just one year of hard work. That was a huge


00:29:21.540 --> 00:29:26.240
project for the Pydantic folks, which, you know, they've done a great job on it. And


00:29:26.240 --> 00:29:32.580
I guess the big takeaway really is that Pydantic v2 is quite a bit faster. Maybe you could


00:29:32.580 --> 00:29:37.840
speak to that. And it's mostly but not exactly the same because as you already pointed out,


00:29:37.840 --> 00:29:40.560
the core of it is rewritten in Rust for performance reasons.


00:29:40.560 --> 00:29:47.600
I've made a lot of tests in Beanie. It is much faster when you talk about validation of the models itself,


00:29:47.600 --> 00:29:52.240
especially when you validate parse really nested and complicated models,


00:29:52.240 --> 00:29:56.640
then it's much, much faster than Python, than v1 implementation.


00:29:56.640 --> 00:30:02.000
While with Beanie, you still can see significant performance upgrade,


00:30:02.000 --> 00:30:09.440
but not that much because Beanie works with MongoDB, and there is this input-output operation,


00:30:09.440 --> 00:30:15.280
which is slow and which could not be upgraded just by decreasing processing time.


00:30:15.280 --> 00:30:23.440
When we are talking about simple documents, it's not that visible, like 10, sometimes 20% faster.


00:30:23.440 --> 00:30:30.000
But when we talk about nested documents, when there are nested dictionaries or nested lists of dictionaries,


00:30:30.000 --> 00:30:37.200
then it's much, much faster. In my Allure test, it is twice faster, v2 against v1.


00:30:37.200 --> 00:30:40.740
And I was super impressed by this because I was expecting this,


00:30:40.740 --> 00:30:43.500
expecting this, that it would not be that,


00:30:43.500 --> 00:30:47.500
that fast as then as pedantic tool itself,


00:30:47.500 --> 00:30:49.500
because of this put output operation.


00:30:49.500 --> 00:30:51.780
But yeah, this is, this is crazy.


00:30:51.780 --> 00:30:56.040
Right, because it's not just the parsing that Beanie does, right?


00:30:56.040 --> 00:30:58.040
Beanie sends the message over to Mongo,


00:30:58.040 --> 00:31:01.900
the network does some stuff, Mongo does its thing, sends it back,


00:31:01.900 --> 00:31:06.240
serialized as BSON, and then it's got to deserialize into


00:31:06.240 --> 00:31:12.980
objects somehow and then the pedantic part kicks in right and plus all the extra bits you've already talked about right so it it can


00:31:12.980 --> 00:31:19.920
Only affect that part, but I think it your example here shows. You know standard computer science answer it depends


00:31:19.920 --> 00:31:20.240
I


00:31:20.240 --> 00:31:28.320
Is a faster it depends I would guess the more complicated your document is the bigger bonus you get what you've already said


00:31:28.320 --> 00:31:30.320
and the more


00:31:30.760 --> 00:31:37.180
documents you return. So if I return one record from the database, it's got five fields, the amount that of that


00:31:37.180 --> 00:31:43.360
processing that is pedantic is small. But if I return 1000 records, and there's all that serialization, like, you know,


00:31:43.360 --> 00:31:48.600
the database has kind of done more or less the same amount of work, it's streamed the stuff back. But at this, when it gets


00:31:48.600 --> 00:31:54.000
to Python, it's like, whoa, I've got a lot of stuff to validate and parse. And I suspect that also matters how many


00:31:54.000 --> 00:31:54.880
records are coming back.


00:31:54.880 --> 00:32:00.480
Yes, this is true. That's why this affected this case for lazy parsing that was implemented for v1.


00:32:00.480 --> 00:32:03.880
And now it's not necessary for many cases.


00:32:03.880 --> 00:32:06.640
Only for very extreme high load.


00:32:06.640 --> 00:32:07.440
That's really cool.


00:32:07.440 --> 00:32:09.840
What makes me smile from this is


00:32:09.840 --> 00:32:11.980
the more Pydantic you use,


00:32:11.980 --> 00:32:15.080
the more awesome this upgrade to 2 becomes.


00:32:15.080 --> 00:32:17.440
And like I said, it's almost no work.


00:32:17.440 --> 00:32:20.240
Technically, I had to set all the optionals to be none.


00:32:20.240 --> 00:32:23.680
That's not a beanie thing, that's a Pydantic thing, but it's not a big deal.


00:32:23.680 --> 00:32:28.080
So upgrading basically means all the parts of your frame, all the frameworks


00:32:28.080 --> 00:32:30.360
you use that are built on Pydantic get faster.


00:32:30.360 --> 00:32:34.780
So for me, when I upgraded the website, it went about, I don't know, 40% faster


00:32:34.780 --> 00:32:39.160
or something like that, which is a huge speed up or very little work.


00:32:39.160 --> 00:32:40.560
It's already really fast, right?


00:32:40.560 --> 00:32:43.440
If you go to, you know, the podcast, you pull up an episode page.


00:32:43.440 --> 00:32:44.760
It's like 30 milliseconds.


00:32:44.760 --> 00:32:48.200
You go to the courses and you pull up a video to play.


00:32:48.200 --> 00:32:51.840
It's got many queries it does, but it's probably 20 milliseconds.


00:32:51.960 --> 00:32:54.860
So now it's 15 milliseconds or 14 milliseconds.


00:32:54.860 --> 00:32:57.800
But still, to get that much of a speed up


00:32:57.800 --> 00:33:00.600
and do basically no work on my part, that's awesome.


00:33:00.600 --> 00:33:03.200
And I'm not using a framework like FastAPI


00:33:03.200 --> 00:33:06.500
where the other side of that story is also Pydantic.


00:33:06.500 --> 00:33:08.800
So if you're using FastAPI and Beanie,


00:33:08.800 --> 00:33:11.500
which I think is probably a common combination,


00:33:11.500 --> 00:33:13.540
both the database side that gets you


00:33:13.540 --> 00:33:14.900
the Pydantic things is faster,


00:33:14.900 --> 00:33:17.800
and then the outbound and inbound processing


00:33:17.800 --> 00:33:20.240
that the API itself does is a lot faster


00:33:20.240 --> 00:33:21.440
because of Pydantic.


00:33:21.440 --> 00:33:26.760
And so you get this kind of multiplicative doubling of the speed on both ends, right?


00:33:26.760 --> 00:33:33.880
The numbers you just told about your website, it's like this time is only about this communication.


00:33:33.880 --> 00:33:38.120
I mean, how bits are going from one computer to another.


00:33:38.120 --> 00:33:40.720
There is no computations there, probably.


00:33:40.720 --> 00:33:42.480
It's super, super impressive.


00:33:42.480 --> 00:33:46.560
You know, people say, "Well, Python is not fast enough."


00:33:46.560 --> 00:33:51.660
That may be true for a few very rare, extremely high load situations,


00:33:51.660 --> 00:33:54.320
but I would bet it's fast enough for most people.


00:33:54.320 --> 00:33:59.820
If your website end-to-end processing is responding in 15 milliseconds,


00:33:59.820 --> 00:34:05.060
you've got other parts of your system like CDNs and an amount of JavaScript you send


00:34:05.060 --> 00:34:07.860
to worry about, not your truly awesome.


00:34:07.860 --> 00:34:11.160
Because of indexes also, don't forget your indexes.


00:34:11.160 --> 00:34:16.060
Yeah, each time when I have any requests about my things are slow


00:34:16.060 --> 00:34:19.100
and probably have to switch Python to anything else.


00:34:19.100 --> 00:34:24.220
Usually the problem is about the data model, not about the processing, because, you know,


00:34:24.220 --> 00:34:30.620
people could store things a bit wrongly, a bit too nested or less nested than it should be, and etc.


00:34:30.620 --> 00:34:32.220
And yeah, indexes.


00:34:32.220 --> 00:34:37.260
Yeah, indexes or you've done a query where you return a hundred things of huge documents


00:34:37.260 --> 00:34:40.300
and you only want, like, say, the title and last updated.


00:34:40.300 --> 00:34:43.900
But you don't do a projection, and so you're sending way too much data.


00:34:43.900 --> 00:34:47.200
It's like select star instead of select title comma date.


00:34:47.200 --> 00:34:48.100
You know, something like that.


00:34:48.100 --> 00:34:50.200
Sometimes, sometimes, sometimes


00:34:50.200 --> 00:34:53.100
also works to make protection on the database layer.


00:34:53.100 --> 00:34:55.900
Like to make some, like


00:34:55.900 --> 00:34:58.300
to find maximum elements or minimum elements


00:34:58.300 --> 00:35:01.200
and to do this stuff on the database is better than in Python


00:35:01.200 --> 00:35:04.800
because in Python you have to iterate over the objects to find things


00:35:04.800 --> 00:35:06.200
which is not that efficient.


00:35:06.200 --> 00:35:07.100
So we just have to...


00:35:07.100 --> 00:35:10.300
You've got to pull them all back, deserialize them, and validate them


00:35:10.300 --> 00:35:12.800
and then iterate over them rather than just let that happen


00:35:12.800 --> 00:35:14.160
on just the fields in the database.


00:35:14.160 --> 00:35:15.160
That's a good point.


00:35:15.160 --> 00:35:16.720
And maybe the query is just bad as well.


00:35:16.720 --> 00:35:19.080
Okay, so what was your experience?


00:35:19.080 --> 00:35:21.320
You know, they shipped a migration guide


00:35:21.320 --> 00:35:24.040
about the things that you've got to do.


00:35:24.040 --> 00:35:26.200
And if you look at the scroll bar here,


00:35:26.200 --> 00:35:28.120
the migration guide is large.


00:35:28.120 --> 00:35:29.720
I don't know how many pages.


00:35:29.720 --> 00:35:30.840
Let's see if I press print,


00:35:30.840 --> 00:35:33.000
if it'll tell me how many pages.


00:35:33.000 --> 00:35:34.640
No, sadly, it doesn't want to tell me


00:35:34.640 --> 00:35:35.760
how many pages it would print.


00:35:35.760 --> 00:35:38.320
But there are many pages here, I guess.


00:35:38.320 --> 00:35:39.840
If I were to print this out,


00:35:39.840 --> 00:35:41.440
was this a daunting experience?


00:35:41.440 --> 00:35:42.520
How did it go for you?


00:35:42.520 --> 00:35:46.360
It was very interesting. So when I just switched pip install,


00:35:46.360 --> 00:35:47.400
a Pentantic V2.


00:35:47.400 --> 00:35:49.240
Or you're like, let's see if it just works. Come on.


00:35:49.240 --> 00:35:53.080
And just run tests and everything was ready.


00:35:53.080 --> 00:35:57.000
Firstly, it was like only one error. Nothing can work.


00:35:57.000 --> 00:36:00.440
I don't run any tests. So one error.


00:36:00.440 --> 00:36:05.560
I handled it and each test was read and everything.


00:36:05.560 --> 00:36:08.120
It was really interesting and challenging.


00:36:08.120 --> 00:36:11.560
Interesting because it's kind of really a computer science problem.


00:36:11.560 --> 00:36:21.560
sometimes there. So, PyDentic moved a lot of logic to the Rust layer, and it got hidden for me as a user of PyDentic.


00:36:21.560 --> 00:36:27.560
For example, in Python there is a thing called "forward ref". What is it?


00:36:27.560 --> 00:36:33.960
When you have two classes in a single module, for example, and in one class you have a field of the second class,


00:36:33.960 --> 00:36:39.400
and in the second class you have a field of type of the first class, you cannot just put these names


00:36:39.400 --> 00:36:45.560
without any magic. You can make input from annotation or you can just write it as a string


00:36:45.560 --> 00:36:50.920
instead of the class itself. But then Python will understand it as a forward ref, a forward


00:36:50.920 --> 00:36:58.440
reference for another class. And Pydentic can resolve it and make it an actual class, finally,


00:36:58.440 --> 00:37:04.360
in the base model. And in v1, this mechanism was implemented in Python and I could use it,


00:37:04.360 --> 00:37:06.360
and I could use the results of this


00:37:06.360 --> 00:37:08.360
while in Pandent V2


00:37:08.360 --> 00:37:10.360
everything is in the Rust layer.


00:37:10.360 --> 00:37:12.360
And when it updates this reference, it updates


00:37:12.360 --> 00:37:14.360
inside of the Rust and I cannot see


00:37:14.360 --> 00:37:16.360
the actual class finally.


00:37:16.360 --> 00:37:18.360
And I had to implement my own resolvers there.


00:37:18.360 --> 00:37:21.360
And there are a few stuff like this.


00:37:21.360 --> 00:37:23.360
Another one big change was about...


00:37:23.360 --> 00:37:25.360
That does not sound easy.


00:37:25.360 --> 00:37:27.360
Yeah. I was like,


00:37:27.360 --> 00:37:28.360
"So, will I?"


00:37:28.360 --> 00:37:30.360
"Am I going to do this?"


00:37:30.360 --> 00:37:32.360
Yes, exactly.


00:37:32.360 --> 00:37:36.860
And it, you know, for people maybe haven't played with this, it's really important


00:37:36.860 --> 00:37:42.560
because Pydantic and hence Beanie depends on the types, right?


00:37:42.560 --> 00:37:48.660
The parsing and the validation and all of those things, you have to know exactly what type a thing is, right?


00:37:48.660 --> 00:37:53.860
And so if you lose access to the forward reference resolution, that's going to be bad.


00:37:53.860 --> 00:38:01.760
Yeah, for example, in links or in backward links, if you don't clearly understand which document is linked to this document,


00:38:01.760 --> 00:38:03.400
You cannot build a query for this.


00:38:03.400 --> 00:38:05.680
So yeah, and I have made this resolver.


00:38:05.680 --> 00:38:12.200
I honestly, I just was reading identically one code and was, I didn't copy paste, but I


00:38:12.200 --> 00:38:14.160
was using nearly the same algorithm.


00:38:14.160 --> 00:38:20.920
And another big feature was about how validation of the custom types happens.


00:38:20.920 --> 00:38:21.720
Yeah.


00:38:21.720 --> 00:38:23.240
And get the pedantic core schema.


00:38:23.240 --> 00:38:28.280
So everything is in the schema inside of the Rust layer now, and you can write


00:38:28.280 --> 00:38:36.040
instructions in Python, which would be imported to this Rust layer and would be called from there.


00:38:36.040 --> 00:38:42.440
That's why the whole syntax of this completely changed. And that's why I was thinking,


00:38:42.440 --> 00:38:49.240
how can I have two completely different syntaxes for the same thing inside of the same class?


00:38:49.240 --> 00:38:55.080
And I was thinking, maybe I have to switch branches now and have


00:38:55.640 --> 00:39:02.760
Bini v2 after pedantic v2 and Bini v1 and support all the new features in both versions and it was


00:39:02.760 --> 00:39:07.240
oh no it will be nightmare. You're already busy with one project do you need because I already


00:39:07.240 --> 00:39:12.120
have Bannet. Yeah do you want two projects? Yeah and I already have Bannet which is a synchronous


00:39:12.120 --> 00:39:18.280
version of Bini which also would be split into two then and I will have four projects which is


00:39:18.280 --> 00:39:25.160
which is too crazy. Yeah no kidding. I can't split myself this is a problem and yeah finally finally


00:39:25.160 --> 00:39:31.880
Finally, I found, I honestly, I just went to FastAPI code, and I was reading how they deal with this.


00:39:31.880 --> 00:39:38.120
And like, nice idea. I will do the same. Thank you, guys. And that's the power of open source.


00:39:38.120 --> 00:39:44.680
Yeah, it is. I feel like Sebastian and FastAPI are kind of examples for a lot of different


00:39:44.680 --> 00:39:49.160
projects and different people, you know, people look to them for kind of an example.


00:39:49.160 --> 00:39:53.320
Yeah, this is true. And so and finally, finally, I solved all the problems.


00:39:53.320 --> 00:39:58.060
It took me, to solve all the problems, it took me like one, maybe one and a half weeks.


00:39:58.060 --> 00:40:03.860
But then I published a better version, and there were performance problems with better versions.


00:40:03.860 --> 00:40:09.300
There were some corner cases that I didn't catch, and the community found them.


00:40:09.300 --> 00:40:12.660
And this is great also about open sourcing, because


00:40:12.660 --> 00:40:17.660
honestly, I would not be able to find all of these problems myself for this short period of time.


00:40:17.660 --> 00:40:18.400
Definitely.


00:40:18.400 --> 00:40:21.160
I guess, how much of this is at runtime?


00:40:21.160 --> 00:40:27.320
And how much of the, I guess it's all at runtime, but how much of this is startup versus kind of once the app is up and running.


00:40:27.320 --> 00:40:38.160
So, you know, you've got your Beanie init code where you pass the motor async client over and you pass the models and it's got to like verify that they all click together correctly.


00:40:38.160 --> 00:40:45.200
You know, they all have the settings that say, you know, what database they go to and the indexes are set up correctly and whatever else is in there.


00:40:45.200 --> 00:40:51.000
And then once I imagine once that gets processed, it kind of just knows it and runs.


00:40:51.000 --> 00:40:56.500
So how much of this stuff that you're talking about was kind of the setup, get things working,


00:40:56.500 --> 00:40:59.740
and how much of it is happening on every query, every insert?


00:40:59.740 --> 00:41:04.440
Most of this was about run time of about every query and every...


00:41:04.440 --> 00:41:09.100
Not even this way, like, how do I set up the document itself?


00:41:09.100 --> 00:41:13.660
how do I set up validators, because I also have validators in the documents


00:41:13.660 --> 00:41:18.300
to make things simpler, and the syntax changed, and etc.


00:41:18.300 --> 00:41:25.740
So, for example, there was a nested class called "config" before in pedantic v1,


00:41:25.740 --> 00:41:29.100
and now this is a field called "model-config",


00:41:29.100 --> 00:41:32.700
which you see is a completely different interface again, because this is not a class,


00:41:32.700 --> 00:41:37.740
this is just a field now. And I was using and still use this config stuff,


00:41:37.740 --> 00:41:40.800
and I had to not only switch to the new syntax,


00:41:40.800 --> 00:41:43.680
but support on the class if you use Pydentic V1.


00:41:43.680 --> 00:41:45.800
And that's why inside of my classes,


00:41:45.800 --> 00:41:49.760
I have conditions, like which field I want to define


00:41:49.760 --> 00:41:51.920
based on the version of Pydentic.


00:41:51.920 --> 00:41:55.320
And yeah, most of the changes were about


00:41:55.320 --> 00:41:58.160
this setups of the documents and setups of the types,


00:41:58.160 --> 00:42:01.120
but you use it not on the initialization layer,


00:42:01.120 --> 00:42:05.000
but on the runtime, yeah, with all these things.


00:42:05.000 --> 00:42:08.040
You also talked about the performance story.


00:42:08.040 --> 00:42:12.800
Do you do any profiling or have any tools like that?


00:42:12.800 --> 00:42:14.680
- Honestly, I didn't.


00:42:14.680 --> 00:42:19.200
So there are pprofile and other tools to do this stuff.


00:42:19.200 --> 00:42:24.200
I was measuring using just time start, time end,


00:42:24.200 --> 00:42:27.640
but I was doing this for different parts of the code


00:42:27.640 --> 00:42:30.080
just to see what's happening there and here.


00:42:30.080 --> 00:42:33.840
And honestly, it was when I faced a performance problem,


00:42:33.840 --> 00:42:37.980
this was because there are some methods in Pidentic V2


00:42:37.980 --> 00:42:41.440
that they keep but marked as deprecated.


00:42:41.440 --> 00:42:42.940
They keep from V1.


00:42:42.940 --> 00:42:46.640
In some cases, I just didn't switch it to the new versions.


00:42:46.640 --> 00:42:49.040
And this was the performance problem.


00:42:49.040 --> 00:42:52.940
And when I found all the places where I used deprecated methods,


00:42:52.940 --> 00:42:54.440
then everything--


00:42:54.440 --> 00:42:56.940
Switch it to the new, more intended one,


00:42:56.940 --> 00:43:00.440
and that's got the fully optimized version or something like that.


00:43:00.440 --> 00:43:00.840
Yeah.


00:43:00.840 --> 00:43:03.440
- Yeah, yeah, true, because Beanie is working


00:43:03.440 --> 00:43:05.680
with a lot of internal things of Pydentic,


00:43:05.680 --> 00:43:08.400
and it uses this very heavily.


00:43:08.400 --> 00:43:11.720
And sometimes I just don't know that in this,


00:43:11.720 --> 00:43:14.560
I mean, don't remember that in this specific part,


00:43:14.560 --> 00:43:16.840
there is something internal for Pydentic,


00:43:16.840 --> 00:43:20.360
and I use this also, and so I had to check everything.


00:43:20.360 --> 00:43:22.560
And Pydentic code base is big already,


00:43:22.560 --> 00:43:24.400
so it's hard to keep everything in mind.


00:43:24.400 --> 00:43:25.920
- Yeah, I feel like that's the challenge


00:43:25.920 --> 00:43:29.240
for people like you and FastAPI and others.


00:43:29.240 --> 00:43:33.960
you have your code way deeper in the internals of Pydantic


00:43:33.960 --> 00:43:37.520
than people who just consume FastAPI or consume Beanie


00:43:37.520 --> 00:43:38.160
like I do.


00:43:38.160 --> 00:43:39.560
This is very interesting.


00:43:39.560 --> 00:43:41.600
I mean, this is true computer science problem,


00:43:41.600 --> 00:43:43.560
like when you have to swap interfaces,


00:43:43.560 --> 00:43:48.120
and you don't even know where all those interfaces are used.


00:43:48.120 --> 00:43:49.280
And you have to detect them.


00:43:49.280 --> 00:43:50.840
So yeah, this is nice.


00:43:50.840 --> 00:43:51.600
Super interesting.


00:43:51.600 --> 00:43:53.800
Yeah, and again, on your side, you've


00:43:53.800 --> 00:43:55.960
got to do that to adapt to the new Pydantic,


00:43:55.960 --> 00:43:57.760
but you've also got to present some kind


00:43:57.760 --> 00:44:02.920
consistent forward-looking view to people consuming Beanie so they don't have to rewrite


00:44:02.920 --> 00:44:03.920
all their code too, right?


00:44:03.920 --> 00:44:04.920
Yeah, true.


00:44:04.920 --> 00:44:11.600
So, and all the interfaces, I didn't change any Beanie interface when I was working with


00:44:11.600 --> 00:44:12.600
this.


00:44:12.600 --> 00:44:17.600
Like, all the interfaces are still the same for Beanie and nobody should change their


00:44:17.600 --> 00:44:18.920
code which uses Beanie.


00:44:18.920 --> 00:44:24.640
I implemented kind of middleware between Pydentic and Beanie and this middleware have static


00:44:24.640 --> 00:44:29.600
interfaces and inside of this there are these conditions like if identic v2 then


00:44:29.600 --> 00:44:37.760
and yeah this kind of logic. Nice. It's a pretty good question on the audience from Marwan here


00:44:37.760 --> 00:44:42.400
says other than getting the code to execute correctly were there any gnarly parts you had


00:44:42.400 --> 00:44:47.920
to figure out to appease type checkers and linters and that kind of stuff? I don't remember any


00:44:47.920 --> 00:44:57.200
changes about this thing, like mypy and ruf, I use ruf instead of flake8 currently.


00:44:57.200 --> 00:45:03.600
I didn't fix this stuff. Everything was okay with new Pydantic. I think guys made a really


00:45:03.600 --> 00:45:09.560
great job about this to make everything work, because I have other checks about mypy and


00:45:09.560 --> 00:45:12.440
about ruf, and everything went smoothly about this.


00:45:12.440 --> 00:45:19.840
So I can't imagine being Samuel on team to have to rewrite Pydantic with such a major refactoring,


00:45:19.840 --> 00:45:25.440
realizing quarter million other projects depend on this and then people depend on those projects.


00:45:25.440 --> 00:45:30.140
You know, and like, how are we going to do this without the world just completely breaking, you know?


00:45:30.140 --> 00:45:33.540
Currently, they have a Discord channel also for Pydantic.


00:45:33.540 --> 00:45:41.440
And I see many people asking for help and some questions about new syntax.


00:45:41.440 --> 00:45:45.120
But I see that it could be much more because


00:45:45.120 --> 00:45:48.800
so current syntax is very similar to the previous syntax,


00:45:48.800 --> 00:45:51.600
but the change, it's completely rewritten, right?


00:45:51.600 --> 00:45:53.520
Oh yeah, this is very impressive work.


00:45:53.520 --> 00:45:54.880
Yeah, completely rewritten.


00:45:54.880 --> 00:45:56.480
A good part of it in another language.


00:45:56.480 --> 00:46:01.200
Broken into multiple modules and still it seems to go pretty well.


00:46:01.200 --> 00:46:04.400
Yeah, and the assumptions about the default values for


00:46:04.400 --> 00:46:06.640
optionals, that was the only thing that seemed to have caught me out.


00:46:06.640 --> 00:46:11.940
You can put in the config that you can have options, like,


00:46:11.940 --> 00:46:15.080
use the same logic as for v1,


00:46:15.080 --> 00:46:17.940
but you just have to mention it in the config now.


00:46:17.940 --> 00:46:19.440
But I don't remember, honestly.


00:46:19.440 --> 00:46:21.940
There was a few other things that maybe I ran across, like,


00:46:21.940 --> 00:46:23.940
and honestly, I don't know why some of these changed.


00:46:23.940 --> 00:46:26.940
So it used to be able to just call .json on an object,


00:46:26.940 --> 00:46:30.840
and now it's model_dump_json.


00:46:30.840 --> 00:46:33.540
Or there was dict, model_dump, right?


00:46:33.540 --> 00:46:36.620
Everything has a prefix model currently in Pydantic.


00:46:36.620 --> 00:46:41.380
And I believe this is to not make conflicts with the user logic.


00:46:41.380 --> 00:46:46.180
Because when you have your own suffix or prefix,


00:46:46.180 --> 00:46:50.460
then it's simpler for users to have their own methods.


00:46:50.460 --> 00:46:53.020
And I like this solution. This is really nice.


00:46:53.020 --> 00:46:55.020
I guess this is the other thing that I ran into,


00:46:55.020 --> 00:46:57.460
is I have a few places I was calling .dict, I think.


00:46:57.460 --> 00:46:59.780
For me as well. And I have conditions.


00:46:59.780 --> 00:47:00.900
I see.


00:47:00.900 --> 00:47:03.220
Anything else you want to talk about, about the migration?


00:47:03.220 --> 00:47:07.460
Like what's go okay for you or any other thing you want to highlight about how it went?


00:47:07.460 --> 00:47:14.580
Honestly, I think I mentioned everything and yeah, it's been very smooth, thanks to the pedantic team.


00:47:14.580 --> 00:47:17.860
And yeah, I really like pedantic v2.


00:47:17.860 --> 00:47:20.020
I still really like pedantic v1 actually.


00:47:20.020 --> 00:47:21.620
I like both.


00:47:21.620 --> 00:47:28.900
But this completely different libraries inside and very similar libraries regarding interfaces.


00:47:28.900 --> 00:47:30.900
So I really like how it's--


00:47:30.900 --> 00:47:34.900
It's not too often that you get that massive of a speed up of your code


00:47:34.900 --> 00:47:36.900
and you didn't have to do anything, right?


00:47:36.900 --> 00:47:40.900
I was using this library and it was really right in the core of all the processing


00:47:40.900 --> 00:47:43.200
and now it's a lot faster. So is my code.


00:47:43.200 --> 00:47:48.400
When you read the code, the Rust part of Padentica, I started to read it just to learn.


00:47:48.400 --> 00:47:53.200
And this is really nice how it can interact with Python parts.


00:47:53.200 --> 00:47:56.700
I mean, I can write Rust itself, just logic.


00:47:56.700 --> 00:47:59.340
I even implemented a database in Rust.


00:47:59.340 --> 00:48:03.980
But how to do all this Python stuff inside of another language.


00:48:03.980 --> 00:48:05.380
So this is super impressive.


00:48:05.380 --> 00:48:06.380
It is super impressive.


00:48:06.380 --> 00:48:08.780
We'll get a little short on time here. Let's see what...


00:48:08.780 --> 00:48:12.220
I guess I'll give a shout out to this course I recently released.


00:48:12.220 --> 00:48:14.540
MongoDB with Async Python.


00:48:14.540 --> 00:48:17.900
Which of course uses Beanie as well.


00:48:17.900 --> 00:48:24.700
And I created this course on Beanie 1.10 or something prior to the 1.21


00:48:24.700 --> 00:48:27.500
switch this to pydantic 2 and it's all pydantic 1.


00:48:27.500 --> 00:48:31.500
And so I was always wondering like, well, how, you know, how tricky is it going to be to upgrade?


00:48:31.500 --> 00:48:34.500
And there was really either zero or very little changes.


00:48:34.500 --> 00:48:39.500
I think maybe the default values on optionals was also a thing I had to adjust on there.


00:48:39.500 --> 00:48:44.700
But if people want to learn all the stuff that we're talking about, you know, just talkpython.fm.


00:48:44.700 --> 00:48:47.900
Go to courses, check out the MongoDB async course.


00:48:47.900 --> 00:48:49.900
It's all about Beanie and stuff like that.


00:48:49.900 --> 00:48:52.900
I was reading this course also and I can highly recommend it.


00:48:52.900 --> 00:48:54.100
Thank you so much.


00:48:54.100 --> 00:48:57.340
One thing I do want to give a shout out to is I use Locus.


00:48:57.340 --> 00:48:58.640
Are you familiar with Locus?


00:48:58.640 --> 00:48:59.480
Locus.io?


00:48:59.480 --> 00:48:59.980
Yeah.


00:48:59.980 --> 00:49:01.480
What a cool project.


00:49:01.480 --> 00:49:04.440
So this lets you do really nice modeling


00:49:04.440 --> 00:49:07.180
of how users interact with your site using Python.


00:49:07.180 --> 00:49:09.640
And then what you get is,


00:49:09.640 --> 00:49:13.400
I don't know if there's any cool pictures that show up on here in terms of the graphs,


00:49:13.400 --> 00:49:15.980
but you get really nice graphs that show you real time,


00:49:15.980 --> 00:49:19.780
but how many requests per second and different scenarios you get.


00:49:19.780 --> 00:49:26.020
And on this one, I'm pretty sure when I upgraded it to Pydantic 2 and ran it again,


00:49:26.020 --> 00:49:29.060
trying to think of all the variations that you know, there could be something


00:49:29.060 --> 00:49:31.460
that has changed that I wasn't aware of, like maybe,


00:49:31.460 --> 00:49:36.260
maybe I recorded it on my M1 Mac Mini and then ran it again on my M2 Pro Mac Mini,


00:49:36.260 --> 00:49:39.700
so that could affect it by like a little bit as well, like 20%.


00:49:39.700 --> 00:49:47.460
But I think just, so using Beanie and FastAPI and upgrading all those paths to Pydantic 2


00:49:47.460 --> 00:49:50.340
and the respective Beanie and FastAPI versions,


00:49:50.340 --> 00:49:52.860
I think it went 50% or double fast,


00:49:52.860 --> 00:49:55.060
two times as fast, 100% faster,


00:49:55.060 --> 00:49:56.500
just by making that change.


00:49:56.500 --> 00:49:58.260
So that was pretty awesome.


00:49:58.260 --> 00:49:59.700
- This is great, yeah.


00:49:59.700 --> 00:50:03.300
Yeah, I see this 50% also and yeah.


00:50:03.300 --> 00:50:06.060
- All I did is I just reran pip tools


00:50:06.060 --> 00:50:07.940
to get the new versions of everything


00:50:07.940 --> 00:50:09.340
and reran the load tests


00:50:09.340 --> 00:50:11.740
and look how much faster they are.


00:50:11.740 --> 00:50:13.180
And so that's a real cool example


00:50:13.180 --> 00:50:14.340
of kind of what I was talking about.


00:50:14.340 --> 00:50:16.660
So yeah, if you wanna see all this stuff in action,


00:50:16.660 --> 00:50:19.760
Check out the MongoDB with Async Python course.


00:50:19.760 --> 00:50:21.760
Thanks for coming on the show and


00:50:21.760 --> 00:50:27.060
updating us on Beanie and especially giving us this look into your journey of migrating


00:50:27.060 --> 00:50:29.560
based on Pydantic 1.2. I think that's really cool.


00:50:29.560 --> 00:50:30.760
Yeah, thank you very much.


00:50:30.760 --> 00:50:31.760
It's a great time, it's here.


00:50:31.760 --> 00:50:34.360
Of course. So, before you get out of here,


00:50:34.360 --> 00:50:38.160
got a PyPI project library to recommend to people?


00:50:38.160 --> 00:50:41.460
Something besides, of course, Beanie and Pydantic, which are pretty


00:50:41.460 --> 00:50:42.360
awesome and obvious.


00:50:42.360 --> 00:50:43.960
I would recommend to use Motor.


00:50:43.960 --> 00:50:47.520
This is, this is kind of PyMongo, but asynchronous.


00:50:47.520 --> 00:50:51.360
Integrates with async and await perfectly, which is real, real nice.


00:50:51.360 --> 00:50:55.600
If you want to do something more low level than, than Beanie,


00:50:55.600 --> 00:50:59.840
then you have to at least meet with Mojo because this is really nice library.


00:50:59.840 --> 00:51:04.480
And even after that many years, it's still very actual.


00:51:04.480 --> 00:51:07.960
And what else? Honestly, I don't have anything in my mind.


00:51:07.960 --> 00:51:09.720
Kind of just Pydentics.


00:51:09.720 --> 00:51:11.520
Yeah, Pydentics, good stuff. Awesome.


00:51:11.520 --> 00:51:13.880
Okay, I'll throw Locust out there for people.


00:51:13.880 --> 00:51:15.380
They can check out Locust. That's pretty cool.


00:51:15.380 --> 00:51:17.780
If you are going through the same process,


00:51:17.780 --> 00:51:21.680
you've got code built on Beanie or just Pydantic in general,


00:51:21.680 --> 00:51:26.320
and you want to see, you know, how does my system respond before and after,


00:51:26.320 --> 00:51:28.720
Locust is like ridiculously easy to set up.


00:51:28.720 --> 00:51:30.220
Run it against your code,


00:51:30.220 --> 00:51:32.320
pip install upgrade,


00:51:32.320 --> 00:51:34.020
run it again, and just see what happens.


00:51:34.020 --> 00:51:36.320
I think that'll be a really good recommendation too.


00:51:36.320 --> 00:51:37.580
Yeah, final call to action.


00:51:37.580 --> 00:51:39.580
People want to get started with Beanie.


00:51:39.580 --> 00:51:42.300
maybe people out there already using Beanie want to upgrade their code.


00:51:42.300 --> 00:51:42.820
What do you tell them?


00:51:42.820 --> 00:51:43.820
Just pip install it.


00:51:43.820 --> 00:51:46.140
Everything would be, would work fine.


00:51:46.140 --> 00:51:47.380
So just try it.


00:51:47.380 --> 00:51:49.900
But at least you have to upgrade everything.


00:51:49.900 --> 00:51:51.620
So please write tests.


00:51:51.620 --> 00:51:52.780
Absolutely.


00:51:52.780 --> 00:51:57.940
And if something will go wrong, go to my Discord channel and me or other


00:51:57.940 --> 00:51:59.500
people will answer your questions.


00:51:59.500 --> 00:52:00.060
Sounds good.


00:52:00.060 --> 00:52:00.500
All right.


00:52:00.500 --> 00:52:02.940
Well, congrats on upgrading Beanie.


00:52:02.940 --> 00:52:04.700
You must be really happy to have it done.


00:52:04.700 --> 00:52:05.260
Yeah, I think.


00:52:05.260 --> 00:52:06.020
I think very much.


00:52:06.020 --> 00:52:07.060
Yeah, you bet.


00:52:07.060 --> 00:52:07.740
See you later.


00:52:07.740 --> 00:52:08.060
See you.


00:52:09.420 --> 00:52:12.700
This has been another episode of Talk Python to Me.


00:52:12.700 --> 00:52:14.140
Thank you to our sponsors.


00:52:14.140 --> 00:52:15.500
Be sure to check out what they're offering.


00:52:15.500 --> 00:52:17.580
It really helps support the show.


00:52:17.580 --> 00:52:20.660
Studio 3T is the IDE that gives you full visual control


00:52:20.660 --> 00:52:22.380
of your MongoDB data.


00:52:22.380 --> 00:52:24.480
With the drag and drop visual query builder


00:52:24.480 --> 00:52:27.140
and multi-language query code generator,


00:52:27.140 --> 00:52:29.740
new users will find they're up to speed in no time.


00:52:29.740 --> 00:52:32.820
You can even query MongoDB directly with SQL


00:52:32.820 --> 00:52:35.940
and migrate tabular data easily from relational DBs


00:52:35.940 --> 00:52:37.620
into MongoDB documents.


00:52:37.620 --> 00:52:43.620
Try Studio 3T for free at talkpython.fm/studio2023.


00:52:43.620 --> 00:52:44.960
Want to level up your Python?


00:52:44.960 --> 00:52:49.080
We have one of the largest catalogs of Python video courses over at Talk Python.


00:52:49.080 --> 00:52:54.120
Our content ranges from true beginners to deeply advanced topics like memory and async.


00:52:54.120 --> 00:52:56.780
And best of all, there's not a subscription in sight.


00:52:56.780 --> 00:52:59.820
Check it out for yourself at training.talkpython.fm.


00:52:59.820 --> 00:53:04.460
Be sure to subscribe to the show, open your favorite podcast app, and search for Python.


00:53:04.460 --> 00:53:05.820
We should be right at the top.


00:53:05.820 --> 00:53:08.720
You can also find the iTunes feed at /itunes,


00:53:08.720 --> 00:53:10.920
the Google Play feed at /play,


00:53:10.920 --> 00:53:15.820
and the Direct RSS feed at /rss on talkpython.fm.


00:53:15.820 --> 00:53:18.420
We're live streaming most of our recordings these days.


00:53:18.420 --> 00:53:21.820
If you want to be part of the show and have your comments featured on the air,


00:53:21.820 --> 00:53:26.720
be sure to subscribe to our YouTube channel at talkpython.fm/youtube.


00:53:26.720 --> 00:53:28.120
This is your host, Michael Kennedy.


00:53:28.120 --> 00:53:30.520
Thanks so much for listening. I really appreciate it.


00:53:30.520 --> 00:53:32.720
Now get out there and write some Python code.


00:53:32.720 --> 00:53:42.720
[MUSIC]


00:53:42.720 --> 00:53:45.300
(upbeat music)


00:53:45.300 --> 00:53:48.660
[MUSIC PLAYING]


00:53:48.660 --> 00:53:52.000
[MUSIC PLAYING]


00:53:52.000 --> 00:54:02.000
[BLANK_AUDIO]

