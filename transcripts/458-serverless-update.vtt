WEBVTT

00:00:00.000 --> 00:00:04.480
What is the status of serverless computing and Python in 2024?

00:00:04.480 --> 00:00:06.960
What are some of the new tools and best practices?

00:00:06.960 --> 00:00:09.200
Well, we're lucky to have Tony Sherman,

00:00:09.200 --> 00:00:11.600
who has a lot of practical experience

00:00:11.600 --> 00:00:14.320
with serverless programming on the show.

00:00:14.320 --> 00:00:17.360
This is "Talk Python To Me," episode 458,

00:00:17.360 --> 00:00:20.640
recorded January 25th, 2024.

00:00:20.640 --> 00:00:23.220
(upbeat music)

00:00:25.800 --> 00:00:38.120
Welcome to "Talk Python To Me," a weekly podcast on Python.

00:00:38.120 --> 00:00:39.900
This is your host, Michael Kennedy.

00:00:39.900 --> 00:00:42.260
Follow me on Mastodon, where I'm @mkennedy,

00:00:42.260 --> 00:00:44.980
and follow the podcast using @talkpython,

00:00:44.980 --> 00:00:47.540
both on fosstodon.org.

00:00:47.540 --> 00:00:49.660
Keep up with the show and listen to over seven years

00:00:49.660 --> 00:00:52.780
of past episodes at talkpython.fm.

00:00:52.780 --> 00:00:56.260
We've started streaming most of our episodes live on YouTube.

00:00:56.260 --> 00:00:57.460
Subscribe to our YouTube channel

00:00:57.460 --> 00:00:59.860
over at talkpython.fm/youtube

00:00:59.860 --> 00:01:02.060
to get notified about upcoming shows

00:01:02.060 --> 00:01:04.060
and be part of that episode.

00:01:04.060 --> 00:01:06.080
This episode is brought to you by Sentry.

00:01:06.080 --> 00:01:07.580
Don't let those errors go unnoticed.

00:01:07.580 --> 00:01:09.740
Use Sentry like we do here at Talk Python.

00:01:09.740 --> 00:01:13.220
Sign up at talkpython.fm/sentry.

00:01:13.220 --> 00:01:15.580
And it's brought to you by Mailtrap,

00:01:15.580 --> 00:01:18.680
an email delivery platform that developers love.

00:01:18.680 --> 00:01:22.020
Try for free at mailtrap.io.

00:01:22.020 --> 00:01:24.340
Tony, welcome to Talk Python to me.

00:01:24.340 --> 00:01:25.180
- Thank you.

00:01:25.180 --> 00:01:26.000
Thanks for having me.

00:01:26.000 --> 00:01:27.380
- Fantastic to have you here.

00:01:27.380 --> 00:01:30.060
Gonna be really fun to talk about serverless.

00:01:30.060 --> 00:01:32.340
You know, the joke with the cloud is,

00:01:32.340 --> 00:01:34.060
well, I know you call it the cloud,

00:01:34.060 --> 00:01:36.060
but it's really just somebody else's computer.

00:01:36.060 --> 00:01:37.820
But we're not even talking about computers,

00:01:37.820 --> 00:01:39.000
we're just talking about functions.

00:01:39.000 --> 00:01:40.140
Maybe it's someone else's function.

00:01:40.140 --> 00:01:41.260
I don't know, we're gonna find out.

00:01:41.260 --> 00:01:42.100
- Yeah, I actually,

00:01:42.100 --> 00:01:45.400
I saw a recent article about server-free.

00:01:45.400 --> 00:01:48.860
Recently, somebody trying to, yeah, move completely.

00:01:48.860 --> 00:01:50.980
Yes, yeah, because as you might know,

00:01:50.980 --> 00:01:53.780
serverless doesn't mean actually no servers.

00:01:53.780 --> 00:01:55.380
- Of course, of course.

00:01:55.380 --> 00:01:56.540
Server-free, all right.

00:01:56.540 --> 00:01:59.220
So we could just get the thing

00:01:59.220 --> 00:02:01.100
to run on the BitTorrent network.

00:02:01.100 --> 00:02:01.940
Got it, okay.

00:02:01.940 --> 00:02:02.900
- Yeah.

00:02:02.900 --> 00:02:05.260
- I don't know, I don't know, we'll figure it out.

00:02:05.260 --> 00:02:06.300
But it's gonna be super fun.

00:02:06.300 --> 00:02:08.940
We're gonna talk about your experience

00:02:08.940 --> 00:02:10.180
working with serverless.

00:02:10.180 --> 00:02:12.900
We'll talk about some of the choices people have out there

00:02:12.900 --> 00:02:15.740
and also some of the tools that we can use

00:02:15.740 --> 00:02:19.540
to do things like observe and test our serverless code.

00:02:19.540 --> 00:02:22.020
Before that though, tell us a bit about yourself.

00:02:22.020 --> 00:02:26.900
- Sure, so I'm actually a career changer.

00:02:26.900 --> 00:02:31.700
So I worked in the cable industry for about 10 years

00:02:31.700 --> 00:02:34.820
and doing a lot of different things

00:02:34.820 --> 00:02:38.220
from installing, knock at the door cable guy

00:02:38.220 --> 00:02:40.700
to working on more of the outside plant.

00:02:40.700 --> 00:02:42.740
But it just, at some point,

00:02:42.740 --> 00:02:46.820
I was seeing limits of career path there.

00:02:46.820 --> 00:02:50.500
And so my brother-in-law is a software engineer

00:02:50.500 --> 00:02:54.140
and I had already started going back to school,

00:02:54.140 --> 00:02:55.180
finishing my degree and I was like,

00:02:55.180 --> 00:02:57.900
okay, well maybe I should look into this.

00:02:57.900 --> 00:03:00.540
And so I took an intro to programming class.

00:03:00.540 --> 00:03:05.540
It was in Python and that just led me down this path.

00:03:05.540 --> 00:03:07.980
So now for the past four years or so,

00:03:07.980 --> 00:03:10.020
been working professionally in the software world,

00:03:10.020 --> 00:03:14.660
started out in a QA role at an IOT company.

00:03:14.660 --> 00:03:18.700
And now, yeah, doing a lot of serverless programming

00:03:18.700 --> 00:03:20.220
in Python these days.

00:03:20.220 --> 00:03:21.180
Second company now,

00:03:21.180 --> 00:03:24.260
but that does some school bus safety products.

00:03:24.260 --> 00:03:26.500
- Interesting, very cool.

00:03:26.500 --> 00:03:27.420
- Yeah, yep.

00:03:27.420 --> 00:03:29.860
But a lot of Python and a lot of serverless.

00:03:29.860 --> 00:03:33.020
- Well, serverless and IOT,

00:03:33.020 --> 00:03:34.820
feel like they go pretty hand in hand.

00:03:34.820 --> 00:03:36.220
- Yes, yep.

00:03:36.220 --> 00:03:39.300
Yeah, another thing is with serverless

00:03:39.300 --> 00:03:42.300
is when you have very like spiky traffic,

00:03:42.300 --> 00:03:44.060
like if you think about school buses

00:03:44.060 --> 00:03:47.900
that you have a lot coming on twice a day.

00:03:47.900 --> 00:03:50.260
- Exactly, like the 8 a.m. shift

00:03:50.260 --> 00:03:52.740
and then the 2.30 to 3.00 shift.

00:03:52.740 --> 00:03:55.380
- So yeah, that's a really good use case for serverless

00:03:55.380 --> 00:03:57.100
is something like that.

00:03:57.100 --> 00:04:01.060
- Okay, are you enjoying doing the programming stuff?

00:04:01.060 --> 00:04:02.140
So the cable stuff?

00:04:02.140 --> 00:04:03.500
- Absolutely.

00:04:03.500 --> 00:04:05.140
Sometimes I live in Michigan,

00:04:05.140 --> 00:04:08.580
so I look outside and look at the snow coming down

00:04:08.580 --> 00:04:11.700
or these storms and yeah, I just,

00:04:12.580 --> 00:04:14.060
yeah, I really, some people are like,

00:04:14.060 --> 00:04:14.980
you don't miss being outside?

00:04:14.980 --> 00:04:16.700
I'm like, maybe every once in a while,

00:04:16.700 --> 00:04:19.020
but I can go walk outside on a nice day.

00:04:19.020 --> 00:04:21.620
- You can choose to go outside.

00:04:21.620 --> 00:04:24.700
You're not ready to go outside in the sleet or rain.

00:04:24.700 --> 00:04:25.660
- Yeah.

00:04:25.660 --> 00:04:26.540
- Yeah, absolutely.

00:04:26.540 --> 00:04:29.060
We just had a mega storm here

00:04:29.060 --> 00:04:31.740
and just the huge tall trees here in Oregon

00:04:31.740 --> 00:04:33.140
just fell left and right.

00:04:33.140 --> 00:04:36.180
And there's in every direction that I look,

00:04:36.180 --> 00:04:39.420
there's a large tree on top of one of the houses

00:04:39.420 --> 00:04:42.460
of my neighbors, maybe a house or two over.

00:04:42.460 --> 00:04:44.140
But it just took out all the,

00:04:44.140 --> 00:04:46.260
everything that was a cable in the air was taken out.

00:04:46.260 --> 00:04:47.940
So it's just been a swarm of people

00:04:47.940 --> 00:04:50.860
who are out in 13 degree Fahrenheit,

00:04:50.860 --> 00:04:52.860
negative nine Celsius weather.

00:04:52.860 --> 00:04:53.700
And I'm thinking,

00:04:53.700 --> 00:04:56.820
not really choosing to be out there today probably.

00:04:56.820 --> 00:04:57.660
Excellent.

00:04:57.660 --> 00:04:59.780
Well, thanks for that introduction.

00:04:59.780 --> 00:05:01.100
I guess maybe we could,

00:05:01.100 --> 00:05:02.940
a lot of people probably know what serverless is,

00:05:02.940 --> 00:05:05.700
but I'm sure there's a lot who are not even really aware

00:05:05.700 --> 00:05:08.340
of what serverless programming is, right?

00:05:08.340 --> 00:05:09.300
- Yes.

00:05:09.300 --> 00:05:10.900
- Let's talk about what's the idea,

00:05:10.900 --> 00:05:13.180
what's the zen of this?

00:05:13.180 --> 00:05:14.020
- Yeah.

00:05:14.020 --> 00:05:16.860
So yeah, I kind of made the joke that serverless

00:05:16.860 --> 00:05:18.420
doesn't mean there are no servers,

00:05:18.420 --> 00:05:22.740
but, and there's, hopefully I don't butcher it too much,

00:05:22.740 --> 00:05:25.740
but it's more like functions as a service.

00:05:25.740 --> 00:05:28.260
There's other things that can be serverless too.

00:05:28.260 --> 00:05:30.980
Like there's serverless databases

00:05:30.980 --> 00:05:35.340
or a lot of different services that can be serverless,

00:05:35.340 --> 00:05:37.180
meaning you don't have to think about like

00:05:37.180 --> 00:05:38.220
how to operate them,

00:05:38.220 --> 00:05:40.420
how to think about scaling them up.

00:05:40.420 --> 00:05:43.940
You don't have to spin up VMs

00:05:43.940 --> 00:05:46.060
or Kubernetes clusters or anything.

00:05:46.060 --> 00:05:48.380
You don't have to think about that part.

00:05:48.380 --> 00:05:51.380
It's just your code that goes into it.

00:05:51.380 --> 00:05:53.700
And so yeah, serverless functions

00:05:53.700 --> 00:05:55.580
are probably what people are most familiar with.

00:05:55.580 --> 00:05:58.180
And that's, I'm sure what we'll talk about most today.

00:05:58.180 --> 00:06:01.620
But yeah, that's really the idea.

00:06:01.620 --> 00:06:05.420
You don't have to manage the server.

00:06:05.420 --> 00:06:06.260
- Sure.

00:06:06.260 --> 00:06:07.660
And that's a huge barrier.

00:06:07.700 --> 00:06:11.660
I remember when I first started getting into web apps

00:06:11.660 --> 00:06:14.220
and programming and then another level

00:06:14.220 --> 00:06:15.420
when I got into Python,

00:06:15.420 --> 00:06:18.420
because I had not done that much Linux work,

00:06:18.420 --> 00:06:21.180
getting stuff up running, it was really tricky.

00:06:21.180 --> 00:06:24.580
And then having the concern of, is it secure?

00:06:24.580 --> 00:06:25.420
How do I patch it?

00:06:25.420 --> 00:06:26.500
How do I back it up?

00:06:26.500 --> 00:06:28.220
How do I keep it going?

00:06:28.220 --> 00:06:31.300
All of those things, they're non-trivial, right?

00:06:31.300 --> 00:06:32.140
- Right.

00:06:32.140 --> 00:06:32.980
Yeah, yeah.

00:06:32.980 --> 00:06:33.900
There's a lot to think about.

00:06:33.900 --> 00:06:36.900
And if you like work at an organization,

00:06:36.900 --> 00:06:39.140
it's probably different everywhere you go too,

00:06:39.140 --> 00:06:42.060
that how they manage their servers and things.

00:06:42.060 --> 00:06:44.300
So putting in some stuff in the cloud

00:06:44.300 --> 00:06:46.860
kind of brings some commonality to it too.

00:06:46.860 --> 00:06:51.860
Like you can learn how the Azure cloud or Google cloud

00:06:51.860 --> 00:06:53.660
or AWS, how those things work

00:06:53.660 --> 00:06:55.980
and kind of have some common ground too.

00:06:55.980 --> 00:06:58.260
- Yeah, for sure.

00:06:58.260 --> 00:07:01.060
Like having, also feels more accessible

00:07:01.060 --> 00:07:04.220
to the developers in a larger group,

00:07:04.220 --> 00:07:06.540
in the sense that it's not a DevOps team

00:07:06.540 --> 00:07:08.900
that kind of takes care of the servers

00:07:08.900 --> 00:07:11.780
or a production engineers where you hand them your code.

00:07:11.780 --> 00:07:14.380
It's a little closer to just, I have a function

00:07:14.380 --> 00:07:15.220
and then I get it up there

00:07:15.220 --> 00:07:17.420
and it continues to be the function, you know?

00:07:17.420 --> 00:07:19.820
- Yeah, and that is a different mindset too.

00:07:19.820 --> 00:07:21.380
You kind of see it all the way through

00:07:21.380 --> 00:07:24.040
from writing your code to deploying it.

00:07:24.040 --> 00:07:28.700
Yeah, without maybe an entire DevOps team

00:07:28.700 --> 00:07:32.340
that you just kind of say, here you go, go deploy this.

00:07:32.340 --> 00:07:33.180
- Yeah.

00:07:33.420 --> 00:07:37.420
In my world, I mostly have virtual machines.

00:07:37.420 --> 00:07:40.580
I've moved over to kind of a Docker cluster.

00:07:40.580 --> 00:07:43.440
I think I've got 17 different things

00:07:43.440 --> 00:07:45.340
running in the Docker cluster at the moment,

00:07:45.340 --> 00:07:46.940
but both of those are really different

00:07:46.940 --> 00:07:48.940
than serverless, right?

00:07:48.940 --> 00:07:49.780
- Yeah.

00:07:49.780 --> 00:07:52.220
- Yeah, so it's been working well for me,

00:07:52.220 --> 00:07:53.980
but when I think about serverless,

00:07:53.980 --> 00:07:55.300
let me know if this is true.

00:07:55.300 --> 00:08:00.060
It feels like you don't need to have as much of a Linux

00:08:00.060 --> 00:08:03.540
or server or sort of an ops experience

00:08:03.540 --> 00:08:05.140
to create these things.

00:08:05.140 --> 00:08:07.580
- Yeah, I would say like you could probably get away

00:08:07.580 --> 00:08:09.320
with like almost none, right?

00:08:09.320 --> 00:08:11.780
Like at the simplest form,

00:08:11.780 --> 00:08:16.780
like with like AWS, for instance, their Lambda functions,

00:08:16.780 --> 00:08:19.760
you can, and that's the one I'm most familiar with.

00:08:19.760 --> 00:08:22.860
So forgive me for using them as an example for everything.

00:08:22.860 --> 00:08:26.300
There's a lot of different serverless options,

00:08:26.300 --> 00:08:29.460
but you could go into the AWS console

00:08:29.460 --> 00:08:33.820
and you could actually write your Python code

00:08:33.820 --> 00:08:36.140
right in the console, deploy that.

00:08:36.140 --> 00:08:38.140
They have function URLs now.

00:08:38.140 --> 00:08:39.980
So you could actually have like,

00:08:39.980 --> 00:08:41.500
I mean, within a matter of minutes,

00:08:41.500 --> 00:08:44.020
you can have a serverless function set up.

00:08:44.020 --> 00:08:45.460
And so, yeah.

00:08:45.460 --> 00:08:47.060
- AWS Lambda, right?

00:08:47.060 --> 00:08:48.580
That's the one. - Yes, yep.

00:08:48.580 --> 00:08:50.740
- Lambda being, I guess, a simple function, right?

00:08:50.740 --> 00:08:51.940
We have Lambdas in Python.

00:08:51.940 --> 00:08:53.780
They can only be one line.

00:08:53.780 --> 00:08:56.740
I'm sure you can have more than one line in the AWS Lambda.

00:08:56.740 --> 00:08:58.660
- Yeah, there are limitations though

00:08:58.660 --> 00:09:02.860
with Lambda that are definitely some pain points

00:09:02.860 --> 00:09:04.140
that I ran into, so.

00:09:04.140 --> 00:09:04.980
- Oh, really?

00:09:04.980 --> 00:09:05.940
Okay, what are some of the limitations?

00:09:05.940 --> 00:09:09.780
- Yeah, so package size is one.

00:09:09.780 --> 00:09:12.220
So if you start thinking about all these

00:09:12.220 --> 00:09:15.740
like amazing packages on PyPI,

00:09:15.740 --> 00:09:17.420
you do have to start thinking about

00:09:17.420 --> 00:09:19.740
how many you're gonna bring in.

00:09:19.740 --> 00:09:24.420
So, and I don't know the exact limits off the top of my head,

00:09:24.420 --> 00:09:26.180
but it's, yeah, pretty quick Google search

00:09:26.180 --> 00:09:28.020
on their package size.

00:09:28.020 --> 00:09:30.460
It might be like 50 megabytes zipped,

00:09:30.460 --> 00:09:35.460
but 250 when you decompress it to do a zip base,

00:09:35.460 --> 00:09:39.620
then they do have containerized Lambda functions

00:09:39.620 --> 00:09:41.100
that go up to like a 10 gig limit.

00:09:41.100 --> 00:09:42.460
So that helps, but.

00:09:42.460 --> 00:09:43.540
- Interesting, okay.

00:09:43.540 --> 00:09:47.500
- Yeah, yeah, those ones used to be less performant,

00:09:47.500 --> 00:09:49.940
but they're kind of catching up to where they're,

00:09:49.940 --> 00:09:53.420
that was really on something called cold starts,

00:09:53.420 --> 00:09:56.820
but they're getting, I think, pretty close to it,

00:09:56.820 --> 00:09:59.940
not being a very big difference

00:09:59.940 --> 00:10:02.020
whether you dockerize or zip these functions,

00:10:02.020 --> 00:10:05.700
but yeah, so when you start just like pip install

00:10:05.700 --> 00:10:07.140
and everything, you've got to think about

00:10:07.140 --> 00:10:09.740
how to get that code into your function

00:10:09.740 --> 00:10:13.580
and how much it's gonna bring in.

00:10:13.580 --> 00:10:16.620
So yeah, that definitely was a limitation

00:10:16.620 --> 00:10:19.940
that I had to quickly learn.

00:10:19.940 --> 00:10:21.980
- Yeah, I guess it's probably trying to do

00:10:21.980 --> 00:10:24.620
pip install -r effectively.

00:10:24.620 --> 00:10:25.460
- Yeah.

00:10:25.460 --> 00:10:28.100
- And it's like, you can't go overboard with this, right?

00:10:28.100 --> 00:10:29.900
- Right, yeah, yeah.

00:10:29.900 --> 00:10:31.180
When you start bringing in packages,

00:10:31.180 --> 00:10:35.540
like maybe like some of the scientific packages,

00:10:35.540 --> 00:10:38.500
you're definitely gonna be hitting some size limits.

00:10:38.500 --> 00:10:40.620
- Okay, and with the containerized ones,

00:10:40.620 --> 00:10:42.940
basically you probably give it a Docker file

00:10:42.940 --> 00:10:44.500
and a command to run in it,

00:10:44.500 --> 00:10:47.060
and it can build those images before

00:10:47.060 --> 00:10:49.060
and then just execute and just do a Docker run.

00:10:49.060 --> 00:10:51.100
- Yeah, I think how those ones work

00:10:51.100 --> 00:10:55.860
is you store an image on like their container registry,

00:10:55.860 --> 00:10:58.940
Amazon's, is it ECR, I think.

00:10:58.940 --> 00:11:01.020
And so then you kind of point it at that

00:11:01.020 --> 00:11:06.020
and yeah, it'll execute your like handler function

00:11:06.020 --> 00:11:08.380
when the Lambda gets called, so.

00:11:08.380 --> 00:11:11.260
- This portion of Talk Python to Me

00:11:11.260 --> 00:11:12.140
is brought to you by

00:11:12.140 --> 00:11:15.620
Multi-Platform Error Monitoring at Sentry.

00:11:15.620 --> 00:11:17.500
Code breaks, it's a fact of life.

00:11:17.500 --> 00:11:20.300
With Sentry, you can fix it faster.

00:11:20.300 --> 00:11:21.820
Does your team or company work

00:11:21.820 --> 00:11:24.380
on multiple platforms that collaborate?

00:11:24.380 --> 00:11:27.100
Chances are extremely high that they do.

00:11:27.100 --> 00:11:29.820
It might be a React or Vue front-end JavaScript app

00:11:29.820 --> 00:11:32.940
that talks to your FastAPI backend services.

00:11:32.940 --> 00:11:34.700
Could be a Go microservice

00:11:34.700 --> 00:11:36.460
talking to your Python microservice,

00:11:36.460 --> 00:11:38.380
or even native mobile apps

00:11:38.380 --> 00:11:41.620
talking to your Python backend APIs.

00:11:41.620 --> 00:11:43.060
Now let me ask you a question.

00:11:43.060 --> 00:11:45.580
Whatever combination of these that applies to you,

00:11:45.580 --> 00:11:47.900
how tightly do these teams work together?

00:11:47.900 --> 00:11:49.380
Especially if there are errors

00:11:49.380 --> 00:11:50.940
originating at one layer,

00:11:50.940 --> 00:11:53.340
but becoming visible at the other.

00:11:53.340 --> 00:11:55.380
It can be super hard to track these errors

00:11:55.380 --> 00:11:57.580
across platforms and devices,

00:11:57.580 --> 00:11:58.860
but Sentry has you covered.

00:11:58.860 --> 00:12:01.740
They support many JavaScript front-end frameworks,

00:12:01.740 --> 00:12:04.900
obviously Python backend, such as FastAPI and Django,

00:12:04.900 --> 00:12:07.540
and they even support native mobile apps.

00:12:07.540 --> 00:12:09.180
For example, at Talk Python,

00:12:09.180 --> 00:12:11.340
we have Sentry integrated into our mobile apps

00:12:11.340 --> 00:12:12.620
for our courses.

00:12:12.620 --> 00:12:14.060
Those apps are built and compiled

00:12:14.060 --> 00:12:15.600
in native code with Flutter.

00:12:15.600 --> 00:12:17.760
With Sentry, it's literally a few lines of code

00:12:17.760 --> 00:12:19.580
to start tracking those errors.

00:12:19.580 --> 00:12:20.740
Don't fly blind.

00:12:20.740 --> 00:12:22.420
Fix code faster with Sentry.

00:12:22.420 --> 00:12:25.740
Create your Sentry account at talkpython.fm/sentry.

00:12:25.740 --> 00:12:27.780
And if you sign up with the code TALKPYTHON,

00:12:27.780 --> 00:12:29.580
one word, all caps,

00:12:29.580 --> 00:12:32.180
it's good for two free months of Sentry's business plan,

00:12:32.180 --> 00:12:34.980
which will give you up to 20 times as many monthly events,

00:12:34.980 --> 00:12:36.880
as well as some other cool features.

00:12:36.880 --> 00:12:39.780
My thanks to Sentry for supporting Talk Python to me.

00:12:39.780 --> 00:12:42.820
- Yeah, so out in the audience,

00:12:42.820 --> 00:12:47.300
Kim says, "AWS does make a few packages available directly

00:12:47.300 --> 00:12:48.760
just by default in Lambda."

00:12:48.760 --> 00:12:49.600
That's kind of nice.

00:12:49.600 --> 00:12:50.420
- Yeah, yep.

00:12:50.420 --> 00:12:54.700
So yeah, Bodo, which if you're dealing with AWS and Python,

00:12:54.700 --> 00:12:57.840
you're using the Bodo package.

00:12:57.840 --> 00:12:59.700
And yeah, that's included for you.

00:12:59.700 --> 00:13:02.460
So that's definitely helpful in any of their,

00:13:02.460 --> 00:13:04.360
transitive dependencies would be there.

00:13:04.360 --> 00:13:08.460
I think Bodo used to even include like requests,

00:13:08.460 --> 00:13:11.120
but then I think they eventually dropped that

00:13:11.120 --> 00:13:12.800
with some like SSL stuff.

00:13:12.800 --> 00:13:15.960
But yeah, you definitely,

00:13:15.960 --> 00:13:17.560
you can't just like pip install anything

00:13:17.560 --> 00:13:19.000
and not think of it,

00:13:19.000 --> 00:13:21.440
unless depending on how you package these up.

00:13:21.440 --> 00:13:22.440
So. - Sure.

00:13:22.440 --> 00:13:23.560
Sure, that makes sense.

00:13:23.560 --> 00:13:25.920
Of course they would include their own Python libraries.

00:13:25.920 --> 00:13:26.760
Right?

00:13:26.760 --> 00:13:28.120
- Yeah, and it's not a,

00:13:28.120 --> 00:13:29.860
yeah, it's not exactly small.

00:13:29.860 --> 00:13:34.340
I think like Bodo core used to be like 60 megabytes,

00:13:34.340 --> 00:13:37.000
but I think they've done some work to really get that down.

00:13:37.000 --> 00:13:37.920
So.

00:13:37.920 --> 00:13:40.480
- Yeah, yeah, that's, yeah, that's not too bad.

00:13:40.480 --> 00:13:42.620
I feel like Bodo core, Bodo three,

00:13:42.620 --> 00:13:45.500
those are constantly changing, like constantly.

00:13:45.500 --> 00:13:50.500
- Yeah, yeah, well, as fast as AWS ad services,

00:13:50.500 --> 00:13:52.920
that they'll probably keep changing quickly.

00:13:52.920 --> 00:13:55.880
- Yeah, I feel like those are auto-generated maybe,

00:13:55.880 --> 00:13:58.280
just from looking at the way the API looks at it,

00:13:58.280 --> 00:14:00.000
you know, the way they look written.

00:14:00.000 --> 00:14:01.440
And so. - Yeah, yeah.

00:14:01.440 --> 00:14:04.360
That's probably the case, yeah.

00:14:04.360 --> 00:14:06.260
I know they do that with like their,

00:14:06.260 --> 00:14:09.440
their infrastructure is code CDK,

00:14:09.440 --> 00:14:11.320
it's all like TypeScript originally,

00:14:11.320 --> 00:14:14.200
and then you have your Python bindings for it and so.

00:14:14.200 --> 00:14:15.280
- Right, right, right, right.

00:14:15.280 --> 00:14:17.360
I mean, it makes sense, but at the same time,

00:14:17.360 --> 00:14:19.400
when you see a change, it doesn't necessarily mean,

00:14:19.400 --> 00:14:22.160
oh, there's a new important aspect added,

00:14:22.160 --> 00:14:23.600
it's probably just, I don't know,

00:14:23.600 --> 00:14:27.840
people have actually pulled up the console for AWS,

00:14:27.840 --> 00:14:30.360
but just the amount of services that are there.

00:14:30.360 --> 00:14:32.920
And then each one of those has its own full API,

00:14:32.920 --> 00:14:34.720
like a little bit of the one of those.

00:14:34.720 --> 00:14:37.440
So we regenerated it, but it might be for some part

00:14:37.440 --> 00:14:38.840
that you never, never call, right?

00:14:38.840 --> 00:14:41.740
Like you might only work with S3 and it's only changed,

00:14:41.740 --> 00:14:44.080
I don't know, EC2 stuff, right?

00:14:44.080 --> 00:14:46.320
- Right, yep, exactly.

00:14:46.320 --> 00:14:47.240
- Yeah, indeed.

00:14:47.240 --> 00:14:49.040
All right, well, let's talk real quickly

00:14:49.040 --> 00:14:53.320
about some of the places where we could do serverless, right?

00:14:53.320 --> 00:14:55.160
You've mentioned AWS Lambda.

00:14:55.160 --> 00:14:56.000
- Yep.

00:14:56.000 --> 00:14:57.520
- And I also maybe touch on

00:14:57.520 --> 00:15:00.920
just 1 million requests free per month.

00:15:00.920 --> 00:15:02.400
That's pretty cool. - Yeah, yeah.

00:15:02.400 --> 00:15:06.000
So yeah, getting like jumping into AWS

00:15:06.000 --> 00:15:06.880
sometimes sounds scary,

00:15:06.880 --> 00:15:08.880
but they have a pretty generous free tier.

00:15:08.880 --> 00:15:12.120
Definitely do your research on some of the security of this,

00:15:12.120 --> 00:15:16.240
but yeah, you can, a million requests free per month.

00:15:16.240 --> 00:15:18.280
You probably have to look into that a little bit

00:15:18.280 --> 00:15:22.300
because it's, you have your memory configurations too.

00:15:22.300 --> 00:15:25.600
So there's probably, I don't know exactly how that works

00:15:25.600 --> 00:15:28.240
within their free tier, but you're charged like,

00:15:28.240 --> 00:15:32.440
with Lambda at least it's your like invocation time

00:15:32.440 --> 00:15:34.960
and memory and also amount of requests.

00:15:34.960 --> 00:15:37.000
So yeah.

00:15:37.000 --> 00:15:39.320
- I'm always confused when I look at that and go,

00:15:39.320 --> 00:15:41.580
okay, with all of those variables,

00:15:41.580 --> 00:15:43.520
is that a lot or a little, I know it's a lot,

00:15:43.520 --> 00:15:45.840
but it's hard for me to conceptualize like,

00:15:45.840 --> 00:15:47.500
well, I use a little more memory than I thought.

00:15:47.500 --> 00:15:48.680
So it costs like, wait a minute,

00:15:48.680 --> 00:15:50.040
how do I know how much memory I use?

00:15:50.040 --> 00:15:51.240
You know, like. - Yeah.

00:15:51.240 --> 00:15:52.080
- What does this mean in practice?

00:15:52.080 --> 00:15:52.960
- And it's actually, yeah,

00:15:52.960 --> 00:15:55.520
it's built by how you configure it too.

00:15:55.520 --> 00:15:59.960
So if you say I need a Lambda with 10 gigs of memory,

00:15:59.960 --> 00:16:04.960
you're being built at that like 10 gigabyte price threshold.

00:16:04.960 --> 00:16:10.380
So there is a really, a really cool tool called PowerTooth

00:16:11.360 --> 00:16:13.380
or AWS Lambda PowerTuner.

00:16:13.380 --> 00:16:17.460
So yeah, what that'll do is you can,

00:16:17.460 --> 00:16:19.500
it creates a state machine in AWS.

00:16:19.500 --> 00:16:21.820
Yeah, I think I did send you a link to that one.

00:16:21.820 --> 00:16:26.820
So the PowerTuner will create a state machine

00:16:26.820 --> 00:16:29.140
that invocates your Lambda

00:16:29.140 --> 00:16:31.380
with several different memory configurations.

00:16:31.380 --> 00:16:32.200
And you can say,

00:16:32.200 --> 00:16:35.140
I want either the best cost optimized version

00:16:35.140 --> 00:16:37.980
or the best performance optimized version.

00:16:37.980 --> 00:16:41.140
So, and that'll tell you, like, it'll say,

00:16:41.140 --> 00:16:44.420
okay, yeah, you're best with a Lambda configured at,

00:16:44.420 --> 00:16:48.900
you know, 256 megabytes, you know, for memory.

00:16:48.900 --> 00:16:53.280
So, sorry, yeah, for the link, it's,

00:16:53.280 --> 00:16:54.140
this is PowerTools.

00:16:54.140 --> 00:16:56.480
This is a different amazing package.

00:16:56.480 --> 00:16:58.600
Maybe I didn't send you the PowerTuner.

00:16:58.600 --> 00:16:59.440
I should, okay, sorry.

00:16:59.440 --> 00:17:01.020
- It's news to me.

00:17:01.020 --> 00:17:03.100
I'll look and see. - Okay, sorry, yeah.

00:17:03.100 --> 00:17:04.620
And they have similar names.

00:17:04.620 --> 00:17:07.180
- Yeah, there's only so many ways to describe stuff.

00:17:07.180 --> 00:17:08.580
- Right, yeah, okay.

00:17:08.580 --> 00:17:10.220
They have it right in their AW, yep.

00:17:10.220 --> 00:17:11.780
- And it is an open source package.

00:17:11.780 --> 00:17:14.540
So there's probably a GitHub link in there, but yeah.

00:17:14.540 --> 00:17:17.640
And this will tell you like the best way

00:17:17.640 --> 00:17:19.780
to optimize your Lambda function,

00:17:19.780 --> 00:17:22.220
at least as far as memory is concerned.

00:17:22.220 --> 00:17:24.660
So, yeah, really good tool.

00:17:24.660 --> 00:17:25.780
It gives you a visualization,

00:17:25.780 --> 00:17:27.700
gives you a graph that will say like,

00:17:27.700 --> 00:17:31.380
okay, here's kind of where cost and performance meet.

00:17:31.380 --> 00:17:34.920
And so, yeah, it's really excellent

00:17:34.920 --> 00:17:36.800
for figuring that out.

00:17:36.800 --> 00:17:39.780
Yeah, at least in AWS land.

00:17:39.780 --> 00:17:42.140
I don't know if some of the other cloud providers

00:17:42.140 --> 00:17:43.560
have something similar to this,

00:17:43.560 --> 00:17:48.560
but yeah, it's definitely a really helpful tool.

00:17:48.560 --> 00:17:49.820
- Sure, yeah.

00:17:49.820 --> 00:17:51.340
Like I said, I'm confused

00:17:51.340 --> 00:17:52.860
and I've been doing cloud stuff for a long time

00:17:52.860 --> 00:17:53.700
when I look at it.

00:17:53.700 --> 00:17:55.500
- Yeah, so, well, there's some interesting things here.

00:17:55.500 --> 00:18:00.380
So like you can actually have a Lambda invocation

00:18:00.380 --> 00:18:04.380
that costs less with a higher memory configuration

00:18:04.380 --> 00:18:05.780
because it'll run faster.

00:18:05.780 --> 00:18:09.700
So you're, I think Lambda bills like by the millisecond now.

00:18:09.700 --> 00:18:12.940
So you can actually, because it runs faster,

00:18:12.940 --> 00:18:14.300
it can be cheaper to run.

00:18:14.300 --> 00:18:15.340
So. - Well, that explains

00:18:15.340 --> 00:18:17.420
all the rust that's been getting written.

00:18:17.420 --> 00:18:18.580
- Yeah, yeah.

00:18:18.580 --> 00:18:21.420
- There's a real number behind this.

00:18:21.420 --> 00:18:24.060
I mean, we need to go faster, right?

00:18:24.060 --> 00:18:27.740
Okay, so, I think maybe AWS Lambda

00:18:27.740 --> 00:18:29.860
is one of the very first ones as well

00:18:29.860 --> 00:18:32.620
to come on with this concept of serverless.

00:18:32.620 --> 00:18:36.580
- Yeah, I don't know for sure, but it probably is.

00:18:36.580 --> 00:18:38.760
And then, yeah, your other big cloud providers have them.

00:18:38.760 --> 00:18:41.700
And now you're actually even seeing them come up

00:18:41.700 --> 00:18:46.140
with a lot of like Vercel has some type

00:18:46.140 --> 00:18:47.340
of serverless function.

00:18:47.340 --> 00:18:50.320
I don't know what they're using behind it,

00:18:50.320 --> 00:18:53.380
but it's almost like they just put a nicer UI

00:18:53.380 --> 00:18:56.060
around AWS Lambda or whichever cloud provider

00:18:56.060 --> 00:18:58.420
that's potentially backing this up.

00:18:58.420 --> 00:18:59.260
But yeah.

00:18:59.260 --> 00:19:02.180
- They're just reselling their flavor

00:19:02.180 --> 00:19:04.100
of somebody else's cloud, yeah.

00:19:04.100 --> 00:19:05.820
- Yeah, it could be because, yeah,

00:19:05.820 --> 00:19:09.280
Vercel obviously they have a really nice suite

00:19:09.280 --> 00:19:12.040
of products with a good UI, very usable.

00:19:12.040 --> 00:19:13.160
So, yeah.

00:19:13.160 --> 00:19:16.120
- Okay, so Vercel, some of them people can try.

00:19:16.120 --> 00:19:20.040
And then we've got the two other hyperscale clouds,

00:19:20.040 --> 00:19:20.920
I guess you call them.

00:19:20.920 --> 00:19:22.840
Google Cloud has serverless, right?

00:19:22.840 --> 00:19:23.680
- Yep.

00:19:23.680 --> 00:19:24.500
- Okay, so.

00:19:24.500 --> 00:19:25.800
- I'm not sure which ones,

00:19:25.800 --> 00:19:27.960
they might just be called Cloud Functions.

00:19:27.960 --> 00:19:31.280
And yeah, Azure also has.

00:19:31.280 --> 00:19:33.160
- They got Cloud Run and Cloud Functions.

00:19:33.160 --> 00:19:35.800
I have no idea what the difference is though.

00:19:35.800 --> 00:19:39.860
- Yep, and yeah, Azure also has a serverless product.

00:19:39.860 --> 00:19:42.260
And I'd imagine there's probably like even more

00:19:42.260 --> 00:19:45.020
that we're not aware of, but yeah,

00:19:45.020 --> 00:19:48.260
it's kind of nice to not think about

00:19:48.260 --> 00:19:52.300
setting up servers for something, so.

00:19:52.300 --> 00:19:53.940
- I think maybe, is it FaaS?

00:19:53.940 --> 00:19:55.420
Yeah, Function as a Service, let's see.

00:19:55.420 --> 00:19:56.260
- Yeah.

00:19:56.260 --> 00:20:01.260
- But if we search for FaaS instead of PaaS or IaaS, right?

00:20:01.260 --> 00:20:04.900
There's, oh, we've got Almeda, Intel.

00:20:04.900 --> 00:20:06.520
I saw that IBM had some.

00:20:06.520 --> 00:20:10.080
Oh, there's also, we've got Digital Ocean.

00:20:10.080 --> 00:20:11.400
I'm a big fan of Digital Ocean

00:20:11.400 --> 00:20:14.160
because I feel like their pricing is really fair

00:20:14.160 --> 00:20:16.160
and they've got good documentation and stuff.

00:20:16.160 --> 00:20:21.160
So they've got functionless, sorry, serverless functions

00:20:21.160 --> 00:20:24.200
that you can, I don't use these.

00:20:24.200 --> 00:20:27.000
- Yeah, I haven't used these either, but yeah.

00:20:27.000 --> 00:20:29.360
And yeah, as far as costs,

00:20:29.360 --> 00:20:32.000
especially for small personal projects and things

00:20:32.020 --> 00:20:35.340
where you don't need to have a server on all the time,

00:20:35.340 --> 00:20:39.500
they're, yeah, pretty nice if you have a website

00:20:39.500 --> 00:20:41.000
that you need something server side

00:20:41.000 --> 00:20:42.380
where you gotta have some Python,

00:20:42.380 --> 00:20:44.300
but you don't need a server going all the time.

00:20:44.300 --> 00:20:45.140
Yeah, it's-

00:20:45.140 --> 00:20:47.640
- Okay, like maybe I have a static site,

00:20:47.640 --> 00:20:49.500
but then I want this one thing to happen

00:20:49.500 --> 00:20:51.380
if somebody clicks a button, something like that.

00:20:51.380 --> 00:20:53.180
- Yeah, yeah, absolutely.

00:20:53.180 --> 00:20:55.020
Yep, you could be completely static,

00:20:55.020 --> 00:20:57.260
but have something that is, yeah,

00:20:57.260 --> 00:21:00.340
yeah, that one function call that you do need, yeah.

00:21:00.340 --> 00:21:01.300
- Exactly.

00:21:01.300 --> 00:21:03.540
And then you also pointed out that Cloudflare

00:21:03.540 --> 00:21:05.580
has some form of serverless.

00:21:05.580 --> 00:21:07.900
- Yeah, and I haven't used these either,

00:21:07.900 --> 00:21:11.980
but yeah, I do know that they have some type of,

00:21:11.980 --> 00:21:15.940
functions as a service as well, so.

00:21:15.940 --> 00:21:18.080
- I don't know what frameworks for languages,

00:21:18.080 --> 00:21:19.860
they let you write them in there.

00:21:19.860 --> 00:21:23.340
I use bunny.net for my CDN,

00:21:23.340 --> 00:21:25.300
just absolutely awesome platform.

00:21:25.300 --> 00:21:26.140
I really, really love it.

00:21:26.140 --> 00:21:28.380
And one of the things that they've started offering,

00:21:28.380 --> 00:21:30.660
I can get this stupid, completely useless cookie banner

00:21:30.660 --> 00:21:35.660
to go away, is they've offered what they call edge compute.

00:21:35.660 --> 00:21:37.100
- Oh, yeah, okay.

00:21:37.100 --> 00:21:39.820
- What you would do, I don't know where to find it,

00:21:39.820 --> 00:21:44.820
somewhere maybe, but basically the CDN has 115,

00:21:44.820 --> 00:21:48.380
120 points of presence all over the world where,

00:21:48.380 --> 00:21:49.620
this one's close to Brazil,

00:21:49.620 --> 00:21:52.060
this one's close to Australia, whatever.

00:21:52.060 --> 00:21:55.300
But you can actually run serverless functions

00:21:55.300 --> 00:21:57.800
on those things, like, so you deploy them,

00:21:57.800 --> 00:22:01.500
so the code actually executes in 115 locations.

00:22:01.500 --> 00:22:02.500
- Yes, yeah.

00:22:02.500 --> 00:22:04.260
- Probably Cloudflare or something like that as well,

00:22:04.260 --> 00:22:05.180
but I don't know.

00:22:05.180 --> 00:22:10.180
- Yeah, AWS has, they have like Lambda at edge,

00:22:10.180 --> 00:22:13.140
at the edge, so that's kind of goes hand in hand

00:22:13.140 --> 00:22:17.660
with their like CDN CloudFront, I believe, yeah.

00:22:17.660 --> 00:22:19.200
So they have something similar like that,

00:22:19.200 --> 00:22:22.580
where you have a Lambda that's gonna be,

00:22:22.580 --> 00:22:26.140
perform it because it's distributed across their CDN.

00:22:26.140 --> 00:22:28.800
- Yeah, CDNs, that's a whole nother world.

00:22:28.800 --> 00:22:30.440
They're getting really advanced.

00:22:30.440 --> 00:22:31.580
- Yeah, yeah.

00:22:31.580 --> 00:22:35.960
- Yeah, so we won't, maybe that's a different show,

00:22:35.960 --> 00:22:38.700
it's not a show today, but it's just the idea of like,

00:22:38.700 --> 00:22:42.880
you distribute the compute on the CDN, it's pretty nice.

00:22:42.880 --> 00:22:45.520
The drawback is it's just JavaScript, which is okay,

00:22:45.520 --> 00:22:47.480
but it's not the same as--

00:22:47.480 --> 00:22:49.640
- Right, yes, yeah.

00:22:49.640 --> 00:22:51.920
- Wonder if you could do HighScript.

00:22:51.920 --> 00:22:54.080
- Oh, yeah, that's an interesting thought, yeah.

00:22:54.080 --> 00:22:55.740
- Yeah, we're getting closer and closer

00:22:55.740 --> 00:22:57.500
to Python in the browser, so.

00:22:57.500 --> 00:22:59.660
- Yeah, my JavaScript includes

00:22:59.660 --> 00:23:01.340
this little bit of WebAssembly,

00:23:01.340 --> 00:23:04.820
and I don't like semicolons, but go ahead and run it anyway.

00:23:04.820 --> 00:23:05.940
- Yeah.

00:23:05.940 --> 00:23:08.020
- Out in the audience, it looks like CloudFlare

00:23:08.020 --> 00:23:10.780
probably does support Python, which is awesome.

00:23:10.780 --> 00:23:13.100
- Yeah, yeah, there's so many options out there

00:23:13.100 --> 00:23:16.140
for serverless functions that are, yeah,

00:23:16.140 --> 00:23:17.900
especially if you're already in,

00:23:17.900 --> 00:23:21.180
if you're maybe deploying some static stuff

00:23:21.180 --> 00:23:24.760
over CloudFlare or Brazil, yeah,

00:23:24.760 --> 00:23:29.480
it's sometimes nice just to be all in on one service.

00:23:29.480 --> 00:23:30.840
- Yeah, yeah, it really is.

00:23:30.840 --> 00:23:35.160
Let's talk about choosing serverless over other things,

00:23:35.160 --> 00:23:37.240
right, you've actually laid out two really good examples,

00:23:37.240 --> 00:23:40.240
or maybe three even with the static site example,

00:23:40.240 --> 00:23:43.520
but I've got bursts of activity.

00:23:43.520 --> 00:23:44.360
- Yeah, that's definitely--

00:23:44.360 --> 00:23:47.200
- Right, and really, really low,

00:23:47.200 --> 00:23:51.040
incredibly, incredibly low usage other times, right?

00:23:51.040 --> 00:23:52.700
- Yeah, yeah, you think of like,

00:23:52.700 --> 00:23:54.980
yeah, your Black Friday traffic, right?

00:23:54.980 --> 00:23:57.980
Like you, to not have to think of like

00:23:57.980 --> 00:24:00.740
how many servers to be provisioned

00:24:00.740 --> 00:24:04.020
for something like that, or if you don't know,

00:24:04.020 --> 00:24:06.180
I think there's probably some like,

00:24:06.180 --> 00:24:07.600
well, I actually know there's been like

00:24:07.600 --> 00:24:09.540
some pretty popular articles about people

00:24:09.540 --> 00:24:13.220
like leaving the cloud, and yeah,

00:24:13.220 --> 00:24:16.240
like if you know your scale and you know,

00:24:16.240 --> 00:24:19.000
you know exactly what you need, yeah,

00:24:19.000 --> 00:24:22.820
you probably can save money by just having

00:24:22.820 --> 00:24:24.820
your own infrastructure set up,

00:24:24.820 --> 00:24:27.660
or, but yeah, if you don't know,

00:24:27.660 --> 00:24:31.500
or it's very like spiky, you don't need to have a server

00:24:31.500 --> 00:24:33.620
that's consuming a lot of power running,

00:24:33.620 --> 00:24:35.420
you know, 24 hours a day,

00:24:35.420 --> 00:24:39.500
you can just invoke a function as you need, so.

00:24:39.500 --> 00:24:42.660
- This portion of Talk Python to Me

00:24:42.660 --> 00:24:44.260
is brought to you by Mailtrap,

00:24:44.260 --> 00:24:48.180
an email delivery platform that developers love.

00:24:48.180 --> 00:24:51.840
An email sending solution with industry best analytics,

00:24:51.840 --> 00:24:56.620
SMTP and email API SDKs for major programming languages

00:24:56.620 --> 00:24:59.460
and 24/7 human support.

00:24:59.460 --> 00:25:02.180
Try for free at mailtrap.io.

00:25:02.180 --> 00:25:06.240
- Yeah, there's a super interesting series

00:25:06.240 --> 00:25:09.680
by David Heinemeyer Hansen of Ruby on Rails fame

00:25:09.680 --> 00:25:13.480
and from Basecamp about how Basecamp has left the cloud

00:25:13.480 --> 00:25:16.480
and how they're saving $7 million

00:25:16.480 --> 00:25:18.980
and getting better performance over five years.

00:25:18.980 --> 00:25:19.820
- Yeah, yeah.

00:25:19.820 --> 00:25:21.520
- But that's a big investment, right?

00:25:21.520 --> 00:25:26.320
They bought, they paid $600,000 for hardware, right?

00:25:26.320 --> 00:25:27.160
- Yeah, yeah.

00:25:27.160 --> 00:25:28.460
- Only so many people can do that.

00:25:28.460 --> 00:25:32.480
- Right, and you know, you gotta have that running somewhere

00:25:32.480 --> 00:25:36.740
that, you know, with backup power and, yeah.

00:25:36.740 --> 00:25:39.560
- Yeah, so what they ended up doing for this one

00:25:39.560 --> 00:25:42.000
is they went with some service called Geft,

00:25:42.000 --> 00:25:46.320
cloud hosting, which is like white glove, white,

00:25:46.320 --> 00:25:49.960
so white labeled is the word I'm looking for,

00:25:49.960 --> 00:25:51.880
where it just looks like it's your hardware,

00:25:51.880 --> 00:25:54.360
but they put it into a mega data center.

00:25:54.360 --> 00:25:57.280
And there's, you know, they'll have the hardware shipped

00:25:57.280 --> 00:25:58.480
to them and somebody will just come out

00:25:58.480 --> 00:26:00.600
and install it into racks and go, here's your IP.

00:26:00.600 --> 00:26:01.440
- Right, yeah.

00:26:01.440 --> 00:26:06.440
- Like a virtual VM or a VM in a cloud,

00:26:06.440 --> 00:26:09.460
but it takes three weeks to boot.

00:26:09.460 --> 00:26:12.000
- Right, yeah, yeah.

00:26:12.000 --> 00:26:14.600
- Which is kind of the opposite, it's almost,

00:26:14.600 --> 00:26:16.760
I'm kind of diving into it because it's almost

00:26:16.760 --> 00:26:20.600
the exact opposite of the serverless benefits, right?

00:26:20.600 --> 00:26:22.600
This is insane stability.

00:26:22.600 --> 00:26:25.840
I have this thing for five years.

00:26:25.840 --> 00:26:28.040
We have 4,000 CPUs we've installed

00:26:28.040 --> 00:26:30.200
and we're using them for the next five years

00:26:30.200 --> 00:26:31.960
rather than how many milliseconds

00:26:31.960 --> 00:26:33.800
am I gonna run this code for?

00:26:33.800 --> 00:26:35.760
- Right, exactly, yeah, yeah, yeah.

00:26:35.760 --> 00:26:37.560
It's definitely the far opposite.

00:26:37.560 --> 00:26:39.760
And so, yeah, you kind of, you know,

00:26:39.760 --> 00:26:42.300
maybe serverless isn't for every use case,

00:26:42.300 --> 00:26:44.340
but it's definitely a nice like tool to have

00:26:44.340 --> 00:26:47.160
in the toolbox and yeah, you definitely,

00:26:47.160 --> 00:26:49.800
even working in serverless, like if you're,

00:26:49.800 --> 00:26:52.160
yeah, eventually you're gonna need like maybe

00:26:52.160 --> 00:26:54.120
to interact with the database that's gotta be on

00:26:54.120 --> 00:26:57.040
all the time, you know, it's, yeah, there's a lot of,

00:26:57.040 --> 00:26:59.160
it's a good tool, but it's definitely not

00:26:59.160 --> 00:27:02.400
the one size fits all solution, so.

00:27:02.400 --> 00:27:04.120
- Yeah, let's talk databases in a second,

00:27:04.120 --> 00:27:07.480
but for, you know, when does it make sense to say,

00:27:07.480 --> 00:27:09.400
we're gonna put this, like if let's suppose

00:27:09.400 --> 00:27:11.200
I have an API, right, that's a pretty,

00:27:11.200 --> 00:27:13.860
an API is a real similar equivalent

00:27:13.860 --> 00:27:16.000
to what a serverless thing is, like,

00:27:16.000 --> 00:27:17.360
I'm gonna call this API, things gonna happen,

00:27:17.360 --> 00:27:19.000
I'm gonna call this function, the thing's gonna happen.

00:27:19.000 --> 00:27:22.680
Let's suppose I have an API and it has eight endpoints,

00:27:22.680 --> 00:27:24.720
it's written in FastAPI or whatever it is.

00:27:24.720 --> 00:27:27.420
It might make sense to have that as serverless, right?

00:27:27.420 --> 00:27:29.600
You don't wanna run a server and all that kind of thing.

00:27:29.600 --> 00:27:32.080
But what if I have an API with 200 endpoints?

00:27:32.080 --> 00:27:33.720
Like, where is the point where like,

00:27:33.720 --> 00:27:35.320
there are so many little serverless things,

00:27:35.320 --> 00:27:36.280
I don't even know where to look,

00:27:36.280 --> 00:27:38.080
they're everywhere, which version is this one?

00:27:38.080 --> 00:27:38.920
You know what I mean?

00:27:38.920 --> 00:27:41.480
Like, where's that trade off and how do,

00:27:41.480 --> 00:27:42.760
you know, you and the people you work with

00:27:42.760 --> 00:27:43.660
think about that?

00:27:43.660 --> 00:27:47.840
- Yeah, I guess that's a good question.

00:27:47.840 --> 00:27:49.860
I mean, as you start like, you know,

00:27:49.860 --> 00:27:52.280
getting into these like micro services,

00:27:52.280 --> 00:27:54.800
how small do you wanna break these up?

00:27:54.800 --> 00:27:58.040
And so there is some different thoughts on that.

00:27:58.040 --> 00:28:01.360
Even like a Lambda function, for instance,

00:28:01.360 --> 00:28:03.860
if you put this behind an API,

00:28:03.860 --> 00:28:07.840
you can use a single Lambda function

00:28:07.840 --> 00:28:12.120
for your entire REST API, even if it is,

00:28:12.120 --> 00:28:13.440
you know, 200 endpoints.

00:28:13.440 --> 00:28:15.480
So- - Okay.

00:28:15.480 --> 00:28:16.980
- Yeah. - So you put the whole app there

00:28:16.980 --> 00:28:18.640
and then when a request comes in,

00:28:18.640 --> 00:28:20.640
it routes to whatever part of your app?

00:28:20.640 --> 00:28:21.880
- Theoretically, yeah.

00:28:21.880 --> 00:28:25.720
Yeah, so there's a package called Power Tools

00:28:25.720 --> 00:28:28.400
for AWS Power Tools.

00:28:28.400 --> 00:28:30.000
AWS Lambda Power Tools for Python.

00:28:30.000 --> 00:28:31.520
Yeah, I know, yes.

00:28:31.520 --> 00:28:32.600
Yeah, I know the similar name.

00:28:32.600 --> 00:28:36.040
Yeah, so they have a really good like event resolver.

00:28:36.040 --> 00:28:39.740
So you can actually, it almost looks like,

00:28:39.740 --> 00:28:44.000
you know, Flask or some of the other Python web frameworks.

00:28:44.000 --> 00:28:46.560
And so you can have this resolver,

00:28:46.560 --> 00:28:49.900
whether it's, you know, API gateway and in AWS

00:28:49.900 --> 00:28:52.120
or different, they have a few different options

00:28:52.120 --> 00:28:54.960
for the API itself.

00:28:54.960 --> 00:28:59.960
But yeah, in theory, you could have your entire API

00:28:59.960 --> 00:29:02.000
behind a single Lambda function,

00:29:02.000 --> 00:29:04.320
but then that's probably not optimal, right?

00:29:04.320 --> 00:29:08.000
So you're, that's where you have to figure out

00:29:08.000 --> 00:29:09.040
how to break that up.

00:29:09.040 --> 00:29:12.880
And so, yeah, they do like that same,

00:29:12.880 --> 00:29:17.040
the decorators, you know, app.post or, yeah.

00:29:17.040 --> 00:29:19.440
Yeah, and your endpoints and you can do the,

00:29:19.440 --> 00:29:23.180
with the, have them have variables in there

00:29:23.180 --> 00:29:26.360
where maybe you have like ID as your lookup

00:29:26.360 --> 00:29:29.360
and it can, you know, slash user slash ID

00:29:29.360 --> 00:29:33.320
is going to find your, find, you know, a single user.

00:29:33.320 --> 00:29:35.980
So, and their documentation,

00:29:35.980 --> 00:29:37.880
they actually address this a little bit.

00:29:37.880 --> 00:29:39.960
Like, do you want to do,

00:29:39.960 --> 00:29:43.880
they call it either like a micro function pattern

00:29:43.880 --> 00:29:46.400
where maybe every single endpoint

00:29:46.400 --> 00:29:48.200
has its own Lambda function.

00:29:48.200 --> 00:29:50.920
But yeah, that's a lot of overhead to maintain.

00:29:50.920 --> 00:29:52.880
If you had, like you said, 200 endpoints,

00:29:52.880 --> 00:29:54.560
you have 200 Lambdas.

00:29:54.560 --> 00:29:57.920
- You gotta upgrade them all at the same time

00:29:57.920 --> 00:30:00.480
so they have the right data models and all that.

00:30:00.480 --> 00:30:01.720
Yeah, that's really.

00:30:01.720 --> 00:30:05.840
- So yeah, so there's definitely some,

00:30:05.840 --> 00:30:07.500
even conflicting views on this.

00:30:07.500 --> 00:30:09.720
How micro do you want to go?

00:30:09.720 --> 00:30:14.720
And so I was able to go to AWS reInvent in November

00:30:14.720 --> 00:30:19.080
and they actually kind of pitched this hybrid.

00:30:19.080 --> 00:30:21.840
Maybe like if you take your like CRUD operations, right?

00:30:21.840 --> 00:30:26.840
And maybe you have your create, update and delete

00:30:26.840 --> 00:30:30.600
all on one Lambda that's with its configuration for those,

00:30:30.600 --> 00:30:33.520
but your read is on another Lambda.

00:30:33.520 --> 00:30:35.080
So maybe your CRUD operations,

00:30:35.080 --> 00:30:37.740
they all interact with a relational database,

00:30:37.740 --> 00:30:42.740
but your reader just does like reads from a Dynamo database

00:30:42.740 --> 00:30:45.220
where you kind of sync that data up.

00:30:45.220 --> 00:30:47.980
And so you could have your permissions kind of separated

00:30:47.980 --> 00:30:50.700
for each of those Lambda functions.

00:30:50.700 --> 00:30:54.420
And people reading from an API

00:30:54.420 --> 00:30:56.020
don't always need the same permissions

00:30:56.020 --> 00:30:57.980
as updating, deleting.

00:30:57.980 --> 00:31:00.780
And so, yeah, there's a lot of different ways

00:31:00.780 --> 00:31:04.020
to break that up and how micro do you go with this?

00:31:04.020 --> 00:31:05.880
- Definitely. - How micro can you go?

00:31:05.880 --> 00:31:08.240
- Yeah. - Yeah, 'cause it sounds to me

00:31:08.240 --> 00:31:09.720
like if you had many, many of them,

00:31:09.720 --> 00:31:11.360
then all of a sudden you're back to like,

00:31:11.360 --> 00:31:14.880
wait, I did this because I didn't want to be in DevOps

00:31:14.880 --> 00:31:17.640
and now I'm different kind of DevOps.

00:31:17.640 --> 00:31:18.520
- Yeah, yeah.

00:31:18.520 --> 00:31:22.560
So yeah, that Python, that package, the Power Tools

00:31:22.560 --> 00:31:27.280
is, does a lot of like heavy lifting for you.

00:31:27.280 --> 00:31:30.240
At PyCon, there was a talk on serverless

00:31:30.240 --> 00:31:34.700
that the way they described the Power Tools package

00:31:34.700 --> 00:31:37.500
was it, they said it like codified

00:31:37.500 --> 00:31:39.740
your serverless best practices.

00:31:39.740 --> 00:31:40.740
And it's really true.

00:31:40.740 --> 00:31:42.860
They give a lot, there's like so many different tools

00:31:42.860 --> 00:31:43.700
in there.

00:31:43.700 --> 00:31:46.860
There's a logger, like a structured logger

00:31:46.860 --> 00:31:48.740
that works really well with Lambda.

00:31:48.740 --> 00:31:53.740
And you don't even have to use like the AWS login services.

00:31:53.740 --> 00:31:56.340
If you want to use like, you know, Datadog

00:31:56.340 --> 00:31:58.860
or Splunk or something else,

00:31:58.860 --> 00:32:01.720
it's just a structured logger and how you aggregate them

00:32:01.720 --> 00:32:03.680
is like up to you and you can even customize

00:32:03.680 --> 00:32:04.760
how you format them.

00:32:04.760 --> 00:32:08.520
But it's, works really well with Lambda.

00:32:08.520 --> 00:32:10.840
- Yeah, you probably could actually capture exceptions

00:32:10.840 --> 00:32:14.120
and stuff with something like Sentry even, right?

00:32:14.120 --> 00:32:14.960
- Oh yeah.

00:32:14.960 --> 00:32:16.240
- Python code, there's no reason you couldn't.

00:32:16.240 --> 00:32:17.400
- Right, exactly.

00:32:17.400 --> 00:32:18.440
Yeah.

00:32:18.440 --> 00:32:20.960
Yeah, some of that comes into, you know,

00:32:20.960 --> 00:32:23.840
packaging up those libraries for that.

00:32:23.840 --> 00:32:26.040
You do have to think of some of that stuff,

00:32:26.040 --> 00:32:27.680
but like Datadog. - Log this log.

00:32:27.680 --> 00:32:28.600
- Yeah.

00:32:28.600 --> 00:32:29.920
Yeah, Datadog, for instance,

00:32:29.920 --> 00:32:32.800
they provide something called like a Lambda layer

00:32:32.800 --> 00:32:33.960
or a Lambda extension,

00:32:33.960 --> 00:32:36.840
which is another way to package code up

00:32:36.840 --> 00:32:38.180
that just makes it a little bit easier.

00:32:38.180 --> 00:32:40.800
So yeah, there's a lot of different ways

00:32:40.800 --> 00:32:43.000
to attack some of these problems.

00:32:43.000 --> 00:32:44.080
- A lot of that stuff,

00:32:44.080 --> 00:32:46.040
even though they have nice libraries for them,

00:32:46.040 --> 00:32:48.400
it's really just calling a HTTP endpoint

00:32:48.400 --> 00:32:51.180
and you could go, okay, we need something really light.

00:32:51.180 --> 00:32:52.600
I don't know if requests is already included,

00:32:52.600 --> 00:32:54.680
or, but there's some gotta be some kind of HTTP thing

00:32:54.680 --> 00:32:55.600
already included.

00:32:55.600 --> 00:32:57.540
We're just gonna directly call it, not.

00:32:57.540 --> 00:32:58.380
- Sure.

00:32:58.380 --> 00:32:59.200
- And then we'll just do all these packages.

00:32:59.200 --> 00:33:00.040
Yeah.

00:33:00.040 --> 00:33:00.880
- Yep.

00:33:00.880 --> 00:33:01.700
- Yeah.

00:33:01.700 --> 00:33:02.540
- Yeah.

00:33:02.540 --> 00:33:03.380
This code looks nice.

00:33:03.380 --> 00:33:04.440
This Power Tools code,

00:33:04.440 --> 00:33:07.360
it looks like well-written Python code.

00:33:07.360 --> 00:33:10.720
- They do some really amazing stuff

00:33:10.720 --> 00:33:13.280
and they bring in a Pydantic too.

00:33:13.280 --> 00:33:17.460
So yeah, like being mostly in serverless,

00:33:17.460 --> 00:33:20.880
I've never really gotten to use like FastAPI, right?

00:33:20.880 --> 00:33:22.760
And leverage Pydantic as much,

00:33:22.760 --> 00:33:24.960
but with Power Tools, you really can.

00:33:24.960 --> 00:33:28.380
So they'll package up Pydantic for you.

00:33:28.380 --> 00:33:31.020
And so you can actually, yeah,

00:33:31.020 --> 00:33:36.020
you can have Pydantic models for validation on these.

00:33:36.020 --> 00:33:38.860
It's like a Lambda function, for instance,

00:33:38.860 --> 00:33:41.100
it always receives an event.

00:33:41.100 --> 00:33:43.500
There's always like two arguments to the handler function,

00:33:43.500 --> 00:33:45.140
it's event and context.

00:33:45.140 --> 00:33:48.000
And like event is always a,

00:33:48.000 --> 00:33:50.020
it's a dictionary in Python.

00:33:50.020 --> 00:33:53.580
And so they can always look different.

00:33:53.580 --> 00:33:56.240
And so, yeah.

00:33:56.240 --> 00:33:58.140
So, 'cause the event, yeah.

00:33:58.140 --> 00:34:02.940
So if you look in the Power Tools, GitHub, their tests,

00:34:02.940 --> 00:34:07.060
they have like, okay, here's what an event from-

00:34:07.060 --> 00:34:11.660
- API gateway proxy event.json or whatever, right?

00:34:11.660 --> 00:34:12.500
- Yes, yeah.

00:34:12.500 --> 00:34:14.940
So they have, yeah, examples.

00:34:14.940 --> 00:34:15.900
Yes, yeah.

00:34:15.900 --> 00:34:19.300
So like, you don't wanna parse that out by yourself.

00:34:19.300 --> 00:34:20.300
- No.

00:34:20.340 --> 00:34:23.740
- So they have Pydantic models

00:34:23.740 --> 00:34:26.180
or they might actually just be Python data classes,

00:34:26.180 --> 00:34:30.260
but that you can say like, okay, yeah,

00:34:30.260 --> 00:34:32.260
this function is going to be for, yeah,

00:34:32.260 --> 00:34:34.440
an API gateway proxy event,

00:34:34.440 --> 00:34:37.740
or it's going to be an S3 event or whatever it is.

00:34:37.740 --> 00:34:41.140
You know, there's so many different ways to receive events

00:34:41.140 --> 00:34:42.820
from different AWS services.

00:34:42.820 --> 00:34:45.700
So, yeah, Power Tools kind of gives you

00:34:45.700 --> 00:34:47.580
some nice validation.

00:34:47.580 --> 00:34:49.740
And yeah, you might just say like, okay, yeah,

00:34:49.740 --> 00:34:50.980
the body of this event,

00:34:50.980 --> 00:34:53.860
even though I don't care about all this other stuff

00:34:53.860 --> 00:34:57.900
that they include, the path headers,

00:34:57.900 --> 00:34:59.260
queer string parameters,

00:34:59.260 --> 00:35:00.780
but I just need like the body of this.

00:35:00.780 --> 00:35:03.300
So you just say, okay, event.body,

00:35:03.300 --> 00:35:06.500
and you can even use, you can validate that further.

00:35:06.500 --> 00:35:09.100
The event body is going to be a Pydantic model

00:35:09.100 --> 00:35:10.560
that you created, so.

00:35:10.560 --> 00:35:12.500
- Yeah, there's a lot of different pieces in here.

00:35:12.500 --> 00:35:13.660
If I was working on this

00:35:13.660 --> 00:35:15.740
and it didn't already have Pydantic models,

00:35:15.740 --> 00:35:19.300
I would take this and go to JSON Pydantic.

00:35:19.300 --> 00:35:21.020
- Oh, I didn't even know this existed.

00:35:21.020 --> 00:35:22.180
That's weird, okay.

00:35:22.180 --> 00:35:25.260
- Boom, put that right in there and boom, there you go.

00:35:25.260 --> 00:35:30.260
It parses it onto a nested tree, object tree of the model.

00:35:30.260 --> 00:35:31.100
- Very nice, yeah.

00:35:31.100 --> 00:35:31.920
- But if they already give it to you,

00:35:31.920 --> 00:35:32.760
they already give it to you,

00:35:32.760 --> 00:35:34.380
then just take what they give you, but.

00:35:34.380 --> 00:35:37.640
- Yeah, those specific events might be data classes

00:35:37.640 --> 00:35:40.920
instead of Pydantic, just because you don't,

00:35:40.920 --> 00:35:42.820
that way you don't have to package Pydantic

00:35:42.820 --> 00:35:43.660
up in your Lambda.

00:35:43.660 --> 00:35:46.460
But yeah, if you're already figuring out a way

00:35:46.460 --> 00:35:47.540
to package Power Tools,

00:35:48.300 --> 00:35:49.700
you're close enough that you probably

00:35:49.700 --> 00:35:51.620
just include Pydantic too, but.

00:35:51.620 --> 00:35:52.460
- Yeah.

00:35:52.460 --> 00:35:55.100
- Yeah, and they also,

00:35:55.100 --> 00:35:57.420
I think they just added this feature

00:35:57.420 --> 00:36:02.420
where it'll actually generate OpenAPI schema for you.

00:36:02.420 --> 00:36:04.820
I think, yeah, FastAPI does that as well, right?

00:36:04.820 --> 00:36:09.400
So, yeah, so that's something you can leverage Power Tools

00:36:09.400 --> 00:36:10.660
to do now as well.

00:36:10.660 --> 00:36:12.100
- So, excellent, and then you can actually

00:36:12.100 --> 00:36:14.820
take the OpenAPI schema and generate a Python.

00:36:14.820 --> 00:36:16.460
- Client board on top of that, I think.

00:36:16.460 --> 00:36:17.500
- Yeah, yeah.

00:36:17.500 --> 00:36:19.940
- So you just, it's robots all the way down.

00:36:19.940 --> 00:36:20.780
- Right, yeah.

00:36:20.780 --> 00:36:21.780
- All the way down.

00:36:21.780 --> 00:36:24.580
- Yeah, yeah, yeah.

00:36:24.580 --> 00:36:29.220
Yeah, I haven't used those OpenAPI generated clients

00:36:29.220 --> 00:36:30.260
very much.

00:36:30.260 --> 00:36:34.180
I was always skeptical of them, but yeah, in theory.

00:36:34.180 --> 00:36:36.900
- I just feel heartless, or soulless, I guess,

00:36:36.900 --> 00:36:37.740
is the word, like, boring.

00:36:37.740 --> 00:36:39.840
It's just like, okay, here's another star org,

00:36:39.840 --> 00:36:42.460
star star KW orgs thing, where it's like,

00:36:42.460 --> 00:36:44.900
couldn't you just write, make some reasonable defaults

00:36:44.900 --> 00:36:46.460
and give me some keyword argument, you know,

00:36:46.460 --> 00:36:47.940
just like, it's all top field.

00:36:47.940 --> 00:36:49.180
But if it's better than nothing, you know,

00:36:49.180 --> 00:36:50.020
it's better than nothing.

00:36:50.020 --> 00:36:51.140
- Right, yeah, yeah.

00:36:51.140 --> 00:36:54.740
So, but yeah, you can see like Power Tools,

00:36:54.740 --> 00:36:58.420
they took a lot of influence from FastAPI and--

00:36:58.420 --> 00:36:59.780
- It does seem like it, yeah, for sure.

00:36:59.780 --> 00:37:00.860
- Yeah, yeah.

00:37:00.860 --> 00:37:02.820
So it's definitely really powerful

00:37:02.820 --> 00:37:05.300
and you get some of those same benefits.

00:37:05.300 --> 00:37:07.440
- Yeah, this is new to me, it looks quite nice.

00:37:07.440 --> 00:37:10.100
So another comment by Kim is,

00:37:10.100 --> 00:37:12.500
tended to use serverless functions for either things

00:37:12.500 --> 00:37:14.840
that run briefly, like once a month on a schedule,

00:37:14.840 --> 00:37:19.840
or the code that processes stuff coming in on an AWS SQS,

00:37:19.840 --> 00:37:23.300
simple queuing service, queue of unknown schedule.

00:37:23.300 --> 00:37:25.460
So maybe that's an interesting segue

00:37:25.460 --> 00:37:28.940
into how do you call your serverless code?

00:37:28.940 --> 00:37:29.780
- Yeah, yeah.

00:37:29.780 --> 00:37:32.340
So as we kind of touched on,

00:37:32.340 --> 00:37:34.620
there's a lot of different ways from like, you know,

00:37:34.620 --> 00:37:36.220
AWS, for instance, to do it.

00:37:36.220 --> 00:37:41.220
So yeah, like AWS Lambda has like Lambda function URLs,

00:37:41.220 --> 00:37:43.340
but I haven't used those as much.

00:37:43.340 --> 00:37:45.340
But if you just look at like the different options

00:37:45.340 --> 00:37:47.320
and like power tools, for instance,

00:37:47.320 --> 00:37:51.420
you can have a load balancer that's gonna,

00:37:51.420 --> 00:37:54.360
where you set the endpoint to invoke a Lambda,

00:37:54.360 --> 00:37:56.720
you can have API gateway,

00:37:56.720 --> 00:37:59.100
which is another service they have.

00:37:59.100 --> 00:38:03.240
So there's a lot of different ways, yeah, SQS.

00:38:03.240 --> 00:38:07.660
So that's kind of almost getting into like a way

00:38:07.660 --> 00:38:11.700
of like streaming or an asynchronous way of processing data.

00:38:11.700 --> 00:38:16.700
So yeah, maybe in AWS, you're using a queue, right?

00:38:16.700 --> 00:38:20.060
That's filling up and you say like, okay, yeah,

00:38:20.060 --> 00:38:23.800
every time this queue is at this size or this timeframe,

00:38:23.800 --> 00:38:27.180
invoke this Lambda and process all these messages.

00:38:27.180 --> 00:38:30.180
So there's a lot of different ways

00:38:30.180 --> 00:38:33.660
to invoke a Lambda function.

00:38:33.660 --> 00:38:38.100
So if it's, I mean, really as simple as you can invoke them

00:38:38.100 --> 00:38:41.100
like from the AWS CLI or,

00:38:41.100 --> 00:38:42.580
but yeah, most people are probably

00:38:42.580 --> 00:38:44.340
have some kind of API around it.

00:38:44.340 --> 00:38:47.860
- Yeah, yeah, almost make them look like just HTTP endpoints.

00:38:47.860 --> 00:38:48.900
- Right, yeah.

00:38:48.900 --> 00:38:51.500
- Yeah, Mark out there says,

00:38:51.500 --> 00:38:53.660
not heard talk of ECS, I don't think,

00:38:53.660 --> 00:38:55.660
but I've been running web services

00:38:55.660 --> 00:38:59.940
using Fargate serverless tasks on ECS for years now.

00:38:59.940 --> 00:39:00.820
Are you familiar with this?

00:39:00.820 --> 00:39:02.420
I haven't done it.

00:39:02.420 --> 00:39:05.120
- Yeah, I'm like vaguely familiar with it,

00:39:05.120 --> 00:39:08.340
but yeah, this is like a serverless,

00:39:08.340 --> 00:39:10.580
yeah, serverless compute for containers.

00:39:10.580 --> 00:39:14.100
So I haven't used this personally,

00:39:14.100 --> 00:39:17.740
but yeah, very like similar concept

00:39:17.740 --> 00:39:19.900
where it kind of scales up for you.

00:39:19.900 --> 00:39:22.460
And yeah, you don't have to have things running

00:39:22.460 --> 00:39:25.860
all the time, but yeah, it can be Dockerized applications.

00:39:25.860 --> 00:39:27.380
Now, in fact, the company I work for now,

00:39:27.380 --> 00:39:29.780
they do this with their Ruby on Rails applications.

00:39:29.780 --> 00:39:34.340
They Dockerize them and run with Fargate.

00:39:34.340 --> 00:39:35.180
So.

00:39:35.180 --> 00:39:39.340
- Creating Docker containers of these things,

00:39:39.340 --> 00:39:42.700
the less familiar you are with running that tech stack,

00:39:42.700 --> 00:39:44.740
the better it is in Docker, you know what I mean?

00:39:44.740 --> 00:39:45.940
- Yeah, yeah.

00:39:45.940 --> 00:39:47.580
- Like I could run straight Python,

00:39:47.580 --> 00:39:49.580
but if it's Ruby on Rails or PHP,

00:39:49.580 --> 00:39:51.020
maybe it's going into a container.

00:39:51.020 --> 00:39:53.180
That would make me feel a little bit better about it.

00:39:53.180 --> 00:39:55.060
- Yeah, especially if you're in that workflow

00:39:55.060 --> 00:39:57.960
of like handing something over to a DevOps team, right?

00:39:57.960 --> 00:40:01.460
Like you can say like, here's an image or a container

00:40:01.460 --> 00:40:04.580
or a Docker file that will work for you.

00:40:04.580 --> 00:40:06.500
That's maybe a little bit easier

00:40:06.500 --> 00:40:09.580
than trying to explain how to set up

00:40:09.580 --> 00:40:11.140
an environment or something, so.

00:40:11.140 --> 00:40:11.980
- Yeah.

00:40:11.980 --> 00:40:15.580
- Yeah, Fargate's a really good serverless option too.

00:40:15.580 --> 00:40:16.420
- Excellent.

00:40:16.420 --> 00:40:17.460
What about performance?

00:40:17.460 --> 00:40:21.100
You know, you talked about having like a whole API apps,

00:40:21.100 --> 00:40:23.300
like FastAPI, Flask or whatever.

00:40:23.300 --> 00:40:24.140
- Yeah.

00:40:24.140 --> 00:40:25.620
- The startup of those apps can be somewhat,

00:40:25.620 --> 00:40:27.660
can be non-trivial basically.

00:40:27.660 --> 00:40:31.100
And so then on the other side, we've got databases and stuff.

00:40:31.100 --> 00:40:33.420
And one of the bits of magic of databases

00:40:33.420 --> 00:40:36.120
is the connection pooling that happens, right?

00:40:36.120 --> 00:40:38.760
So the first connection might take 500 milliseconds,

00:40:38.760 --> 00:40:40.780
but the next one takes one.

00:40:40.780 --> 00:40:42.580
As it's already open effectively, right?

00:40:42.580 --> 00:40:43.820
- Yeah, yeah.

00:40:43.820 --> 00:40:46.260
That's definitely something you really have to take

00:40:46.260 --> 00:40:48.900
into consideration is like how much you can do.

00:40:48.900 --> 00:40:51.060
That's where some of that like observability,

00:40:51.060 --> 00:40:53.060
some of like the tracing that you can do

00:40:53.060 --> 00:40:55.680
and profiling is really powerful.

00:40:55.680 --> 00:40:59.380
Yeah, AWS Lambda, for instance,

00:40:59.380 --> 00:41:03.660
they have something called cold starts.

00:41:03.660 --> 00:41:05.340
So like, yeah.

00:41:05.340 --> 00:41:09.380
So the first time like a Lambda gets invoked

00:41:09.380 --> 00:41:12.740
or maybe you have 10 Lambdas that get called

00:41:12.740 --> 00:41:15.260
at the same time, that's gonna, you know,

00:41:15.260 --> 00:41:17.220
invoke 10 separate Lambda functions.

00:41:17.220 --> 00:41:19.660
So that's like great for the scale, right?

00:41:19.660 --> 00:41:22.260
That's really nice.

00:41:22.260 --> 00:41:23.660
But on a cold start,

00:41:23.660 --> 00:41:26.060
it's usually a little bit slower invocation

00:41:26.060 --> 00:41:27.660
because it has to initialize.

00:41:27.660 --> 00:41:30.620
Like I think what's happening, you know,

00:41:30.620 --> 00:41:32.160
behind the scenes is they're like,

00:41:32.160 --> 00:41:35.580
they're moving your code over that's gonna get executed.

00:41:35.580 --> 00:41:39.380
And anything that happens like outside

00:41:39.380 --> 00:41:43.040
of your handler function, so importing libraries,

00:41:43.040 --> 00:41:46.560
sometimes you're establishing a database connection.

00:41:46.560 --> 00:41:50.440
Maybe you're, you know, loading some environment variables

00:41:50.440 --> 00:41:52.280
or some, you know, secrets.

00:41:52.280 --> 00:41:55.960
And so, yeah, there's definitely,

00:41:55.960 --> 00:41:57.820
performance is something to consider.

00:41:57.820 --> 00:42:01.880
Yeah, that's probably, you mentioned Rust.

00:42:01.880 --> 00:42:03.480
Yeah, there's probably some more performant,

00:42:03.480 --> 00:42:06.640
like runtimes for some of these serverless functions.

00:42:06.640 --> 00:42:10.880
So I've even heard some people say, okay,

00:42:10.880 --> 00:42:13.760
for like client facing things,

00:42:13.760 --> 00:42:15.560
we're not gonna use serverless.

00:42:15.560 --> 00:42:17.040
Like we just want that performance.

00:42:17.040 --> 00:42:20.120
So that cold start definitely can,

00:42:20.120 --> 00:42:21.760
that can have an impact on you.

00:42:21.760 --> 00:42:25.480
- Yeah, on both ends that I've pointed out.

00:42:25.480 --> 00:42:27.720
The app start, but also the service,

00:42:27.720 --> 00:42:29.320
the database stuff with like the connection.

00:42:29.320 --> 00:42:32.200
- Right, yeah, so yeah, relational databases too.

00:42:32.200 --> 00:42:34.480
That's an interesting thing.

00:42:34.480 --> 00:42:35.320
- Yeah, what do you guys do?

00:42:35.320 --> 00:42:36.960
You mentioned Dynamo already.

00:42:36.960 --> 00:42:39.200
- Yeah, so Dynamo really performant

00:42:39.200 --> 00:42:41.960
for a lot of connections, right?

00:42:41.960 --> 00:42:45.960
But a, so Dynamo is a, you know, serverless database

00:42:45.960 --> 00:42:48.840
that can scale, you can query it over and over

00:42:48.840 --> 00:42:50.140
and that's not going to,

00:42:50.140 --> 00:42:53.400
it doesn't reuse a connection in the same way

00:42:53.400 --> 00:42:55.860
that like a SQL database would.

00:42:55.860 --> 00:42:58.840
So that's an excellent option,

00:42:58.840 --> 00:43:02.720
but if you do have to connect to a relational database

00:43:02.720 --> 00:43:05.000
and you have a lot of invocations,

00:43:05.000 --> 00:43:09.400
you can use a, like a proxy,

00:43:09.400 --> 00:43:11.200
if you're all in on AWS.

00:43:11.200 --> 00:43:13.800
And so again, sorry for this is really AWS heavy,

00:43:13.800 --> 00:43:15.920
but if you're using their like

00:43:15.920 --> 00:43:17.840
relational database service, RDS,

00:43:17.840 --> 00:43:19.800
you can use RDS proxy,

00:43:19.800 --> 00:43:22.480
which will use like a pool of connections

00:43:22.480 --> 00:43:24.080
for your Lambda function.

00:43:24.080 --> 00:43:24.920
- Oh, interesting.

00:43:24.920 --> 00:43:25.760
- So that can, yeah,

00:43:25.760 --> 00:43:29.040
that can give you a lot of performance

00:43:29.040 --> 00:43:32.440
or at least you won't be, you know,

00:43:32.440 --> 00:43:34.600
running out of connections to your database.

00:43:34.600 --> 00:43:36.800
So another thing too,

00:43:36.800 --> 00:43:39.080
is just how you structure that connection.

00:43:39.080 --> 00:43:41.200
So I mentioned cold Lambdas,

00:43:41.200 --> 00:43:43.600
you obviously have warm Lambdas too.

00:43:43.600 --> 00:43:47.520
So a Lambda has its handler function.

00:43:47.520 --> 00:43:49.720
And so anything outside of the handler function

00:43:49.720 --> 00:43:52.800
can get reused on a warm Lambda.

00:43:52.800 --> 00:43:55.200
So you can establish the connection to a database

00:43:55.200 --> 00:43:58.880
and it'll get reused on every invocation that it can.

00:43:58.880 --> 00:43:59.720
- That's cool.

00:43:59.720 --> 00:44:01.960
Do you have to do anything explicit to make it do that?

00:44:01.960 --> 00:44:03.320
Or is that just a...

00:44:03.320 --> 00:44:06.080
- It just has to be outside of that handler function.

00:44:06.080 --> 00:44:10.240
So, you know, kind of at your top level of your file.

00:44:10.240 --> 00:44:11.440
So, yeah.

00:44:11.440 --> 00:44:12.320
- Excellent, yeah.

00:44:12.320 --> 00:44:14.480
It makes me think almost one thing you would consider

00:44:14.480 --> 00:44:18.800
is like profiling the import statement almost, right?

00:44:18.800 --> 00:44:19.640
- Yeah.

00:44:19.640 --> 00:44:20.720
- That's what we normally do,

00:44:20.720 --> 00:44:24.040
but there's a library called import profiler

00:44:24.040 --> 00:44:26.040
that actually lets you time how long

00:44:26.040 --> 00:44:27.520
different things take to import.

00:44:27.520 --> 00:44:28.720
It could take a while,

00:44:28.720 --> 00:44:30.560
especially if you come from,

00:44:30.560 --> 00:44:33.960
not from a native Python way of thinking

00:44:33.960 --> 00:44:36.960
in like C# or C++ or something.

00:44:36.960 --> 00:44:40.680
You say hash include or using such and such,

00:44:40.680 --> 00:44:44.200
like that's a compiler type thing that really has no cost.

00:44:44.200 --> 00:44:45.040
- Yeah.

00:44:45.040 --> 00:44:46.000
- But there's code execution

00:44:46.000 --> 00:44:47.520
when you import something in Python

00:44:47.520 --> 00:44:49.400
and some of these can take a while, right?

00:44:49.400 --> 00:44:50.640
- Yes, yeah.

00:44:50.640 --> 00:44:52.920
So there's a lot of tools for that.

00:44:52.920 --> 00:44:55.720
There's some, I think even maybe specific for Lambda.

00:44:55.720 --> 00:44:58.120
I know like Datadog has a profiler

00:44:58.120 --> 00:44:59.920
that gives you like this,

00:44:59.920 --> 00:45:02.240
I forget what the graphic is called.

00:45:02.240 --> 00:45:03.080
Like a flame graph. - Flame graph?

00:45:03.080 --> 00:45:04.080
- A flame graph, yeah.

00:45:04.080 --> 00:45:06.040
That'll give you like a flame graph and show like,

00:45:06.040 --> 00:45:07.680
okay, yeah, it took this long

00:45:07.680 --> 00:45:10.040
to make your database connection,

00:45:10.040 --> 00:45:12.520
this long to import Pydantic.

00:45:12.520 --> 00:45:17.520
And it took this long to make a call to DynamoDB,

00:45:17.520 --> 00:45:21.280
you know, so you can actually kind of like break that up.

00:45:21.280 --> 00:45:24.240
AWS has X-Ray, I think, which does something similar too.

00:45:24.240 --> 00:45:28.400
So yeah, it's definitely something to consider.

00:45:28.400 --> 00:45:30.680
Another, just what you're packaging

00:45:30.680 --> 00:45:34.760
is definitely something to watch for.

00:45:34.760 --> 00:45:36.840
And so I mentioned, yeah,

00:45:36.840 --> 00:45:40.320
I mentioned using Pants to package Lambdas

00:45:40.320 --> 00:45:45.160
and they do, hopefully I don't butcher

00:45:45.160 --> 00:45:46.480
how this works behind the scenes,

00:45:46.480 --> 00:45:48.960
but they're using Rust

00:45:48.960 --> 00:45:51.160
and they'll actually kind of like infer

00:45:51.160 --> 00:45:52.720
your dependencies for you.

00:45:52.720 --> 00:45:57.720
And so they have an integration with AWS Lambda.

00:45:57.720 --> 00:46:00.360
They also have it for Google Cloud Functions.

00:46:00.360 --> 00:46:02.000
So yeah, it'll go through,

00:46:02.000 --> 00:46:05.160
you say, here's like my AWS Lambda function.

00:46:05.160 --> 00:46:07.800
This is the file for it

00:46:07.800 --> 00:46:09.440
and the function that needs to be called.

00:46:09.440 --> 00:46:11.680
And it's gonna create a zip file for you

00:46:11.680 --> 00:46:15.080
that has your Lambda code in it.

00:46:15.080 --> 00:46:17.480
And it's gonna find all those dependencies you need.

00:46:17.480 --> 00:46:20.360
So it'll actually, by default,

00:46:20.360 --> 00:46:23.440
it's gonna include like Bodo that you need.

00:46:23.440 --> 00:46:24.880
If you're using Bodo,

00:46:24.880 --> 00:46:27.640
if you're gonna use,

00:46:27.640 --> 00:46:30.640
PyMySQL or whatever library,

00:46:30.640 --> 00:46:34.360
it's gonna pull all those in and zip that up for you.

00:46:34.360 --> 00:46:37.160
And so if you just like open up that zip and you see,

00:46:37.160 --> 00:46:41.600
especially if you're sharing code across your code base,

00:46:41.600 --> 00:46:43.040
maybe you have a shared function

00:46:43.040 --> 00:46:46.080
to make some of these database connections or calls.

00:46:46.080 --> 00:46:50.400
Like you see everything that's gonna go in there.

00:46:50.400 --> 00:46:52.360
And so, yeah.

00:46:52.360 --> 00:46:55.040
And so how like Pants does it is it's file-based.

00:46:55.040 --> 00:46:57.880
So sometimes just for like ease of imports,

00:46:57.880 --> 00:47:02.240
you might throw a lot of stuff in like your init.py file

00:47:02.240 --> 00:47:04.360
and say like, okay, yeah, from,

00:47:04.360 --> 00:47:05.400
you know, you add all,

00:47:05.400 --> 00:47:07.160
kind of bubble up all your things

00:47:07.160 --> 00:47:09.720
that you want to import in there.

00:47:09.720 --> 00:47:14.720
Well, if one of those imports is also using OpenCV,

00:47:15.720 --> 00:47:18.400
and you don't need that,

00:47:18.400 --> 00:47:21.280
then Pants is gonna say like, oh, he's importing this.

00:47:21.280 --> 00:47:23.080
And because it's file-based,

00:47:23.080 --> 00:47:25.120
now this Lambda needs OpenCV,

00:47:25.120 --> 00:47:29.600
which is a massive package that's going to,

00:47:29.600 --> 00:47:32.520
it's going to impact your performance,

00:47:32.520 --> 00:47:33.800
especially in those cold starts.

00:47:33.800 --> 00:47:36.720
'Cause that code has to be moved over.

00:47:36.720 --> 00:47:37.760
So. - Yeah.

00:47:37.760 --> 00:47:38.600
That's pretty interesting.

00:47:38.600 --> 00:47:41.640
So kind of an alternative to saying,

00:47:41.640 --> 00:47:44.640
here's my requirements or my pyproject.toml.

00:47:44.640 --> 00:47:46.040
- A lock file or whatever. - Yeah.

00:47:46.040 --> 00:47:48.640
- That just lists everything the entire program might use.

00:47:48.640 --> 00:47:51.080
This could say, you're gonna import this function.

00:47:51.080 --> 00:47:52.800
And to do that, it imports these things,

00:47:52.800 --> 00:47:53.800
which import those things.

00:47:53.800 --> 00:47:55.320
And then it just says, okay,

00:47:55.320 --> 00:47:57.280
that means here's what you need, right?

00:47:57.280 --> 00:47:58.520
- Right, yeah.

00:47:58.520 --> 00:48:01.200
Yeah, it's definitely one of like the best ways

00:48:01.200 --> 00:48:04.520
that I've found to package up Lambda functions.

00:48:04.520 --> 00:48:07.240
I think some of the other tooling might do some of this too,

00:48:07.240 --> 00:48:10.200
but yeah, a lot of times it would require

00:48:10.200 --> 00:48:12.200
like requirements.txt.

00:48:12.200 --> 00:48:14.040
But if you have like a large code base too,

00:48:14.040 --> 00:48:19.040
where maybe you do have this shared module for that,

00:48:19.040 --> 00:48:21.800
maybe you have 30 different Lambda functions

00:48:21.800 --> 00:48:24.800
that are all going to use some kind of helper function.

00:48:24.800 --> 00:48:26.640
It's just gonna go and like grab that.

00:48:26.640 --> 00:48:28.520
And it doesn't have to be like pip installable.

00:48:28.520 --> 00:48:30.000
Pants is smart enough to just be like,

00:48:30.000 --> 00:48:31.400
okay, it needs this code.

00:48:31.400 --> 00:48:34.440
And so, but yeah, you just have to be careful.

00:48:34.440 --> 00:48:35.440
Yeah, yeah.

00:48:35.440 --> 00:48:38.120
And there's so many other cool things that Pants is doing

00:48:38.120 --> 00:48:41.480
that they have some really nice stuff for testing

00:48:41.480 --> 00:48:43.520
and linting and formatting.

00:48:43.520 --> 00:48:47.200
And it's, yeah, there's a lot of really good stuff

00:48:47.200 --> 00:48:48.840
that they're doing.

00:48:48.840 --> 00:48:51.680
- Yeah, I had Benji on the show to talk about Pants.

00:48:51.680 --> 00:48:52.720
That was fun.

00:48:52.720 --> 00:48:53.560
- Yeah.

00:48:53.560 --> 00:48:55.600
- So let me go back to this picture.

00:48:55.600 --> 00:48:56.440
Is this the picture?

00:48:56.440 --> 00:48:59.200
I have a lot of things open on my screen now.

00:48:59.200 --> 00:49:00.040
There.

00:49:00.040 --> 00:49:02.600
So on my server setup that I described,

00:49:02.600 --> 00:49:04.320
which is a bunch of Docker containers

00:49:04.320 --> 00:49:06.120
running on one big machine,

00:49:06.120 --> 00:49:08.240
I can go in there and I can say,

00:49:08.240 --> 00:49:10.240
tail this log and see all the traffic

00:49:10.240 --> 00:49:11.720
to all the different containers.

00:49:11.720 --> 00:49:15.200
I can tail another log and just see like the logging,

00:49:15.200 --> 00:49:17.880
log book, log guru, whatever output of that,

00:49:17.880 --> 00:49:18.760
or just web traffic.

00:49:18.760 --> 00:49:20.680
Like there's different ways to just go.

00:49:20.680 --> 00:49:22.600
I'm just gonna sit back and look at it for a minute.

00:49:22.600 --> 00:49:24.760
Make sure it's chilling, right?

00:49:24.760 --> 00:49:28.640
If everything's so transient, not so easy in the same way.

00:49:28.640 --> 00:49:29.800
So what do you do?

00:49:29.800 --> 00:49:30.640
- Yeah.

00:49:30.640 --> 00:49:32.880
So yeah, Power Tools does,

00:49:32.880 --> 00:49:36.680
they have their structured logger that helps a lot.

00:49:36.680 --> 00:49:37.720
But yeah, you have to kind of like

00:49:37.720 --> 00:49:39.520
aggregate these logs somewhere, right?

00:49:39.520 --> 00:49:42.320
Because yeah, you can't, you know,

00:49:42.320 --> 00:49:44.760
a Lambda function you can't like SSH into, right?

00:49:44.760 --> 00:49:45.600
So yeah.

00:49:45.600 --> 00:49:47.960
- You can't, it's gonna take too long.

00:49:47.960 --> 00:49:48.800
- Yeah, yeah.

00:49:48.800 --> 00:49:53.920
So yeah, you need to have some way to aggregate these.

00:49:53.920 --> 00:49:58.920
So like AWS has CloudWatch where that will like by default

00:49:58.920 --> 00:50:00.680
kind of log all of your standard out.

00:50:00.680 --> 00:50:05.360
So even like a print statement would go to CloudWatch

00:50:05.360 --> 00:50:07.440
just by default.

00:50:07.440 --> 00:50:09.320
But you probably wanna like structure these better

00:50:09.320 --> 00:50:13.320
with most likely and, you know, JSON format,

00:50:13.320 --> 00:50:16.560
just most tooling around those is going to help you.

00:50:16.560 --> 00:50:20.680
So yeah, the Power Tools structured logger is really good.

00:50:20.680 --> 00:50:23.800
And you can even like,

00:50:23.800 --> 00:50:25.800
you can have like a single log statement,

00:50:25.800 --> 00:50:27.800
but you can append different keys to it.

00:50:27.800 --> 00:50:31.840
And it's pretty powerful,

00:50:31.840 --> 00:50:34.440
especially 'cause you don't wanna like,

00:50:34.440 --> 00:50:36.800
I think like, so if you just like printed something

00:50:36.800 --> 00:50:38.520
in a Lambda function, for instance,

00:50:38.520 --> 00:50:41.640
that's gonna be like a different row on each of your,

00:50:41.640 --> 00:50:44.400
like by like the default CloudWatch,

00:50:44.400 --> 00:50:48.080
like it'll be, how it breaks it up is really odd

00:50:48.080 --> 00:50:50.560
unless you have some kind of structure to them.

00:50:50.560 --> 00:50:52.200
- Okay. - And so, yeah.

00:50:52.200 --> 00:50:55.400
So definitely something to consider.

00:50:55.400 --> 00:50:58.000
Something else you can do is, yeah,

00:50:58.000 --> 00:51:00.840
there's metrics you can do.

00:51:00.840 --> 00:51:03.040
So like how it works with like CloudWatch,

00:51:03.040 --> 00:51:04.480
they have a specific format.

00:51:04.480 --> 00:51:08.320
And if you use that format, you can,

00:51:08.320 --> 00:51:11.000
it'll automatically pull that in as a metric.

00:51:11.000 --> 00:51:13.720
And like Datadog has something similar

00:51:13.720 --> 00:51:15.640
where you can actually kind of like go in there.

00:51:15.640 --> 00:51:17.960
You can look at your logs and say like,

00:51:17.960 --> 00:51:20.840
find a value and be like, I want this to be a metric now.

00:51:20.840 --> 00:51:23.640
And so that's really powerful.

00:51:23.640 --> 00:51:24.960
- Oh, the metric sounds cool.

00:51:24.960 --> 00:51:27.560
So I see logging and tracing.

00:51:27.560 --> 00:51:29.320
What's the difference between those things?

00:51:29.320 --> 00:51:31.840
Like to me, tracing is a level,

00:51:31.840 --> 00:51:33.360
just a high level of logging.

00:51:33.360 --> 00:51:35.200
- Yeah, tracing,

00:51:37.440 --> 00:51:41.000
and hopefully I do the justice differentiated too.

00:51:41.000 --> 00:51:43.200
I feel like tracing does have a lot more

00:51:43.200 --> 00:51:45.200
to do with your performance

00:51:45.200 --> 00:51:48.080
or maybe even closer to like tracking

00:51:48.080 --> 00:51:49.560
some of these metrics, right?

00:51:49.560 --> 00:51:56.080
I've used the Datadog tracer a lot

00:51:56.080 --> 00:51:59.240
and I've used the AWS like X-ray,

00:51:59.240 --> 00:52:01.360
their tracing utility a little bit too.

00:52:01.360 --> 00:52:04.240
And so like those will show you.

00:52:04.240 --> 00:52:06.840
So like maybe you are reaching out to a database,

00:52:06.840 --> 00:52:08.960
writing to S3. - Almost like a APM

00:52:08.960 --> 00:52:10.720
application performance monitoring

00:52:10.720 --> 00:52:14.960
where it says you spent this much time in a SQL query

00:52:14.960 --> 00:52:18.640
and this much time in identic serialization.

00:52:18.640 --> 00:52:20.200
Whereas the logging would say,

00:52:20.200 --> 00:52:22.280
a user has been sent a message.

00:52:22.280 --> 00:52:23.520
- Right, exactly.

00:52:23.520 --> 00:52:24.600
Yeah, yeah.

00:52:24.600 --> 00:52:27.560
Tracing definitely is probably more around your performance

00:52:27.560 --> 00:52:29.000
and yeah, things like that.

00:52:29.000 --> 00:52:31.760
- It's kind of insane that they can do that.

00:52:31.760 --> 00:52:34.240
You see it in the Django debug tool

00:52:34.240 --> 00:52:35.760
or in the pyramid debug tool,

00:52:35.760 --> 00:52:37.120
but they'll be like, here's your code

00:52:37.120 --> 00:52:38.400
and here's all your SQL queries

00:52:38.400 --> 00:52:39.440
and here's how long they took.

00:52:39.440 --> 00:52:40.400
And you're just like, wow,

00:52:40.400 --> 00:52:42.400
that thing is reaching deep down in there.

00:52:42.400 --> 00:52:45.240
- The Datadog one is very interesting

00:52:45.240 --> 00:52:47.920
because like it just knows like

00:52:47.920 --> 00:52:49.360
that this is a SQL connection

00:52:49.360 --> 00:52:51.000
and it tells you like, oh, okay,

00:52:51.000 --> 00:52:52.760
this SQL connection took this long.

00:52:52.760 --> 00:52:55.160
And it was like, I didn't tell it to even trace that.

00:52:55.160 --> 00:52:58.320
Like it just like, it knows really well.

00:52:58.320 --> 00:52:59.160
Yeah, so like the expectation.

00:52:59.160 --> 00:53:00.760
- It's one thing to know a SQL connection is open,

00:53:00.760 --> 00:53:01.920
it's another to say,

00:53:01.920 --> 00:53:04.160
and here's what it sent over SSL by the way.

00:53:04.160 --> 00:53:05.720
Like how'd you get in there?

00:53:05.720 --> 00:53:06.560
- Yeah, yeah.

00:53:06.560 --> 00:53:07.960
So especially.

00:53:07.960 --> 00:53:10.200
- It's in process so it can do a lot.

00:53:10.200 --> 00:53:12.040
It is impressive to see those things that work.

00:53:12.040 --> 00:53:12.880
All right, so that's probably

00:53:12.880 --> 00:53:14.280
what the tracing is about, right?

00:53:14.280 --> 00:53:15.600
- Yes, yeah, yeah.

00:53:15.600 --> 00:53:17.520
Definitely probably more around performance.

00:53:17.520 --> 00:53:20.040
You can put some different things in tracing too.

00:53:20.040 --> 00:53:23.320
Like I've used it to say like,

00:53:23.320 --> 00:53:25.600
we talked about those like database connections to say like,

00:53:25.600 --> 00:53:29.040
oh yeah, this is reusing a connection here.

00:53:29.040 --> 00:53:31.880
'Cause I was trying to like debug some stuff on,

00:53:31.880 --> 00:53:33.560
am I creating a connection too many times

00:53:33.560 --> 00:53:34.400
so I don't wanna be?

00:53:34.400 --> 00:53:37.240
So yeah, you can put some other useful things

00:53:37.240 --> 00:53:38.880
in tracing as well.

00:53:38.880 --> 00:53:40.480
- Yeah, and Pat out in the audience.

00:53:40.480 --> 00:53:41.960
Oops, I'm moving around.

00:53:41.960 --> 00:53:43.720
When using many microservices,

00:53:43.720 --> 00:53:46.960
like single execution involves many services basically,

00:53:46.960 --> 00:53:49.360
it's hard to follow the logs between the services

00:53:49.360 --> 00:53:51.440
and tracing helps tie that together.

00:53:51.440 --> 00:53:53.560
- Yeah, yeah, that's for sure.

00:53:53.560 --> 00:53:55.120
- All right, let's close this out, Tony,

00:53:55.120 --> 00:53:57.280
with one more thing that I'm not sure

00:53:57.280 --> 00:53:59.120
how constructive it can be.

00:53:59.120 --> 00:54:02.000
There probably is some ways, but testing, right?

00:54:02.000 --> 00:54:05.880
- Yeah, yeah, that's definitely.

00:54:05.880 --> 00:54:08.120
- If you could set up your own Lambda cluster,

00:54:08.120 --> 00:54:10.240
you might just run that for yourself, right?

00:54:10.240 --> 00:54:12.640
So how are you gonna do this, right?

00:54:12.640 --> 00:54:14.440
- Yeah, to some extent you can, right?

00:54:14.440 --> 00:54:16.760
Like there's a Lambda Docker image

00:54:16.760 --> 00:54:19.440
that you could run locally and you can do that.

00:54:19.440 --> 00:54:23.160
But if your Lambda is reaching out to DynamoDB,

00:54:23.160 --> 00:54:27.000
I guess there's technically a DynamoDB container as well.

00:54:27.000 --> 00:54:30.560
Like you could, it's a lot of overhead to set this up,

00:54:30.560 --> 00:54:35.240
but rather than just doing like, you know, flask start

00:54:35.240 --> 00:54:37.840
or, you know, whatever the command is to like spin up

00:54:37.840 --> 00:54:38.680
a flask server. - I pressed the go button

00:54:38.680 --> 00:54:41.240
in my IDE and now it's.

00:54:41.240 --> 00:54:44.400
- Yeah, so that's definitely,

00:54:44.400 --> 00:54:46.960
and there's more and more tooling coming out,

00:54:46.960 --> 00:54:49.320
you know, that's coming out for this kind of stuff.

00:54:49.320 --> 00:54:52.520
But if you can like unit test,

00:54:52.520 --> 00:54:55.240
there's no reason you can't just like, you know,

00:54:55.240 --> 00:54:58.880
run unit tests locally.

00:54:58.880 --> 00:55:01.840
But when you start getting into the integration test,

00:55:01.840 --> 00:55:03.800
you're probably getting to the point where

00:55:03.800 --> 00:55:07.880
maybe you just deploy to actual services.

00:55:07.880 --> 00:55:11.160
And, you know, it's always trade-offs, right?

00:55:11.160 --> 00:55:13.520
Like there's costs associated with it.

00:55:13.520 --> 00:55:15.360
There's the overhead of like, okay,

00:55:15.360 --> 00:55:18.560
how can I deploy to an isolated environment?

00:55:18.560 --> 00:55:20.920
But maybe it interacts with another microservice.

00:55:20.920 --> 00:55:25.320
So yeah, so there's definitely trade-offs,

00:55:25.320 --> 00:55:26.720
but testing is. - I can see that you might

00:55:26.720 --> 00:55:29.800
come up with like a QA environment,

00:55:29.800 --> 00:55:33.600
almost like a mirror image that doesn't share any data.

00:55:33.600 --> 00:55:35.080
- Yeah. - But it's sufficiently close,

00:55:35.080 --> 00:55:36.440
but then you're running, I mean,

00:55:36.440 --> 00:55:38.480
that's a pretty big commitment 'cause you're running

00:55:38.480 --> 00:55:41.000
a whole replica of whatever you have.

00:55:41.000 --> 00:55:42.120
- Right, yeah.

00:55:42.120 --> 00:55:45.200
And so yeah, QA environments are great,

00:55:45.200 --> 00:55:48.440
but you might even want lower than QA.

00:55:48.440 --> 00:55:51.680
You might want to have a dev or like a,

00:55:53.240 --> 00:55:55.600
one place I worked at,

00:55:55.600 --> 00:55:58.920
we would spin up an entire environment for every PR.

00:55:58.920 --> 00:56:03.760
So you could actually, yeah, like when you created a PR,

00:56:03.760 --> 00:56:05.280
that environment got spun up

00:56:05.280 --> 00:56:08.240
and it ran your integration tests and system tests

00:56:08.240 --> 00:56:10.440
against that environment, which, you know,

00:56:10.440 --> 00:56:13.480
simulated your prod environment a little bit better

00:56:13.480 --> 00:56:15.880
than running locally on your machine.

00:56:15.880 --> 00:56:19.720
So certainly a challenge to test this.

00:56:19.720 --> 00:56:21.440
- Yeah, I can imagine that it is.

00:56:21.440 --> 00:56:24.160
- Yeah, and there's always these like one-off things too,

00:56:24.160 --> 00:56:27.440
right, like you can't really simulate

00:56:27.440 --> 00:56:30.840
like that memory limitation of a Lambda locally,

00:56:30.840 --> 00:56:32.520
you know, as much as when you deploy it

00:56:32.520 --> 00:56:33.760
and things like that, so.

00:56:33.760 --> 00:56:34.840
- Yeah, yeah.

00:56:34.840 --> 00:56:37.240
That would be much, much harder.

00:56:37.240 --> 00:56:39.200
Maybe you could run a Docker container

00:56:39.200 --> 00:56:41.680
and put a memory limit on it, you know, that might work.

00:56:41.680 --> 00:56:43.280
- Yeah, yeah, maybe.

00:56:43.280 --> 00:56:45.440
- You're back into like more and more DevOps

00:56:45.440 --> 00:56:46.400
to avoid DevOps.

00:56:46.400 --> 00:56:48.320
- Right, yeah, yeah.

00:56:48.320 --> 00:56:50.840
- So there it goes, but interesting.

00:56:50.840 --> 00:56:52.680
All right, well, anything else you wanna add

00:56:52.680 --> 00:56:54.680
to this conversation before we wrap it up?

00:56:54.680 --> 00:56:55.920
About out of time here.

00:56:55.920 --> 00:56:58.600
- Yeah, I guess, I don't know if I have it,

00:56:58.600 --> 00:57:00.400
hopefully we covered enough.

00:57:00.400 --> 00:57:02.000
There's just a lot of like good,

00:57:02.000 --> 00:57:03.960
yeah, there's a lot of good resources.

00:57:03.960 --> 00:57:05.440
The tooling that I've mentioned,

00:57:05.440 --> 00:57:09.480
like Power Tools and Pants, just amazing communities.

00:57:09.480 --> 00:57:11.560
Like Power Tools has a Discord,

00:57:11.560 --> 00:57:12.840
and you can go on there and ask for help,

00:57:12.840 --> 00:57:14.720
and they're super helpful.

00:57:14.720 --> 00:57:17.800
Pants has a Slack channel, you can join their Slack

00:57:17.800 --> 00:57:19.560
and ask, you know, about things.

00:57:19.560 --> 00:57:22.440
And so those two communities have been really good

00:57:22.440 --> 00:57:24.000
and really helpful in this.

00:57:24.000 --> 00:57:27.000
A lot of good talks that are available on YouTube too.

00:57:27.000 --> 00:57:29.560
So just, yeah, there's definitely resources out there

00:57:29.560 --> 00:57:31.720
and a lot of people have, you know,

00:57:31.720 --> 00:57:33.120
fought this for a while, so.

00:57:33.120 --> 00:57:34.600
- Yeah, excellent.

00:57:34.600 --> 00:57:36.840
And you don't have to start from just create a function

00:57:36.840 --> 00:57:38.040
and start typing.

00:57:38.040 --> 00:57:39.160
- Yeah, yeah.

00:57:39.160 --> 00:57:41.400
- Cool, all right, well, before you get out of here though,

00:57:41.400 --> 00:57:45.840
let's get your recommendation for a PyPI package.

00:57:45.840 --> 00:57:47.560
Something notable, something fun.

00:57:48.600 --> 00:57:51.040
- I probably, you know, we've talked a lot about it,

00:57:51.040 --> 00:57:54.080
but Power Tools is definitely one

00:57:54.080 --> 00:57:56.600
that is like everyday getting used for me.

00:57:56.600 --> 00:58:00.120
So the, yeah, Power Tools for Lambda and Python,

00:58:00.120 --> 00:58:03.200
they actually support other languages too.

00:58:03.200 --> 00:58:06.160
So they have like the same functionality for like,

00:58:06.160 --> 00:58:08.960
you know, Node.js, you know, for like TypeScript and .NET.

00:58:08.960 --> 00:58:13.960
And so, yeah, but this one definitely

00:58:13.960 --> 00:58:17.960
leveraging Power Tools and Pydantic together,

00:58:17.960 --> 00:58:21.840
just really made like a serverless, a lot of fun to write.

00:58:21.840 --> 00:58:25.080
So yeah, definitely doing great things there.

00:58:25.080 --> 00:58:26.440
- Excellent, well, I'll put all those things

00:58:26.440 --> 00:58:29.480
in the show notes and it's been great to talk to you.

00:58:29.480 --> 00:58:34.040
Thanks for sharing your journey down the serverless path.

00:58:34.040 --> 00:58:35.960
- Yep, thanks for having me.

00:58:35.960 --> 00:58:36.800
- You bet.

00:58:36.800 --> 00:58:37.640
- Yeah, enjoy chatting.

00:58:37.640 --> 00:58:38.480
- Same, bye.

00:58:38.480 --> 00:58:42.920
This has been another episode of Talk Python to Me.

00:58:42.920 --> 00:58:44.360
Thank you to our sponsors.

00:58:44.360 --> 00:58:45.720
Be sure to check out what they're offering.

00:58:45.720 --> 00:58:47.840
It really helps support the show.

00:58:47.840 --> 00:58:49.440
Take some stress out of your life.

00:58:49.440 --> 00:58:52.960
Get notified immediately about errors and performance issues

00:58:52.960 --> 00:58:55.520
in your web or mobile applications with Sentry.

00:58:55.520 --> 00:59:00.400
Just visit talkpython.fm/sentry and get started for free.

00:59:00.400 --> 00:59:02.040
And be sure to use the promo code,

00:59:02.040 --> 00:59:03.920
Talk Python, all one word.

00:59:03.920 --> 00:59:07.840
Mailtrap, an email delivery platform that developers love.

00:59:07.840 --> 00:59:11.640
Try for free at mailtrap.io.

00:59:11.640 --> 00:59:12.960
Want to level up your Python?

00:59:12.960 --> 00:59:14.720
We have one of the largest catalogs

00:59:14.720 --> 00:59:17.080
of Python video courses over at Talk Python.

00:59:17.080 --> 00:59:19.160
Our content ranges from true beginners

00:59:19.160 --> 00:59:22.120
to deeply advanced topics like memory and async.

00:59:22.120 --> 00:59:24.800
And best of all, there's not a subscription in sight.

00:59:24.800 --> 00:59:28.040
Check it out for yourself at training.talkpython.fm.

00:59:28.040 --> 00:59:29.640
Be sure to subscribe to the show.

00:59:29.640 --> 00:59:32.640
Open your favorite podcast app and search for Python.

00:59:32.640 --> 00:59:34.040
We should be right at the top.

00:59:34.040 --> 00:59:36.920
You can also find the iTunes feed at /itunes,

00:59:36.920 --> 00:59:39.080
the Google Play feed at /play,

00:59:39.080 --> 00:59:43.560
and the direct RSS feed at /rss on talkpython.fm.

00:59:43.560 --> 00:59:46.160
We're live streaming most of our recordings these days.

00:59:46.160 --> 00:59:47.320
If you want to be part of the show

00:59:47.320 --> 00:59:49.600
and have your comments featured on the air,

00:59:49.600 --> 00:59:51.480
be sure to subscribe to our YouTube channel

00:59:51.480 --> 00:59:54.680
at talkpython.fm/youtube.

00:59:54.680 --> 00:59:56.080
This is your host, Michael Kennedy.

00:59:56.080 --> 00:59:57.240
Thanks so much for listening.

00:59:57.240 --> 00:59:58.480
I really appreciate it.

00:59:58.000 --> 01:00:01.000
Now get out there and write some Python code.

01:00:01.000 --> 01:00:03.580
(upbeat music)

01:00:19.060 --> 01:00:21.120
Thank you for watching.

