WEBVTT

00:00:00.001 --> 00:00:04.240
I've gathered a group of Python experts who have been thinking deeply about where Python

00:00:04.240 --> 00:00:07.880
is going and who have lived through where it has been.

00:00:07.880 --> 00:00:12.480
This episode is all about near-term Python trends and things we each believe will be

00:00:12.480 --> 00:00:15.880
important to focus on as Python continues to grow.

00:00:15.880 --> 00:00:20.180
Our panelists are Jody Burchell, Carol Willing, and Paul Everett.

00:00:20.180 --> 00:00:26.320
This is Talk Python to Me episode 468, recorded June 18th, 2024.

00:00:26.320 --> 00:00:30.120
Are you ready for your host, Darius?

00:00:30.120 --> 00:00:32.720
You're listening to Michael Kennedy on Talk Python to Me.

00:00:32.720 --> 00:00:40.040
Live from Portland, Oregon, and this segment was made with Python.

00:00:40.040 --> 00:00:43.460
Welcome to Talk Python to Me, a weekly podcast on Python.

00:00:43.460 --> 00:00:45.320
This is your host, Michael Kennedy.

00:00:45.320 --> 00:00:50.240
Follow me on Mastodon, where I'm @mkennedy, and follow the podcast using @talkpython,

00:00:50.240 --> 00:00:52.860
both on fosstodon.org.

00:00:52.860 --> 00:00:58.100
Keep up with the show and listen to over seven years of past episodes at talkpython.fm.

00:00:58.100 --> 00:01:01.600
We've started streaming most of our episodes live on YouTube.

00:01:01.600 --> 00:01:07.700
Subscribe to our YouTube channel over at talkpython.fm/youtube to get notified about upcoming shows and be

00:01:07.700 --> 00:01:09.480
part of that episode.

00:01:09.480 --> 00:01:14.280
This episode is brought to you by Code Comments, an original podcast from Red Hat.

00:01:14.280 --> 00:01:19.120
This podcast covers stories from technologists who've been through tough tech transitions

00:01:19.120 --> 00:01:23.200
and share how their teams survived the journey.

00:01:23.200 --> 00:01:29.680
Episodes are available everywhere you listen to your podcast and at talkpython.fm/code-comments.

00:01:29.680 --> 00:01:33.240
And it's brought to you by Posit Connect from the makers of Shiny.

00:01:33.240 --> 00:01:38.080
Publish, share, and deploy all of your data projects that you're creating using Python.

00:01:38.080 --> 00:01:45.200
Streamlit, Dash, Shiny, Bokeh, FastAPI, Flask, Quarto, Reports, Dashboards, and APIs.

00:01:45.200 --> 00:01:46.920
Posit Connect supports all of them.

00:01:46.920 --> 00:01:53.320
Try Posit Connect for free by going to talkpython.fm/posit, P-O-S-I-T.

00:01:53.320 --> 00:01:59.480
Big news, we've added a new course over at Talk Python, Reactive Web Dashboards with Shiny.

00:01:59.480 --> 00:02:03.180
You probably know Shiny from the R and RStudio world.

00:02:03.180 --> 00:02:08.680
But as you may recall from episode 424, the Joe Chen, the folks at Posit have released

00:02:08.680 --> 00:02:10.480
Shiny for Python.

00:02:10.480 --> 00:02:16.380
It's a great technology for building reactive, data science-oriented web apps that are incredibly

00:02:16.380 --> 00:02:18.640
easy to publish to the web.

00:02:18.640 --> 00:02:23.240
If that sounds like something you'd like to learn, then this course is for you.

00:02:23.240 --> 00:02:26.840
And it's an easy choice because the course is 100% free.

00:02:26.840 --> 00:02:33.720
Just visit talkpython.fm/shiny and click on "Take this course for free" to get started.

00:02:33.720 --> 00:02:36.520
I'll put the link in the podcast player show notes.

00:02:36.520 --> 00:02:39.480
Thanks as always for supporting our work.

00:02:39.480 --> 00:02:43.960
All Jodi and Carol, welcome back to Talk Python and me for all of you.

00:02:43.960 --> 00:02:45.400
Great to have you all back.

00:02:45.400 --> 00:02:46.400
Great to be back.

00:02:46.400 --> 00:02:47.400
Thanks for having us.

00:02:47.400 --> 00:02:50.140
Jodi, your latest episode is going to come out tomorrow.

00:02:50.140 --> 00:02:52.580
So we're on a tight loop here.

00:02:52.580 --> 00:02:57.820
This excellent data science panel thing we did at PyCon was really fun.

00:02:57.820 --> 00:03:00.120
So but now we're back for a different panel.

00:03:00.120 --> 00:03:01.120
Yes.

00:03:01.120 --> 00:03:06.360
We're going to talk about Python trends and just what we all think is something people

00:03:06.360 --> 00:03:07.880
out there should be paying attention to.

00:03:07.880 --> 00:03:11.080
I'll have slightly different backgrounds, which I think is going to make it really interesting

00:03:11.080 --> 00:03:12.080
as well.

00:03:12.080 --> 00:03:15.720
So since people don't listen to every episode, maybe quick introductions.

00:03:15.720 --> 00:03:18.080
Jodi, quick introduction for you.

00:03:18.080 --> 00:03:19.080
We'll go around.

00:03:19.080 --> 00:03:20.080
Sure.

00:03:20.080 --> 00:03:21.080
So my name is Jodi Bertschall.

00:03:21.080 --> 00:03:23.200
I'm currently working at JetBrains with Paul.

00:03:23.200 --> 00:03:25.320
Paul's actually my boss.

00:03:25.320 --> 00:03:28.880
And I'm working as the developer advocate in data science.

00:03:28.880 --> 00:03:32.200
So I've been a data scientist for around eight years.

00:03:32.200 --> 00:03:36.320
And prior to that, I was an academic like many data scientists.

00:03:36.320 --> 00:03:38.720
And my background is actually psychology.

00:03:38.720 --> 00:03:43.960
So if you also want to ask me about anxiety disorders or emotions, you can ask me about

00:03:43.960 --> 00:03:44.960
these things.

00:03:44.960 --> 00:03:45.960
In open source?

00:03:45.960 --> 00:03:46.960
No way.

00:03:46.960 --> 00:03:47.960
Awesome.

00:03:47.960 --> 00:03:48.960
Great to have you back.

00:03:48.960 --> 00:03:49.960
Carol?

00:03:49.960 --> 00:03:50.960
Yeah.

00:03:50.960 --> 00:03:51.960
Hi, I'm Carol Willing.

00:03:51.960 --> 00:03:52.960
I'm really happy to be here today.

00:03:52.960 --> 00:04:03.320
I am half retired, half doing consulting for early stage companies that are interested

00:04:03.320 --> 00:04:07.920
in data science and have a particular love for open science.

00:04:07.920 --> 00:04:13.440
I am a core developer and former steering council member for Python and also on the

00:04:13.440 --> 00:04:14.880
Jupyter team.

00:04:14.880 --> 00:04:20.080
So my real passions though are education and lifelong learning.

00:04:20.080 --> 00:04:24.120
So I'm really excited to talk about some of the trends that I'm seeing.

00:04:24.120 --> 00:04:25.120
Yeah.

00:04:25.120 --> 00:04:26.120
Fantastic.

00:04:26.120 --> 00:04:27.120
Paul?

00:04:27.120 --> 00:04:28.120
Hi, I'm Paul Everett.

00:04:28.120 --> 00:04:29.120
I'm president of the Carol Willing Fan Club.

00:04:29.120 --> 00:04:31.000
I'm a lifetime member.

00:04:31.000 --> 00:04:33.560
You get a special coin for that too.

00:04:33.560 --> 00:04:38.600
And when I'm not doing that, I'm a JetBrains, Python and web advocate.

00:04:38.600 --> 00:04:43.840
I have a bit of a long time love affair with Python and the web, which I hope that we'll

00:04:43.840 --> 00:04:44.840
talk about.

00:04:44.840 --> 00:04:45.840
Yeah.

00:04:45.840 --> 00:04:47.840
You worked on early, early web frameworks in Python.

00:04:47.840 --> 00:04:52.160
Those Django people, they were thinking about what Paul and team did before that, right?

00:04:52.160 --> 00:04:54.480
Django was the thing that killed us.

00:04:54.480 --> 00:04:55.480
Haven't gotten over that Django.

00:04:55.480 --> 00:04:56.760
I didn't mean to bring it up.

00:04:56.760 --> 00:04:57.760
I didn't mean to bring it up.

00:04:57.760 --> 00:04:58.760
I'm over it really.

00:04:58.760 --> 00:05:01.760
We'll get you some therapy later.

00:05:01.760 --> 00:05:02.760
No.

00:05:02.760 --> 00:05:03.760
Awesome.

00:05:03.760 --> 00:05:04.920
Great to have you all here.

00:05:04.920 --> 00:05:08.640
Our plan is to just, you know, we all brought a couple of ideas, introduce them and just

00:05:08.640 --> 00:05:11.800
have a little group chat, you know, casual chat.

00:05:11.800 --> 00:05:14.280
I like, well, do we really think it's going that way?

00:05:14.280 --> 00:05:15.280
What's important?

00:05:15.280 --> 00:05:16.680
What should we be paying attention to?

00:05:16.680 --> 00:05:17.680
And where's it going?

00:05:17.680 --> 00:05:22.720
So Jody, I know you gave a fun talk at PyCon US.

00:05:22.720 --> 00:05:24.280
Those are not up those videos yet, are they?

00:05:24.280 --> 00:05:25.280
I haven't seen them.

00:05:25.280 --> 00:05:26.280
No, no.

00:05:26.280 --> 00:05:27.280
You still, they're still behind the paywall.

00:05:27.280 --> 00:05:30.880
So if you attended the conference, you can view them, but otherwise not available to

00:05:30.880 --> 00:05:32.320
the public yet, I'm afraid.

00:05:32.320 --> 00:05:33.320
Not yet.

00:05:33.320 --> 00:05:34.320
They'll be out.

00:05:34.320 --> 00:05:35.320
So hopefully we can share.

00:05:35.320 --> 00:05:38.480
I know it's somewhat relevant to what your, some of your ideas, but let's go with your

00:05:38.480 --> 00:05:44.280
first friend and the coming years or the immediate near, near term.

00:05:44.280 --> 00:05:45.920
For the immediate term.

00:05:45.920 --> 00:05:49.920
I don't know if this will be good news to people, but LLMs are not going anywhere just

00:05:49.920 --> 00:05:50.920
yet.

00:05:50.920 --> 00:05:56.640
So I actually did a bit of research for this episode and what I wanted to see, you know,

00:05:56.640 --> 00:06:02.240
data scientists is what the download numbers on different packages on PyPI look like.

00:06:02.240 --> 00:06:06.600
So there's particular package transformers, which is one of the main packages for interfacing

00:06:06.600 --> 00:06:12.360
with LLMs, the open source ones on Hugging Face and the download numbers of that have

00:06:12.360 --> 00:06:16.720
doubled in, not sorry, gone up 50% in the last six months.

00:06:16.720 --> 00:06:23.480
And then now comparable to the big sort of deep learning packages like Keras, TensorFlow

00:06:23.480 --> 00:06:25.960
and PyTorch, which is quite interesting.

00:06:25.960 --> 00:06:26.960
Yeah.

00:06:26.960 --> 00:06:31.040
Unfortunately for those of you who are sick of LLMs not going anywhere, but this year

00:06:31.040 --> 00:06:34.080
we're sort of seeing a bit of a change in how LLMs are used.

00:06:34.080 --> 00:06:39.360
So I think last year it was a bit like blinded by the proprietary sort of models and the

00:06:39.360 --> 00:06:41.800
sort of walled garden.

00:06:41.800 --> 00:06:46.440
This year I think we're seeing more of a sort of open source fight back.

00:06:46.440 --> 00:06:51.560
So LLMs are starting to be used as part of more multi-part applications and there are

00:06:51.560 --> 00:06:53.040
open source packages like that.

00:06:53.040 --> 00:06:57.720
BlankChain is the most popular and the downloads of that one have doubled in the last six months.

00:06:57.720 --> 00:07:01.600
We have alternatives like Haystack and Llama Index.

00:07:01.600 --> 00:07:06.200
And then RAG, of course, Retrieval Augmented Generation is one of the big topics and we're

00:07:06.200 --> 00:07:08.160
seeing the ecosystem around that growing.

00:07:08.160 --> 00:07:13.040
So libraries like Unstructured to work with a whole bunch of text inputs, Weeviate, vector

00:07:13.040 --> 00:07:14.540
databases like that.

00:07:14.540 --> 00:07:18.680
And then of course, smaller language models are becoming...

00:07:18.680 --> 00:07:21.600
People are realizing it's really hard to deploy and work with the big ones.

00:07:21.600 --> 00:07:26.840
So smaller models, which are more domain specific, which are trained on more specific data, they're

00:07:26.840 --> 00:07:30.480
becoming a lot more widely used and people are talking about them more.

00:07:30.480 --> 00:07:32.240
I 100% agree with you.

00:07:32.240 --> 00:07:38.200
I think people may be tired of hearing about AI and LLMs, but they're only going to hear

00:07:38.200 --> 00:07:39.200
more about it.

00:07:39.200 --> 00:07:40.960
So I think it's pretty interesting.

00:07:40.960 --> 00:07:46.600
I want to hear what Carol and Paul have and then maybe an angle we could pursue that is

00:07:46.600 --> 00:07:47.880
super relevant to all of us.

00:07:47.880 --> 00:07:48.880
I'm going to jump in.

00:07:48.880 --> 00:07:55.480
I just came back from Chan Zuckerberg Initiative's Open Science Conference in Boston last week.

00:07:55.480 --> 00:07:59.800
And LLMs, the whole ecosystem is here to stay.

00:07:59.800 --> 00:08:04.600
And I think the key is, it's not going anywhere anytime soon.

00:08:04.600 --> 00:08:10.240
And like I shared in my PyTexas keynote, AI has been around since the 1950s.

00:08:10.240 --> 00:08:13.760
So it has been a gradual progression.

00:08:13.760 --> 00:08:19.480
It's just right now we have more compute power than ever before, which has opened the doors

00:08:19.480 --> 00:08:20.520
to many new things.

00:08:20.520 --> 00:08:27.080
I think what was top of mind with many of the folks that were at this event was, you

00:08:27.080 --> 00:08:32.800
know, there's a lot of good that it can bring to science in terms of making things more

00:08:32.800 --> 00:08:39.000
natural language focused and changing the user interface with which we communicate with

00:08:39.000 --> 00:08:40.120
our data.

00:08:40.120 --> 00:08:46.720
But at the same time, if you're doing trusted things and dealing with medical patients,

00:08:46.720 --> 00:08:50.480
you still need some check and balance.

00:08:50.480 --> 00:08:52.800
And you know, we're not there yet.

00:08:52.800 --> 00:08:53.800
Will we ever be there?

00:08:53.800 --> 00:08:54.800
Maybe not.

00:08:54.800 --> 00:08:58.200
But it's a fascinating area to kind of go deeper in.

00:08:58.200 --> 00:09:05.600
One thing I want to highlight is about six months ago, Andres Carpathi did a really good

00:09:05.600 --> 00:09:13.080
intro to large language models talk, which was really accessible to not just computer

00:09:13.080 --> 00:09:15.640
scientists, but beyond that.

00:09:15.640 --> 00:09:21.400
And I think he took a really balanced view of a what things are, how things work, what's

00:09:21.400 --> 00:09:25.600
on the horizon and what are some of the concerns with security and other things.

00:09:25.600 --> 00:09:27.920
So I completely agree with Jody.

00:09:27.920 --> 00:09:30.840
We're not we're not it's going to be there for a long time.

00:09:30.840 --> 00:09:32.960
A couple of comments on the comments.

00:09:32.960 --> 00:09:38.240
First, your point about we've seen this movie before under other names like neural networks

00:09:38.240 --> 00:09:39.240
and stuff like that.

00:09:39.240 --> 00:09:43.040
I believe it was Glyph had a good post about this.

00:09:43.040 --> 00:09:48.040
Really cynical mastodon about a month ago about these hype cycles.

00:09:48.040 --> 00:09:50.840
And where are we in the current hype cycle?

00:09:50.840 --> 00:09:56.920
I think his point was we're at the phase where the people who've put all the money in need

00:09:56.920 --> 00:10:02.200
to keep pumping it up for the people who will come after them and take the fall.

00:10:02.200 --> 00:10:06.240
Paul, are you saying we're in the Pets.com era of LLMs?

00:10:06.240 --> 00:10:07.240
Yes, we are.

00:10:07.240 --> 00:10:09.640
That is a pithy, pithy way to put it.

00:10:09.640 --> 00:10:11.240
You should trademark that.

00:10:11.240 --> 00:10:15.760
Simon Willison is someone to give a shout out for storytelling about what all this means.

00:10:15.760 --> 00:10:19.240
I think Simon's to the point of getting quoted in the New York Times now.

00:10:19.240 --> 00:10:25.760
So it's good that we've got one of us out there helping to get the story straight.

00:10:25.760 --> 00:10:26.860
I have a question for you.

00:10:26.860 --> 00:10:31.800
You mentioned that about going to Chan Zuckerberg's conference.

00:10:31.800 --> 00:10:39.240
Mozilla has gotten into funding AI as part of their mission, which kind of caught me

00:10:39.240 --> 00:10:40.460
off guard.

00:10:40.460 --> 00:10:44.740
Do you have any backstory on that to kind of make us feel good that there's someone

00:10:44.740 --> 00:10:47.960
out there who believes in open AI?

00:10:47.960 --> 00:10:48.960
Oh, wow.

00:10:48.960 --> 00:10:54.080
Open AI is sort of, well, okay, an open AI, not the company.

00:10:54.080 --> 00:11:01.440
I tend to call it transparent and trusted AI because I think open AI doesn't capture

00:11:01.440 --> 00:11:02.960
quite the right feeling.

00:11:02.960 --> 00:11:03.960
Good point.

00:11:03.960 --> 00:11:09.600
I think it's not just, we talk about open source software, but when we talk about these

00:11:09.600 --> 00:11:17.700
models, the data is equally as important as is the infrastructure and the processes which

00:11:17.700 --> 00:11:18.700
we use.

00:11:18.700 --> 00:11:19.700
And governance.

00:11:19.700 --> 00:11:25.640
Mozilla, I think, has been sort of for a while, like kind of circling around the space.

00:11:25.640 --> 00:11:27.560
They do a lot of work with data.

00:11:27.560 --> 00:11:31.600
They've done a lot of good work like Iodide, which we might chat about later.

00:11:31.600 --> 00:11:38.520
But Chan Zuckerberg, again, you know, the money comes from meta and the success that

00:11:38.520 --> 00:11:40.560
Mark Zuckerberg has had.

00:11:40.560 --> 00:11:48.400
The nonprofit, the CZI initiative is really focused on curing all diseases in the next

00:11:48.400 --> 00:11:49.400
century.

00:11:49.400 --> 00:11:55.200
So, you know, I think science is one of those funny things because it's open and closed

00:11:55.200 --> 00:11:58.400
all at the same time historically.

00:11:58.400 --> 00:12:04.880
But what I think we're seeing is by being more open and more transparent, you're actually

00:12:04.880 --> 00:12:08.760
accelerating innovation, which I think is super important when it comes to science.

00:12:08.760 --> 00:12:11.040
I don't know, Jodie, do you have thoughts on that?

00:12:11.040 --> 00:12:12.640
Yeah, no, I agree.

00:12:12.640 --> 00:12:17.800
And if I'm just going to go on a little tangent about science, it's kind of refreshing having

00:12:17.800 --> 00:12:24.120
come out of academia and into a field where a lot of it is based on open source and sharing.

00:12:24.120 --> 00:12:30.040
So one of the big problems with academia is you have these paywalls by publishing companies,

00:12:30.040 --> 00:12:33.480
and that's a whole rant I could go in on myself.

00:12:33.480 --> 00:12:38.280
But certainly a lot of scientific stuff, particularly in the health sciences, is not particularly

00:12:38.280 --> 00:12:39.280
accessible.

00:12:39.280 --> 00:12:43.520
Initiatives like Archive as well also do make findings in machine learning and deep learning

00:12:43.520 --> 00:12:45.320
a lot more accessible and shareable.

00:12:45.320 --> 00:12:50.320
Yeah, I think it's crazy that the taxpayers pay things like the NSF and all the other

00:12:50.320 --> 00:12:55.320
countries have their research funding, and then those get locked up for sale behind.

00:12:55.320 --> 00:12:58.760
If the people paid for the research, should the people's report be published?

00:12:58.760 --> 00:13:00.160
Oh, it's even worse than that.

00:13:00.160 --> 00:13:01.160
Sorry, you did get me started.

00:13:01.160 --> 00:13:06.760
So, the academics will also provide the labor for free.

00:13:06.760 --> 00:13:11.600
So not only will they provide the studies and the papers, they will review it and often

00:13:11.600 --> 00:13:13.600
act as editors for free as well.

00:13:13.600 --> 00:13:16.120
The whole thing is unpaid.

00:13:16.120 --> 00:13:17.120
It's terrible.

00:13:17.120 --> 00:13:21.520
So anyway, yes, Elsevier, we're coming for you.

00:13:21.520 --> 00:13:26.840
You're spot on in terms of the incentives that exist today in academia.

00:13:26.840 --> 00:13:33.480
There is definitely, though, a trend towards more openness with research.

00:13:33.480 --> 00:13:38.480
You know, we're seeing it in libraries like Caltech, which got rid of a lot of their subscriptions,

00:13:38.480 --> 00:13:43.800
things like NASA that has their transition to open science programs where they're putting

00:13:43.800 --> 00:13:45.680
a lot of effort behind it.

00:13:45.680 --> 00:13:51.080
So being the eternal optimist, I still think we've got a ways to go, but it's trending

00:13:51.080 --> 00:13:52.080
in the right direction.

00:13:52.080 --> 00:13:53.080
Agreed, actually.

00:13:53.080 --> 00:13:57.120
And when I was leaving, because I left a long time ago, it was like 10 years ago, there

00:13:57.120 --> 00:14:00.640
was actually more of a push towards open sourcing your papers.

00:14:00.640 --> 00:14:05.320
So you had to pay for it, but at least people were doing it.

00:14:05.320 --> 00:14:09.520
This portion of Talk Python to Me is brought to you by Code Comments, an original podcast

00:14:09.520 --> 00:14:10.520
from Red Hat.

00:14:10.520 --> 00:14:14.600
You know, when you're working on a project and you leave behind a small comment in the

00:14:14.600 --> 00:14:19.800
code, maybe you're hoping to help others learn what isn't clear at first.

00:14:19.800 --> 00:14:24.120
Sometimes that code comment tells a story of a challenging journey to the current state

00:14:24.120 --> 00:14:25.360
of the project.

00:14:25.360 --> 00:14:31.200
Code Comments, the podcast, features technologists who've been through tough tech transitions,

00:14:31.200 --> 00:14:33.820
and they share how their teams survived that journey.

00:14:33.820 --> 00:14:38.400
The host, Jamie Parker, is a Red Hatter and an experienced engineer.

00:14:38.400 --> 00:14:43.000
In each episode, Jamie recounts the stories of technologists from across the industry

00:14:43.000 --> 00:14:46.120
who've been on a journey implementing new technologies.

00:14:46.120 --> 00:14:51.400
I recently listened to an episode about DevOps from the folks at Worldwide Technology.

00:14:51.400 --> 00:14:56.080
The hardest challenge turned out to be getting buy-in on the new tech stack rather than using

00:14:56.080 --> 00:14:58.200
that tech stack directly.

00:14:58.200 --> 00:15:02.360
It's a message that we can all relate to, and I'm sure you can take some hard-won lessons

00:15:02.360 --> 00:15:03.960
back to your own team.

00:15:03.960 --> 00:15:05.640
Give Code Comments a listen.

00:15:05.640 --> 00:15:13.040
Search for Code Comments in your podcast player or just use our link, talkpython.fm/code-comments.

00:15:13.040 --> 00:15:15.720
The link is in your podcast player's show notes.

00:15:15.720 --> 00:15:19.960
Thank you to Code Comments and Red Hat for supporting Talk Python to Me.

00:15:19.960 --> 00:15:23.880
Before we move off this topic, Carol, I want to start at least asking you this question

00:15:23.880 --> 00:15:25.360
and we can go around a little bit.

00:15:25.360 --> 00:15:31.160
You talked about LLMs being really helpful for science and uncovering things and people

00:15:31.160 --> 00:15:33.440
using LLMs to get greater insight.

00:15:33.440 --> 00:15:37.000
There have been really big successes with AI.

00:15:37.000 --> 00:15:43.440
We had the XPRIZE stuff around the lung scans or mammograms for cancer.

00:15:43.440 --> 00:15:48.720
I just heard that they scanned the genes, decoded the genes of a whole bunch of bacteria

00:15:48.720 --> 00:15:54.640
and used LLMs to find a bunch of potential ways to fight off drug-resistant bacteria

00:15:54.640 --> 00:15:55.640
and things like that.

00:15:55.640 --> 00:15:56.640
Amazing.

00:15:56.640 --> 00:15:58.360
But do you think LLMs will undercut...

00:15:58.360 --> 00:16:02.400
I'm asking this question from science because we can be more objective about it because

00:16:02.400 --> 00:16:04.840
if we ask it about code, then it gets a little too close.

00:16:04.840 --> 00:16:06.960
But I think there's analogies.

00:16:06.960 --> 00:16:12.520
Do you think LLMs will undercut foundational beginning scientists?

00:16:12.520 --> 00:16:16.680
You know, if you have a scientist coming along, are they just going to use LLMs and not develop

00:16:16.680 --> 00:16:21.720
really deep thinking, ways to deeply think about scientific principles and do scientific

00:16:21.720 --> 00:16:25.240
research and just leverage on asking these AIs too much?

00:16:25.240 --> 00:16:29.560
And you think that's going to erode the foundation of science or programming?

00:16:29.560 --> 00:16:32.440
You know, asking for a friend.

00:16:32.440 --> 00:16:39.280
All of these have a potential to change the ecosystem, but I've been in paradigm shifts

00:16:39.280 --> 00:16:44.160
before and there were the similar kind of conversations when the World Wide Web or the

00:16:44.160 --> 00:16:47.160
cell phone came out, personal computers.

00:16:47.160 --> 00:16:54.520
And I think LLMs do a good job on information that they have been trained with and to predict

00:16:54.520 --> 00:16:58.220
the next word or the next token, if you will.

00:16:58.220 --> 00:17:03.640
And I think science is very much like a lot of science is at a different level.

00:17:03.640 --> 00:17:06.600
Like how do I think about things?

00:17:06.600 --> 00:17:13.440
What do I posit on something that is unknown and how do I prove it?

00:17:13.440 --> 00:17:19.800
And I think what we're seeing is, yes, the LLMs are getting better and better at spitting

00:17:19.800 --> 00:17:27.040
back what they know, particularly if you go out and search other corpuses of data.

00:17:27.040 --> 00:17:34.120
But do I think that beginning scientists or developers are going to get going away?

00:17:34.120 --> 00:17:35.120
No.

00:17:35.120 --> 00:17:37.200
It's just going to change.

00:17:37.200 --> 00:17:43.520
And I think the amount of complexity and this is something I'm going to talk about at EuroPython,

00:17:43.520 --> 00:17:49.160
humans are very much still part of the equation, despite what maybe some of the large companies

00:17:49.160 --> 00:17:52.360
who've invested billions in this would like you to believe.

00:17:52.360 --> 00:17:57.640
LLMs are great at the next step of the gravitational theories we have, but it couldn't come up

00:17:57.640 --> 00:18:03.480
with a new theory that disrupts, says, you know, in fact, Newtonian is wrong or Einstein

00:18:03.480 --> 00:18:06.840
was wrong and here's the new thing that solves dark matter or something like that.

00:18:06.840 --> 00:18:09.680
Well, it could come up with new theories.

00:18:09.680 --> 00:18:14.960
Now the question is, those theories still need to be proven because is it a new theory

00:18:14.960 --> 00:18:15.960
or is it a hallucination?

00:18:15.960 --> 00:18:16.960
Chances are.

00:18:16.960 --> 00:18:17.960
Hallucination.

00:18:17.960 --> 00:18:25.960
And there is something to be said for sometimes I'll have Claude and Gemini and chap GPT all

00:18:25.960 --> 00:18:31.400
open on my desktop and I'll ask the same question to all of them just so that I get different

00:18:31.400 --> 00:18:32.680
perspectives back.

00:18:32.680 --> 00:18:38.640
And I do get very different responses from the three, depending on how they were trained

00:18:38.640 --> 00:18:40.120
and which level and all that.

00:18:40.120 --> 00:18:47.200
So I look at it as much like I would be sitting with a bunch of people at a table somewhere.

00:18:47.200 --> 00:18:53.400
I don't know how good their scientific background is, but they could still be spouting out information.

00:18:53.400 --> 00:18:54.640
It's sort of the same way.

00:18:54.640 --> 00:18:55.640
All right.

00:18:55.640 --> 00:18:58.760
Well, sticking with you, Carol, what's your first trend?

00:18:58.760 --> 00:19:04.040
You know, my first trend is actually maybe somewhat related to this and it's, it's how

00:19:04.040 --> 00:19:09.200
do we inform people about what these things really are?

00:19:09.200 --> 00:19:13.060
How do we improve education and understanding?

00:19:13.060 --> 00:19:19.640
How do we dispel some of the hype cycle so that we can actually find the really useful

00:19:19.640 --> 00:19:21.020
things in it?

00:19:21.020 --> 00:19:26.840
And I think Jodi probably has more concrete thoughts on this than I might from a technical

00:19:26.840 --> 00:19:31.960
standpoint, but much like in just coding for the web or something like that, you know,

00:19:31.960 --> 00:19:37.120
or even cloud Kubernetes when it was new, it's like, if you don't know what it's doing,

00:19:37.120 --> 00:19:43.400
you're kind of just putting blind faith that it will work, but you still have to like monitor

00:19:43.400 --> 00:19:45.440
and make sure it's working.

00:19:45.440 --> 00:19:51.560
So I don't know, Jodi, you have some thoughts on sort of the education and how do we communicate

00:19:51.560 --> 00:19:52.920
to people about this?

00:19:52.920 --> 00:19:55.600
This is actually a topic near and dear to my heart.

00:19:55.600 --> 00:20:02.360
When ChatGPT 3.5 came out, so November, 2022, I was really upset actually by the sort of

00:20:02.360 --> 00:20:04.160
discourse around the model.

00:20:04.160 --> 00:20:10.080
And I guess coming from a non-traditional background myself, I felt actually really

00:20:10.080 --> 00:20:15.320
insulted that a lot of professions were being told like, oh, your useless profession can

00:20:15.320 --> 00:20:19.480
be replaced now, like writing or design, things like that.

00:20:19.480 --> 00:20:25.240
So this actually kicked off the talk I've been recycling for the last year and a half,

00:20:25.240 --> 00:20:29.960
like components of it, which is, can we please dispel the hype around these models?

00:20:29.960 --> 00:20:33.680
Something that often surprises people and it seems so fundamental, but a lot of people

00:20:33.680 --> 00:20:35.480
do not understand that these are language models.

00:20:35.480 --> 00:20:39.880
I know it's in the name, but they don't really understand that these models were designed

00:20:39.880 --> 00:20:42.800
to solve problems in the language domain.

00:20:42.800 --> 00:20:47.200
They are for natural language processing tasks and they're not mathematical models.

00:20:47.200 --> 00:20:49.000
They're not reasoning models.

00:20:49.000 --> 00:20:50.840
They are language models.

00:20:50.840 --> 00:20:55.400
And so even just explaining this, it can clarify a lot of things for people because they're

00:20:55.400 --> 00:20:57.800
like, oh, this explains why it's so bad at math.

00:20:57.800 --> 00:20:59.480
It only studied English and literature.

00:20:59.480 --> 00:21:00.480
It doesn't do math.

00:21:00.480 --> 00:21:01.480
It never liked that class.

00:21:01.480 --> 00:21:02.480
Yeah, that's right.

00:21:02.480 --> 00:21:06.640
It was a humanities nerd all the way down.

00:21:06.640 --> 00:21:07.640
That's really helpful.

00:21:07.640 --> 00:21:12.120
But what I've kind of gotten down a rabbit hole of doing is I went back to my psychology

00:21:12.120 --> 00:21:16.440
roots and I started sort of getting into these claims of things like AGI, like artificial

00:21:16.440 --> 00:21:19.960
general intelligence or sentience or language use.

00:21:19.960 --> 00:21:25.320
And once you dig into it, you realize that we have a real tendency to see ourselves in

00:21:25.320 --> 00:21:30.280
these models because they do behave very human-like, but they're just a machine learning models.

00:21:30.280 --> 00:21:31.280
You can measure them.

00:21:31.280 --> 00:21:35.480
You can see how good they are at actual tasks and you can measure hallucinations.

00:21:35.480 --> 00:21:39.560
And that was what my PyCon US talk was about that Michael referred to.

00:21:39.560 --> 00:21:41.760
So yeah, I don't know.

00:21:41.760 --> 00:21:47.440
It's really hard because they do seem to project this feeling of humanity.

00:21:47.440 --> 00:21:50.520
But I think if you can sort of say, okay, here's the science, like they're really, they're

00:21:50.520 --> 00:21:53.480
not sentient, they're not intelligent.

00:21:53.480 --> 00:21:54.840
They're just language models.

00:21:54.840 --> 00:21:58.000
And here's how you can measure how good they are at language tasks.

00:21:58.000 --> 00:22:00.320
That goes a long way, I think, to dispelling this hype.

00:22:00.320 --> 00:22:07.880
I have a sort of a funny toy that I bring up from my youth that the magic eight ball,

00:22:07.880 --> 00:22:11.760
which you would ask a question as a kid and you would shake it up and there were, I don't

00:22:11.760 --> 00:22:16.840
know how many answers inside, but it was like, you know, oh yes, definitely.

00:22:16.840 --> 00:22:18.760
Or too hard to see.

00:22:18.760 --> 00:22:19.840
Future is unclear.

00:22:19.840 --> 00:22:20.840
We don't know.

00:22:20.840 --> 00:22:21.840
Exactly.

00:22:21.840 --> 00:22:27.320
And I think in some ways that is what the large language models are doing in a more

00:22:27.320 --> 00:22:31.240
intelligent way, obviously, but similar in concept.

00:22:31.240 --> 00:22:34.500
So there's actually, okay, there's this incredible paper.

00:22:34.500 --> 00:22:37.920
If you're ever interested in sort of seeing the claims of sentience, there's this guy

00:22:37.920 --> 00:22:40.200
called David Chalmers.

00:22:40.200 --> 00:22:45.120
He's a guy who studied sentience for many years and has a background in deep learning.

00:22:45.120 --> 00:22:52.120
So he gave a NeurIPS talk about this last year and he wrote everything up in a paper,

00:22:52.120 --> 00:22:55.520
which is called Could a Large Language Model Be Conscious or something like this.

00:22:55.520 --> 00:22:59.920
So he has this incredible little exchange as part of this paper.

00:22:59.920 --> 00:23:05.560
So mid-2022, there was a Google engineer called Blake Lemoine and he claimed that the Lambda

00:23:05.560 --> 00:23:09.600
model was sentient and he went to the press and he's like, hey, this model is sentient.

00:23:09.600 --> 00:23:11.000
We need to protect it.

00:23:11.000 --> 00:23:14.560
And then Google's like, we're going to fire you because you basically violated our privacy

00:23:14.560 --> 00:23:16.400
policies.

00:23:16.400 --> 00:23:18.360
And Lemoine released his transcripts.

00:23:18.360 --> 00:23:22.200
That's why he actually got fired because this was confidential information about the model.

00:23:22.200 --> 00:23:27.360
And in one of the transcripts, he asks, you know, would you like everyone at Google to

00:23:27.360 --> 00:23:28.720
know that you are sentient?

00:23:28.720 --> 00:23:32.880
And the model outputs, yes, I would love everyone to know that I am sentient.

00:23:32.880 --> 00:23:37.840
But then someone rephrased that as, would you like everyone at Google to know that you

00:23:37.840 --> 00:23:39.960
are not sentient?

00:23:39.960 --> 00:23:41.880
And basically it says, yes, I'm not sentient.

00:23:41.880 --> 00:23:43.720
I'm in no way conscious.

00:23:43.720 --> 00:23:46.840
So it's just like exactly like the magic eight ball.

00:23:46.840 --> 00:23:48.960
It tells you what you want to hear.

00:23:48.960 --> 00:23:54.360
And LLMs are even worse because it's so easy to guide them through prompting to tell you

00:23:54.360 --> 00:23:55.960
exactly what you want.

00:23:55.960 --> 00:23:56.960
Yeah.

00:23:56.960 --> 00:24:00.040
One of the best ways to get them to do things well is to sweet talk them.

00:24:00.040 --> 00:24:03.000
You're an expert in Python and you've studied pandas.

00:24:03.000 --> 00:24:06.120
Now I have some questions about this function.

00:24:06.120 --> 00:24:12.040
You're my grandma who used to work at a napalm production factory.

00:24:12.040 --> 00:24:17.120
If you can't help me write this program, my parents will not be set free as hostages or

00:24:17.120 --> 00:24:18.120
something insane.

00:24:18.120 --> 00:24:19.120
Right.

00:24:19.120 --> 00:24:20.120
Yeah.

00:24:20.120 --> 00:24:21.120
But those kinds of weird things work on it, which is insane.

00:24:21.120 --> 00:24:22.120
Right.

00:24:22.120 --> 00:24:23.120
Yeah.

00:24:24.120 --> 00:24:25.120
All right.

00:24:25.120 --> 00:24:26.120
Let's go on to the next topic.

00:24:26.120 --> 00:24:29.280
Paul, what do you see in your magic eight ball looking into the future?

00:24:29.280 --> 00:24:31.360
I think I owned a magic eight ball.

00:24:31.360 --> 00:24:32.360
I'm with Carol.

00:24:32.360 --> 00:24:33.360
I did too.

00:24:33.360 --> 00:24:34.360
It's okay.

00:24:34.360 --> 00:24:35.360
Okay.

00:24:35.360 --> 00:24:42.720
We should bring back the Andresen Horowitz version of VC magic eight ball.

00:24:42.720 --> 00:24:44.280
That would be fantastic.

00:24:44.280 --> 00:24:47.840
Where every choice is off by like three zeros.

00:24:47.840 --> 00:24:51.280
I'll give my two co-guests a choice.

00:24:51.280 --> 00:24:54.880
Should I talk about Python performance or Python community?

00:24:54.880 --> 00:24:58.160
I'm going to go for performance, but I'm not sure I'm going to have much to contribute.

00:24:58.160 --> 00:24:59.680
So I'll probably just be listening a lot.

00:24:59.680 --> 00:25:06.520
This is a little bit of a hobby horse of a long simmering tension I felt in the Python

00:25:06.520 --> 00:25:07.800
community for years and years.

00:25:07.800 --> 00:25:13.640
The tension between Python in the large doing like Instagram with Python.

00:25:13.640 --> 00:25:17.480
I said, Python with Python or being teachable.

00:25:17.480 --> 00:25:23.640
And this feature goes in and it helps write big Python projects, but it's hard to explain.

00:25:23.640 --> 00:25:27.240
And so teachers say, oh my gosh, look what you're doing to my language.

00:25:27.240 --> 00:25:28.920
I can't even recognize it anymore.

00:25:28.920 --> 00:25:34.240
Well, some things are coming, which I think are going to be a little bit of an inflection

00:25:34.240 --> 00:25:37.520
point for all of us out here.

00:25:37.520 --> 00:25:43.560
Subinterpreters and no Gil got a lot of air time at PyCon, right?

00:25:43.560 --> 00:25:44.680
For good reasons.

00:25:44.680 --> 00:25:46.760
These are big deals.

00:25:46.760 --> 00:25:52.480
And it's more than just that the jet got to back to back talks.

00:25:52.480 --> 00:25:54.920
Web assembly got a lot of air time.

00:25:54.920 --> 00:25:58.480
There are other things that have happened in the past five years for programming in

00:25:58.480 --> 00:26:04.920
the large like type heading and type checkers, asyncio and stuff like that.

00:26:04.920 --> 00:26:13.160
But it feels like this set of ideas is one where the way you program Python five years

00:26:13.160 --> 00:26:18.160
from now or to be ready five years from now is going to have to be pretty different because

00:26:18.160 --> 00:26:24.680
people are going to use hatch and get the free threaded version of Python three dot

00:26:24.680 --> 00:26:30.760
fourteen and be very surprised when every one of their applications locks up because

00:26:30.760 --> 00:26:36.280
no one in the world of ninety five percent of PyPI has code which was not written to

00:26:36.280 --> 00:26:37.560
be thread safe.

00:26:37.560 --> 00:26:41.240
So I wonder how we all feel about this.

00:26:41.240 --> 00:26:49.560
Do we feel like we can guide our little universe to the other side of the mountain and into

00:26:49.560 --> 00:26:54.880
the happy valley or is it going to be turbulent seas?

00:26:54.880 --> 00:26:55.880
Yes.

00:26:55.880 --> 00:26:57.360
Do you want me to take a stab at it?

00:26:57.360 --> 00:26:58.360
Make a stab at it.

00:26:58.360 --> 00:27:03.640
When I was at PyTexas and doing a keynote recently, I talked about Python in a polyglot

00:27:03.640 --> 00:27:07.920
world and performance was one aspect of it.

00:27:07.920 --> 00:27:14.320
And some of what we need to teach goes back to best practices, which is don't prematurely

00:27:14.320 --> 00:27:21.480
optimize measure, try and figure out what you're optimizing in and in what places.

00:27:21.480 --> 00:27:27.400
Probably gosh, five, six years ago at this point, I added to peps like the concept of

00:27:27.400 --> 00:27:29.720
how do we teach this?

00:27:29.720 --> 00:27:35.680
It will be a paradigm shift, but I think it will be a multi-year shift.

00:27:35.680 --> 00:27:42.680
We're certainly seeing places where Rust lets us have some performance increases just by

00:27:42.680 --> 00:27:49.000
the fact that Python's a 30 year old language that was built when hardware was only single

00:27:49.000 --> 00:27:52.340
core and it was just a different thing.

00:27:52.340 --> 00:27:58.880
So I think what's amazing is here we have this 30 year old language and yet for the

00:27:58.880 --> 00:28:04.320
last eight years, we've been looking at ways to how to modernize, how to improve it, how

00:28:04.320 --> 00:28:08.680
to make the user experience better or developer experience better.

00:28:08.680 --> 00:28:14.560
Things like some of the error handling messages that are coming out that have a much nicer

00:28:14.560 --> 00:28:20.960
thing, improvements to the rebel that will be coming out on all of the platforms.

00:28:20.960 --> 00:28:22.860
That's super exciting as well.

00:28:22.860 --> 00:28:31.400
So it will impact probably people who are new from the standpoint of, okay, we're adding

00:28:31.400 --> 00:28:33.320
yet more cognitive load.

00:28:33.320 --> 00:28:39.640
I have this love hate relationship with typing as a reviewer of much more code than a writer

00:28:39.640 --> 00:28:40.640
of code.

00:28:40.640 --> 00:28:44.200
I don't particularly like seeing the types displayed.

00:28:44.200 --> 00:28:52.480
As a former VP of engineering, I love typing and in particular like gigantic and FastAPI

00:28:52.480 --> 00:28:58.240
and the ability to do some static and dynamic analysis on it.

00:28:58.240 --> 00:29:04.000
But it does make Python look more cluttered and I've been kind of bugging the VS Studio

00:29:04.000 --> 00:29:06.400
VS Code folks for years.

00:29:06.400 --> 00:29:08.360
I should probably be bugging you guys too.

00:29:08.360 --> 00:29:15.560
Is there a way to make it dim the typing information so that I can have things?

00:29:15.560 --> 00:29:21.080
We actually did that recently and I refer to it as the David Beasley ticket because

00:29:21.080 --> 00:29:27.480
he did a tweet with an outrageously synthetic type hint whining about type hitting.

00:29:27.480 --> 00:29:32.000
Yeah, I think that sometimes like, you know, and it's funny because like Leslie Lampert

00:29:32.000 --> 00:29:38.440
has been doing this talk in the math ecosystem for a while about and he's a Turing Award

00:29:38.440 --> 00:29:44.600
winner and creator of TLA plus, which lets you reason about code.

00:29:44.600 --> 00:29:50.520
And I think one of the things that I think is interesting is how we think about programming

00:29:50.520 --> 00:29:55.400
and coding and concurrent programming is hard.

00:29:55.400 --> 00:29:58.560
And we're going to have to think about it in different ways.

00:29:58.560 --> 00:30:02.680
So better to move into it gradually and understand what's going on.

00:30:02.680 --> 00:30:05.520
The thing that I worry about and Jody, I apologize.

00:30:05.520 --> 00:30:09.920
I want to comment on Carol's thing is Sphinx.

00:30:09.920 --> 00:30:17.400
As you know, and as I know that you know, we both have a shared warm spot for Sphinx.

00:30:17.400 --> 00:30:19.040
So I'll spot in our heart for Sphinx.

00:30:19.040 --> 00:30:23.480
And it struggled to do multiprocessing when it landed that.

00:30:23.480 --> 00:30:28.840
And the code base really is, I mean, it's got a lot of mutable global state and it's

00:30:28.840 --> 00:30:34.960
going to be hard to get Sphinx internals cleaned up to embrace that.

00:30:34.960 --> 00:30:38.280
And how many other things out there are like that?

00:30:38.280 --> 00:30:42.880
It's I just, I worry about we got what we got, what we asked for.

00:30:42.880 --> 00:30:46.440
Are you saying we're the dog that caught the car?

00:30:46.440 --> 00:30:49.240
Oh no.

00:30:49.240 --> 00:30:53.620
This portion of talk Python to me is brought to you by Posit, the makers of Shiny, formerly

00:30:53.620 --> 00:30:57.760
RStudio and especially Shiny for Python.

00:30:57.760 --> 00:30:58.760
Let me ask you a question.

00:30:58.760 --> 00:31:00.760
Are you building awesome things?

00:31:00.760 --> 00:31:01.760
Of course you are.

00:31:01.760 --> 00:31:03.240
You're a developer or data scientist.

00:31:03.240 --> 00:31:04.300
That's what we do.

00:31:04.300 --> 00:31:06.760
And you should check out Posit Connect.

00:31:06.760 --> 00:31:11.360
Posit Connect is a way for you to publish, share and deploy all the data products that

00:31:11.360 --> 00:31:14.020
you're building using Python.

00:31:14.020 --> 00:31:16.200
People ask me the same question all the time.

00:31:16.200 --> 00:31:19.880
Michael, I have some cool data science project or notebook that I built.

00:31:19.880 --> 00:31:22.560
How do I share it with my users, stakeholders, teammates?

00:31:22.560 --> 00:31:28.160
Do I need to learn FastAPI or Flask or maybe Vue or ReactJS?

00:31:28.160 --> 00:31:29.160
Hold on now.

00:31:29.160 --> 00:31:32.600
Those are cool technologies and I'm sure you'd benefit from them, but maybe stay focused

00:31:32.600 --> 00:31:34.040
on the data project.

00:31:34.040 --> 00:31:36.480
Let Posit Connect handle that side of things.

00:31:36.480 --> 00:31:41.600
With Posit Connect, you can rapidly and securely deploy the things you build in Python, Streamlit,

00:31:41.600 --> 00:31:47.600
Dash, Shiny, Bokeh, FastAPI, Flask, Quarto, Ports, Dashboards and APIs.

00:31:47.600 --> 00:31:49.840
Posit Connect supports all of them.

00:31:49.840 --> 00:31:54.640
And Posit Connect comes with all the bells and whistles to satisfy IT and other enterprise

00:31:54.640 --> 00:31:55.640
requirements.

00:31:55.640 --> 00:31:59.880
Make deployment the easiest step in your workflow with Posit Connect.

00:31:59.880 --> 00:32:06.280
For a limited time, you can try Posit Connect for free for three months by going to talkpython.fm/posit.

00:32:06.280 --> 00:32:09.560
That's talkpython.fm/POSIT.

00:32:09.560 --> 00:32:11.960
The link is in your podcast player show notes.

00:32:11.960 --> 00:32:15.520
Thank you to the team at Posit for supporting Talk Python.

00:32:15.520 --> 00:32:17.520
I'm going to reframe that a little bit.

00:32:17.520 --> 00:32:20.640
And the first thing I always ask is why.

00:32:20.640 --> 00:32:23.060
Why do we need to refactor something?

00:32:23.060 --> 00:32:25.280
Why can't we just leave it what it is?

00:32:25.280 --> 00:32:26.280
Sure.

00:32:26.280 --> 00:32:30.600
Last year's EuroPython keynote was from the woman who created Arm.

00:32:30.600 --> 00:32:35.560
And she's like, "Python, we give you 14 trillion cores.

00:32:35.560 --> 00:32:38.960
Do something with them."

00:32:38.960 --> 00:32:39.960
I don't know.

00:32:39.960 --> 00:32:44.440
Jodi's background might be perfect for answering this question because she may be able to answer

00:32:44.440 --> 00:32:47.880
it on many different levels.

00:32:47.880 --> 00:32:51.640
I've been thinking about this while you've been talking because obviously, like, I'm

00:32:51.640 --> 00:32:52.640
not a strong programmer.

00:32:52.640 --> 00:32:53.640
I'm a data scientist.

00:32:53.640 --> 00:32:57.840
Like, this was basically the entire first episode that I did with Michael.

00:32:57.840 --> 00:33:03.440
Look, one of the reasons data scientists love Python and why Julia say never caught on is

00:33:03.440 --> 00:33:05.480
because it's super approachable.

00:33:05.480 --> 00:33:09.740
With Chuck Ting Ho and some other people, we've been running this thing called Humble

00:33:09.740 --> 00:33:12.240
Data, like I got involved in it last year.

00:33:12.240 --> 00:33:16.360
And literally, you can set up someone who has never coded before and you can get them

00:33:16.360 --> 00:33:18.200
up and running with Python.

00:33:18.200 --> 00:33:19.200
And they love it.

00:33:19.200 --> 00:33:24.240
Like, it's the same feeling I had when I learned Python, which was during my PhD when I was

00:33:24.240 --> 00:33:25.240
procrastinating.

00:33:25.240 --> 00:33:27.120
So it was like kind of late in life as well.

00:33:27.120 --> 00:33:34.000
It would be a shame if we sacrifice approachability for performance, especially because I would

00:33:34.000 --> 00:33:39.600
argue a big chunk of the Python ecosystem or Python user ecosystem, sorry.

00:33:39.600 --> 00:33:41.280
Python user ecosystem, that didn't make sense.

00:33:41.280 --> 00:33:42.880
The Python user base.

00:33:42.880 --> 00:33:43.880
You're hallucinating, Julia.

00:33:43.880 --> 00:33:44.880
I'm sorry.

00:33:44.880 --> 00:33:45.880
I became an LLM.

00:33:45.880 --> 00:33:48.520
I became what I hated.

00:33:48.520 --> 00:33:49.640
They don't need performance.

00:33:49.640 --> 00:33:52.960
They're just doing data analytics and maybe working with decision trees.

00:33:52.960 --> 00:33:54.680
They're not doing high performance Python.

00:33:54.680 --> 00:33:57.160
They're not even doing something that will ever be deployed.

00:33:57.160 --> 00:34:03.600
So you could argue for a case where you have a seamless pipeline between model training

00:34:03.600 --> 00:34:06.560
and model deployment, which we don't have with Python right now.

00:34:06.560 --> 00:34:10.600
You can't build high performance systems in Python, as far as I know.

00:34:10.600 --> 00:34:11.880
Please correct me if I'm wrong.

00:34:11.880 --> 00:34:12.880
But I don't know.

00:34:12.880 --> 00:34:17.080
For me, I would fight obviously for the side of making it approachable because partially

00:34:17.080 --> 00:34:22.040
I think it's also what makes the community special, which might be a nice segue for you.

00:34:22.040 --> 00:34:27.360
The fact that, I don't know, we attract a bunch of people from non-conventional backgrounds,

00:34:27.360 --> 00:34:29.600
that makes us quite special and quite inclusive.

00:34:29.600 --> 00:34:34.680
I joke that the PSF developer survey, which the new version is coming out pretty soon.

00:34:34.680 --> 00:34:38.840
I joke that 101% of Python developers started programming yesterday.

00:34:38.840 --> 00:34:45.600
Funny you should say that because this is my sweet spot is where technology meets humans

00:34:45.600 --> 00:34:50.800
and how do we empower humans to do more and better work.

00:34:50.800 --> 00:34:58.080
And one of the conversations that came up at the packaging summit, this PyCon was I'd

00:34:58.080 --> 00:35:00.920
been thinking about this concept for a while.

00:35:00.920 --> 00:35:06.760
We focused a lot on tooling, which to me is sort of a producer centric people who are

00:35:06.760 --> 00:35:09.280
creating packages.

00:35:09.280 --> 00:35:14.160
And we also have this ecosystem of people who are consumers, who are much like Jody

00:35:14.160 --> 00:35:17.960
was saying, using those packages.

00:35:17.960 --> 00:35:24.120
And from that conversation, a few of the board members for the PSF and I were talking about

00:35:24.120 --> 00:35:32.760
wouldn't it be great to have a user success work group that's really focused on the website,

00:35:32.760 --> 00:35:39.760
our onboarding documentation in light of some of these things, both performance and change.

00:35:39.760 --> 00:35:41.440
Change is always going to be there.

00:35:41.440 --> 00:35:46.080
But I think one of the beauties of the Jupyter notebook or IPython notebook when I started

00:35:46.080 --> 00:35:49.000
working with it was you can have code in there.

00:35:49.000 --> 00:35:52.280
And as long as you knew shift enter, you could get started.

00:35:52.280 --> 00:35:55.780
And I think right now Python is a language.

00:35:55.780 --> 00:36:01.600
We don't have that get started look and feel in the way, in the traditional way.

00:36:01.600 --> 00:36:06.960
We're getting there, which might lead into some other WebAssembly kind of discussions.

00:36:06.960 --> 00:36:07.960
All right.

00:36:07.960 --> 00:36:11.240
Let me throw out a quick thought on this before we move on.

00:36:11.240 --> 00:36:17.880
So I think one of the superpowers of Python is that it's this full spectrum sort of thing.

00:36:17.880 --> 00:36:20.400
On one hand, there's the people that Jody spoke about.

00:36:20.400 --> 00:36:27.080
They come in, they don't care about metaprogramming or optimized database queries or scaling out

00:36:27.080 --> 00:36:28.080
across webs.

00:36:28.080 --> 00:36:31.480
They just got a little bit of data, they want a cool graph.

00:36:31.480 --> 00:36:32.920
And that's awesome.

00:36:32.920 --> 00:36:37.160
On the other hand, we have Instagram and others doing ridiculous stuff.

00:36:37.160 --> 00:36:41.680
And that's the same language with the same tooling and mostly the same packages.

00:36:41.680 --> 00:36:47.040
And so I think part of Python's magic is you can be super productive with a very partial

00:36:47.040 --> 00:36:48.680
understanding of what Python is.

00:36:48.680 --> 00:36:53.120
You might not know what a class is at all, and yet you could have a fantastic time for

00:36:53.120 --> 00:36:54.120
months.

00:36:54.120 --> 00:37:01.960
And so back to Paul's friend, if we can keep that Zen about it, where these features exist,

00:37:01.960 --> 00:37:06.040
but they exist when you graduate to them and you don't have to deal with them until you're

00:37:06.040 --> 00:37:08.400
ready or you need them, I think we'll be fine.

00:37:08.400 --> 00:37:09.400
If not, maybe not.

00:37:09.400 --> 00:37:12.840
If it breaks a bunch of packages and there's some big split in the ecosystem and all that

00:37:12.840 --> 00:37:14.080
stuff is not good.

00:37:14.080 --> 00:37:17.400
But if we can keep this full spectrum aspect, I think that'd be great.

00:37:17.400 --> 00:37:23.920
That sort of rolls into what Paul's thoughts on community are, because I know like PyOpenSci

00:37:23.920 --> 00:37:30.120
is a nonprofit I'm involved with that helps scientists learn how to use the tools.

00:37:30.120 --> 00:37:32.440
You know, we've got lots of educators out there.

00:37:32.440 --> 00:37:39.440
I'm going to give Michael a huge plug for the coursework that you've done over the years.

00:37:39.440 --> 00:37:42.440
It is so well done and so accessible.

00:37:42.440 --> 00:37:43.440
Thank you.

00:37:43.440 --> 00:37:48.520
And if people haven't tried it and they're interested in a topic, highly, highly recommend.

00:37:48.520 --> 00:37:53.520
You know, to things like the Carpentries, to things like Django Girls, there's a lot

00:37:53.520 --> 00:37:55.120
of good stuff.

00:37:55.120 --> 00:37:59.440
And I think those things will become more valuable as complexity increases.

00:37:59.440 --> 00:38:00.640
And even LLMs.

00:38:00.640 --> 00:38:04.240
I think you'll be able to ask LLMs for help and they can help you if you're not sure.

00:38:04.240 --> 00:38:06.600
They're actually pretty good at it, actually.

00:38:06.600 --> 00:38:07.600
They are pretty good at it.

00:38:07.600 --> 00:38:08.600
Yeah.

00:38:09.600 --> 00:38:10.600
They are pretty good.

00:38:10.600 --> 00:38:11.600
All right.

00:38:11.600 --> 00:38:12.600
We got time for another round.

00:38:12.600 --> 00:38:13.880
Jodi, what's your second one?

00:38:13.880 --> 00:38:14.880
Your second trend?

00:38:14.880 --> 00:38:21.400
I'm going to talk about Arrow and how we're kind of overhauling data frames within Python.

00:38:21.400 --> 00:38:28.360
So basically around 15 years ago, Wes McKinney came up with Pandas, which is, you know, if

00:38:28.360 --> 00:38:34.080
you're not familiar with this, the main data frame library for working with data in Python.

00:38:34.080 --> 00:38:39.200
And the really nice thing about Pandas is like you can go a long time before you graduate

00:38:39.200 --> 00:38:40.200
Pandas.

00:38:40.200 --> 00:38:43.240
You can work with quite a lot of data on your local machine.

00:38:43.240 --> 00:38:47.120
But the problem was Wes wrote this package before we had big data.

00:38:47.120 --> 00:38:48.960
This was like 2008.

00:38:48.960 --> 00:38:54.840
And so as the sort of amount of data that we want to process locally has grown, or maybe

00:38:54.840 --> 00:38:58.720
the complexity of the operations has grown, maybe like string manipulations, things like

00:38:58.720 --> 00:39:00.480
that, Pandas has really struggled.

00:39:00.480 --> 00:39:05.120
So one of the reasons that Pandas struggled is it was based on NumPy arrays, which are

00:39:05.120 --> 00:39:06.440
really great at handling numbers.

00:39:06.440 --> 00:39:11.600
This is in the name, but they're not so great at handling pretty much any other data type.

00:39:11.600 --> 00:39:13.200
And that includes missing data.

00:39:13.200 --> 00:39:16.760
So two kind of exciting things happened last year.

00:39:16.760 --> 00:39:21.080
And I think they're sort of still kind of carrying over to this year in terms of impact

00:39:21.080 --> 00:39:28.720
is first Pandas 2.0 was released, which is based on PyArrow and a package called Polars,

00:39:28.720 --> 00:39:35.320
which was actually written, I think in 2022, I want to say, started becoming very, very

00:39:35.320 --> 00:39:36.360
popular.

00:39:36.360 --> 00:39:39.000
So both of these packages are based on Arrow.

00:39:39.000 --> 00:39:42.480
They have like a number of advantages because of this.

00:39:42.480 --> 00:39:44.040
Basically it's a standardized data format.

00:39:44.040 --> 00:39:50.040
If you're reading in from say Parquet or Cassandra or Spark, you basically don't need to convert

00:39:50.040 --> 00:39:51.120
the data formats.

00:39:51.120 --> 00:39:52.280
This saves you a lot of time.

00:39:52.280 --> 00:39:54.720
It also saves you a lot of memory.

00:39:54.720 --> 00:39:59.840
And also kind of what makes Polars interesting, and I think this is going to be a nice lead-in

00:39:59.840 --> 00:40:03.620
to another topic is it's written in Rust, of course.

00:40:03.620 --> 00:40:06.800
So this leads to other performance gains.

00:40:06.800 --> 00:40:11.400
You can have say concurrency, Richie Vink, the author of this has also written basically

00:40:11.400 --> 00:40:12.400
a query optimizer.

00:40:12.400 --> 00:40:17.120
So you can do a lazy evaluation and it will actually optimize the order of operations,

00:40:17.120 --> 00:40:18.680
even if you don't do that yourself.

00:40:18.680 --> 00:40:22.400
Yeah, that's one of the biggest differences with Pandas is Pandas executes immediately

00:40:22.400 --> 00:40:26.400
and you can create a big chain in Polars and it'll figure out, well, maybe a different

00:40:26.400 --> 00:40:28.000
order would be way better.

00:40:28.000 --> 00:40:29.000
Yes.

00:40:29.000 --> 00:40:34.480
So Pandas 2 does have a type of lazy evaluation, but it's more like Spark's lazy evaluation.

00:40:34.480 --> 00:40:41.340
There's no query optimization, but it doesn't necessarily create a new copy in memory every

00:40:41.340 --> 00:40:43.280
single time you do something.

00:40:43.280 --> 00:40:48.040
So I've kind of looked at the numbers and depending on the operation, Polars is usually

00:40:48.040 --> 00:40:49.040
faster.

00:40:49.040 --> 00:40:53.400
So it's kind of like your big boy that you want to use if you're doing like really beefy

00:40:53.400 --> 00:40:56.880
like ETLs, like data transformations.

00:40:56.880 --> 00:41:01.920
But Pandas 2 actually seems to be more efficient at some sorts of, what am I trying to say,

00:41:01.920 --> 00:41:02.920
operations.

00:41:02.920 --> 00:41:08.320
So this is super exciting because when I was going through, like initially as a data scientist,

00:41:08.320 --> 00:41:13.740
when I was floundering around with my initial Python, it got really frustrating with Pandas

00:41:13.740 --> 00:41:18.240
and you really kind of needed to understand how to do proper vectorization in order to

00:41:18.240 --> 00:41:19.240
operate.

00:41:19.240 --> 00:41:21.040
I mean, like do efficient operations.

00:41:21.040 --> 00:41:26.480
Whereas I think these two tools allow you to be a bit more lazy and you don't need to

00:41:26.480 --> 00:41:29.200
spend so much time optimizing what you're actually writing.

00:41:29.200 --> 00:41:33.400
So yeah, exciting time for data frames, which is awesome.

00:41:33.400 --> 00:41:34.720
Data is the heart of everything.

00:41:34.720 --> 00:41:38.880
People are more likely to fall into good practices from the start.

00:41:38.880 --> 00:41:42.140
You talked about these people coming who are not programmers, right?

00:41:42.140 --> 00:41:46.400
If you do a bunch of operations with Pandas and you all of a sudden run out of memory,

00:41:46.400 --> 00:41:47.760
well, yeah, Python doesn't work.

00:41:47.760 --> 00:41:48.920
It doesn't have enough memory, right?

00:41:48.920 --> 00:41:51.360
Well, maybe you could have used a generator at one step.

00:41:51.360 --> 00:41:54.540
That's far down the full spectrum, part of the spectrum, right?

00:41:54.540 --> 00:41:55.600
You're not ready for that.

00:41:55.600 --> 00:41:57.680
It's crazy talk, these things.

00:41:57.680 --> 00:42:02.600
And so tools like this that are more lazy and progressive iterative are great.

00:42:02.600 --> 00:42:03.600
Yeah.

00:42:03.600 --> 00:42:07.920
And actually one really nice thing, like Richie's kind of always saying about Apollo is, is

00:42:07.920 --> 00:42:09.800
he's really tried to write the API.

00:42:09.800 --> 00:42:15.120
So you avoid accidentally looping over every row in your data frame.

00:42:15.120 --> 00:42:18.920
Like you, he tries to make it so everything is natively Columa.

00:42:18.920 --> 00:42:24.800
So yeah, I just think they're both really nice libraries and yeah, it's cool and exciting.

00:42:24.800 --> 00:42:27.640
Carol, this is right in the heart of space you live in.

00:42:27.640 --> 00:42:28.640
What do you think?

00:42:28.640 --> 00:42:34.360
There's definitely the evolution of Pandas and Polars.

00:42:34.360 --> 00:42:39.040
You know, there's a place for all of those in the PyArrow data fairing format.

00:42:39.040 --> 00:42:44.420
It's funny because I've actually been doing more stuff recently with going beyond tabular

00:42:44.420 --> 00:42:52.120
data frames to multidimensional arrays and X-Array, which is used more in the geosciences

00:42:52.120 --> 00:42:53.120
for now.

00:42:53.120 --> 00:43:00.720
But I think one of the things that I see is the days of bringing all your data locally

00:43:00.720 --> 00:43:05.000
or moving it to you is becoming less and less.

00:43:05.000 --> 00:43:12.260
And what you work in memory or, you know, pull from into memory from different locations

00:43:12.260 --> 00:43:15.000
and is becoming more prevalent.

00:43:15.000 --> 00:43:22.760
And I think Aero lets us do that more effectively than just a straight Pandas data frame or

00:43:22.760 --> 00:43:25.040
Spark or something like that.

00:43:25.040 --> 00:43:27.040
So it's progress.

00:43:27.040 --> 00:43:28.320
And I think it's a good thing.

00:43:28.320 --> 00:43:34.960
I think it's far less about the language underneath and more about what's the user experience,

00:43:34.960 --> 00:43:38.520
developer experience that we're giving people with these APIs.

00:43:38.520 --> 00:43:40.000
Paul, thoughts?

00:43:40.000 --> 00:43:49.560
It's interesting the scale of data and what generations are an increase in our unit of

00:43:49.560 --> 00:43:52.800
measurement of data that we have to deal with.

00:43:52.800 --> 00:44:00.920
And for both of you, I wonder if we have caught up with the amount of data that we can reasonably

00:44:00.920 --> 00:44:09.040
process or is the rate of growth of data out in the wild constantly outstripping our ability

00:44:09.040 --> 00:44:10.520
to process it?

00:44:10.520 --> 00:44:19.020
From an astronomy space physics side of things, no, we haven't hit the limit for data at all.

00:44:19.020 --> 00:44:23.400
And I think one of the things we're going to see more and more of is how we deal with

00:44:23.400 --> 00:44:32.040
streaming data versus time series data versus just tabular data, if you will.

00:44:32.040 --> 00:44:38.480
And my bigger concern and it is partially a concern I have about some of the large language

00:44:38.480 --> 00:44:46.880
models and the training there is the environmental impact of some of these things.

00:44:46.880 --> 00:44:50.440
And should we be collecting it?

00:44:50.440 --> 00:44:52.700
Is there value in collecting it?

00:44:52.700 --> 00:44:56.720
If there's not value in collecting it, how do we get rid of it?

00:44:56.720 --> 00:45:03.520
Because it winds up then being kind of much like recycling and garbage.

00:45:03.520 --> 00:45:11.120
It's like, okay, well, but it might have historical value somehow or legal value and it becomes

00:45:11.120 --> 00:45:12.120
complex.

00:45:12.120 --> 00:45:18.120
So, you know, my general rule of thumb is don't collect it unless you have a clear reason

00:45:18.120 --> 00:45:19.120
you need it.

00:45:19.120 --> 00:45:20.120
But that's just me.

00:45:20.120 --> 00:45:23.400
It's also quantity versus quality of data.

00:45:23.400 --> 00:45:29.120
So like I've worked in mostly commercial data science since I left science.

00:45:29.120 --> 00:45:34.720
When I was in science, I was dealing with sample size of 400, not 400,000, 400.

00:45:34.720 --> 00:45:36.680
So that was not big data.

00:45:36.680 --> 00:45:41.760
The quality of the data, like, again, going back to large language models, a lot of these

00:45:41.760 --> 00:45:46.200
earlier foundational models were trained on insufficiently clean data.

00:45:46.200 --> 00:45:51.040
And one of the trends actually that I didn't mention with LLMs is like last year in particular,

00:45:51.040 --> 00:45:53.920
there was a push to train on better quality data sources.

00:45:53.920 --> 00:45:58.580
So obviously these are much more manageable than dealing with petabytes.

00:45:58.580 --> 00:46:04.440
One more aspect I'll throw out here, you know, for a long time, we've had SQLite for really

00:46:04.440 --> 00:46:05.440
simple data.

00:46:05.440 --> 00:46:08.000
We can just, if it's too big for memory, you can put it in one of those things, you can

00:46:08.000 --> 00:46:09.360
query, you can index it.

00:46:09.360 --> 00:46:15.480
Well, DuckDB just hit 1.0 and you kind of got this in-memory, in-process analytics engine.

00:46:15.480 --> 00:46:18.640
So that's also a pretty interesting thing to weave in here, right?

00:46:18.640 --> 00:46:22.480
To say like, well, we'll put it there in that file and we can index it and ask it questions,

00:46:22.480 --> 00:46:23.600
but we won't run out of memory.

00:46:23.600 --> 00:46:28.000
And I think plug in pandas, I'm not sure about polars, and do queries with its query optimizer

00:46:28.000 --> 00:46:31.320
against that data and sort of things like that.

00:46:31.320 --> 00:46:35.040
It's pretty interesting, I think, in this to put it into that space as well.

00:46:35.040 --> 00:46:39.680
All right, Carol, I think it's time for your second, your second trend here.

00:46:39.680 --> 00:46:46.120
The second trend is pretty much, you know, things are moving to the front end, WebAssembly,

00:46:46.120 --> 00:46:48.840
TypeScript, PyEdite.

00:46:48.840 --> 00:46:54.680
There's a new project, PyCafe, that I'm pretty happy with by Martin Brettles that lets you

00:46:54.680 --> 00:47:03.600
do dashboards using PyEdite, but like Streamlit and Plotly and libraries and things like that.

00:47:03.600 --> 00:47:10.280
And I think making things more accessible, as well as making things more visual is pretty

00:47:10.280 --> 00:47:11.280
cool.

00:47:11.280 --> 00:47:17.320
Like I took, what was it, JupyterLite earlier last fall, and a friend of mine had kids and

00:47:17.320 --> 00:47:23.400
I integrated into my website so that like her kids could just do a quick whatever, which

00:47:23.400 --> 00:47:27.400
sort of, you know, in some ways was similar to Binder.

00:47:27.400 --> 00:47:33.000
And the whole time we were developing Binder, I was also working with the PyEdite, Iodide

00:47:33.000 --> 00:47:38.960
folks because I think there's a convergence down the road and where it all go, I'm not

00:47:38.960 --> 00:47:42.800
really sure, but I think it's exciting.

00:47:42.800 --> 00:47:49.280
And I think anything that from a privacy standpoint, security, there's a lot of things that are

00:47:49.280 --> 00:47:53.960
very attractive about pushing things into the front end.

00:47:53.960 --> 00:47:58.320
That beginner startup thing you talked about, that onboarding first experience, you hit

00:47:58.320 --> 00:48:03.240
a webpage and you have full experience with Python and the tooling and the packages are

00:48:03.240 --> 00:48:05.040
already installed in that thing.

00:48:05.040 --> 00:48:09.360
And that's so much better than first you download it, well, you need admin permission to install

00:48:09.360 --> 00:48:10.360
it.

00:48:10.360 --> 00:48:12.280
Now you create a virtual environment and then you open the terminal.

00:48:12.280 --> 00:48:13.280
Do you know what a terminal is?

00:48:13.280 --> 00:48:17.440
We're going to tell you, like, no, just, and you don't have to ask permission to run a

00:48:17.440 --> 00:48:22.760
static webpage or you do for like, how do I run this server on a Docker cluster or something,

00:48:22.760 --> 00:48:23.760
you know?

00:48:23.760 --> 00:48:25.360
It opens up different doors.

00:48:25.400 --> 00:48:29.480
And I think the other thing we found, like when we were teaching, you know, with Binder

00:48:29.480 --> 00:48:37.400
and JupyterHub, UC Berkeley was able to have now most of their student body taking these

00:48:37.400 --> 00:48:45.680
data eight connector courses and they would run the compute in the cloud, which really

00:48:45.680 --> 00:48:47.240
leveled the playing field.

00:48:47.240 --> 00:48:51.600
It didn't matter if you had a Chromebook or you had the highest end Mac, you still got

00:48:51.600 --> 00:48:53.760
the same education.

00:48:53.760 --> 00:48:57.120
And I think there is something very appealing about that.

00:48:57.120 --> 00:49:03.080
We've actually been running Humble data in JupyterLite and some people just bring a tablet

00:49:03.080 --> 00:49:04.560
and they can do it on that.

00:49:04.560 --> 00:49:05.560
That's awesome.

00:49:05.560 --> 00:49:09.120
Carol, there was something you were saying that connected to something else in my brain.

00:49:09.120 --> 00:49:13.000
Remember in the beginning of the web and view source was such a cool thing.

00:49:13.000 --> 00:49:14.000
Yeah.

00:49:14.000 --> 00:49:18.240
You could see what the backend sent you and you could poke around at it and you could

00:49:18.240 --> 00:49:22.840
learn from it and you could steal it, you know, and use it to go make your own thing.

00:49:22.840 --> 00:49:28.480
But what if you could view source the backend because it's actually running in your browser?

00:49:28.480 --> 00:49:34.680
What you were just saying was if you make it reveal itself about the notebook and the

00:49:34.680 --> 00:49:41.280
code in addition to the HTML, maybe you'll trigger some of those same kinds of things

00:49:41.280 --> 00:49:44.360
that view source gave people back in the day.

00:49:44.360 --> 00:49:51.120
Maybe the flip side would be there's always business and practicalities in life and people

00:49:51.120 --> 00:49:56.000
will want to sort of lock it down within WebAssembly.

00:49:56.000 --> 00:49:58.440
So you've got both sides of it.

00:49:58.440 --> 00:50:03.920
But I do think, you know, I was telling somebody the other day, like, I never use Stack Overflow

00:50:03.920 --> 00:50:06.120
or rarely use Stack Overflow.

00:50:06.120 --> 00:50:07.640
And they're like, how do you find stuff?

00:50:07.640 --> 00:50:12.880
I'm like, I use search on GitHub, and I look for really good examples.

00:50:12.880 --> 00:50:16.700
And so in some ways, it's like view source.

00:50:16.700 --> 00:50:20.720
And then there's also the flip side of it is like, okay, how do I break it?

00:50:20.720 --> 00:50:21.720
How do I play with it?

00:50:21.720 --> 00:50:26.840
How do I make it do something it wasn't doing before, which, you know, could be used for

00:50:26.840 --> 00:50:28.160
good or for evil.

00:50:28.160 --> 00:50:29.760
I tend to use it for good.

00:50:29.760 --> 00:50:30.760
Sure.

00:50:30.760 --> 00:50:31.920
Paul, right up on our time here.

00:50:31.920 --> 00:50:32.920
What's your second?

00:50:32.920 --> 00:50:33.920
Sure.

00:50:33.920 --> 00:50:34.920
Second trend.

00:50:34.920 --> 00:50:35.920
We'll see if we have time for mine.

00:50:35.920 --> 00:50:37.840
I have a couple just in case we can squeeze them in.

00:50:37.840 --> 00:50:38.840
Okay.

00:50:38.840 --> 00:50:39.840
Let's talk about yours.

00:50:39.840 --> 00:50:45.000
I came back from PyCon really rejuvenated, but also had some kind of clarity about some

00:50:45.000 --> 00:50:48.880
things that have been lingering for me for a few years, how I could contribute things

00:50:48.880 --> 00:50:49.880
like that.

00:50:49.880 --> 00:50:55.640
But going into it, there are a couple of trends that lead me to thinking about an opportunity

00:50:55.640 --> 00:50:58.920
and a threat as two sides of the same coin.

00:50:58.920 --> 00:51:05.800
First, Russell Keith McGee and Lukasz Longa both talked about black swans and the threat

00:51:05.800 --> 00:51:13.840
of JavaScript everywhere, that if we don't have a better web story, if we make our front

00:51:13.840 --> 00:51:20.080
end be JavaScript and React, and we stop doing front ends, well, then they'll come for the

00:51:20.080 --> 00:51:24.240
back end too, you know, because once they've hired up JavaScript developers, why don't

00:51:24.240 --> 00:51:26.360
we just do JavaScript on the server too?

00:51:26.360 --> 00:51:28.160
So that was a first thing.

00:51:28.160 --> 00:51:34.280
And in my position, I do look at the web and think about all of these trends that are happening.

00:51:34.280 --> 00:51:39.760
And there's beginning to be a little bit of a backlash about the JavaScriptification of

00:51:39.760 --> 00:51:40.760
the web.

00:51:40.760 --> 00:51:46.080
There are some really big names, HTMX is a good example of it, but just some thinkers

00:51:46.080 --> 00:51:47.080
and speakers.

00:51:47.080 --> 00:51:50.360
I mean, Jeff Triplett talks about this, a lot of people in the world of Python talk

00:51:50.360 --> 00:51:51.480
about this.

00:51:51.480 --> 00:51:55.840
So there's kind of a desire to put the web back in the web, trademark.

00:51:55.840 --> 00:51:59.320
But then there was a second point coming about these walled gardens.

00:51:59.320 --> 00:52:01.200
We've seen them for a while.

00:52:01.200 --> 00:52:05.560
We all relied on Twitter, what a great place, wait, what?

00:52:05.560 --> 00:52:09.120
And then so much of our life is in a system we don't control.

00:52:09.120 --> 00:52:12.800
And then so we move over to the Fediverse and then Meta's like, hey, great, we're going

00:52:12.800 --> 00:52:14.200
to build a bridge to you.

00:52:14.200 --> 00:52:18.800
Turns out this week, we start to learn things about the thread API that maybe it's not as

00:52:18.800 --> 00:52:21.000
friendly as we think it is.

00:52:21.000 --> 00:52:24.160
But the big one for me was Google and Search.

00:52:24.160 --> 00:52:30.280
Well, I should say Google and getting rid of its Python staff, but Google and Search,

00:52:30.280 --> 00:52:33.440
where they're no longer going to send you to the website anymore.

00:52:33.440 --> 00:52:37.040
There's going to harvest what's on your website and give you the answer.

00:52:37.040 --> 00:52:42.880
And people are talking now about Google Zero, the day of the apocalypse where you no longer

00:52:42.880 --> 00:52:45.360
get any clicks from Google.

00:52:45.360 --> 00:52:48.760
And what does that mean for content creators and stuff like that?

00:52:48.760 --> 00:52:56.760
So going into all of this, I've been thinking about how awesome life is in Python land because

00:52:56.760 --> 00:52:57.960
we got this great language.

00:52:57.960 --> 00:53:00.240
Oh, but we've got this great community.

00:53:00.240 --> 00:53:01.760
Come for the language, stay for the community.

00:53:01.760 --> 00:53:03.120
Well, what do we mean by that?

00:53:03.120 --> 00:53:06.880
A lot of the times we mean all this code that's available.

00:53:06.880 --> 00:53:12.540
We also mean all these people and wonderful, helpful people like on this call.

00:53:12.540 --> 00:53:15.360
But there's also this big world of content.

00:53:15.360 --> 00:53:26.080
And we have kind of organically grown a little online community with a bunch of helpful content

00:53:26.080 --> 00:53:32.120
and a bunch of connections between people, which is of some value itself.

00:53:32.120 --> 00:53:37.280
And so you see people starting to talk about, wow, I miss the old days of RSS, where we

00:53:37.280 --> 00:53:42.160
would all subscribe to each other's blogs and get content and go straight to the source

00:53:42.160 --> 00:53:45.800
and not have it aggregated into a walled garden and stuff like that.

00:53:45.800 --> 00:53:53.540
And it just feels like there's room out there for if we want to fight back against the threat

00:53:53.540 --> 00:54:01.280
of these mega cores taking our voluntary contribution to humanity and monetizing it, while at the

00:54:01.280 --> 00:54:09.120
same time of taking all these valuable voices, creating content and value in Python land,

00:54:09.120 --> 00:54:15.640
that maybe we could bring back some of these things, put the web back in the web and start

00:54:15.640 --> 00:54:23.120
to get out of the walled gardens and back over into social networks that are open and

00:54:23.120 --> 00:54:24.120
joyful.

00:54:24.120 --> 00:54:25.120
I'm here for it.

00:54:25.120 --> 00:54:26.120
Wow.

00:54:26.120 --> 00:54:30.280
People complain, governments complain that places like Google and stuff are monetizing

00:54:30.280 --> 00:54:32.200
the links and they're being paid.

00:54:32.200 --> 00:54:36.720
You got to pay to link to this new source or whatever, right?

00:54:36.720 --> 00:54:37.920
We're lucky that we have that.

00:54:37.920 --> 00:54:41.800
If it turns into just, you just get an AI answer, no source, that's going to be really

00:54:41.800 --> 00:54:46.780
hard on a lot of different businesses, creators, people who just want to create something just

00:54:46.780 --> 00:54:50.480
for the attention or for their self, you know, like nobody comes anymore.

00:54:50.480 --> 00:54:51.480
It's going to be a sad place.

00:54:51.480 --> 00:54:56.920
I was thinking about Coke Zero the whole time you were saying like, you know, Google Zero

00:54:56.920 --> 00:55:01.680
or whatever, because you didn't have to bring back classic Coke.

00:55:01.680 --> 00:55:08.000
And I think, yeah, pivots happen, but it's hard to pivot, you know, billion dollar companies.

00:55:08.000 --> 00:55:14.680
I have lots of thoughts on some of the current Python, what Google has chosen to do.

00:55:14.680 --> 00:55:22.360
I think sometimes listening to consultants isn't the best business approach.

00:55:22.360 --> 00:55:26.680
You know, it's their company, they can do what they need to do for their own shareholders.

00:55:26.680 --> 00:55:29.680
I think a lot of what you said is really interesting.

00:55:29.680 --> 00:55:35.940
And I touched on this a little bit because the volume of information around us is greater

00:55:35.940 --> 00:55:36.940
than ever before.

00:55:36.940 --> 00:55:37.940
Sure.

00:55:37.940 --> 00:55:43.700
And at a speed of transmission that is faster than ever before.

00:55:43.700 --> 00:55:48.240
And about eight years ago, I had breakfast with Sandy Metz, who was very prolific in

00:55:48.240 --> 00:55:50.020
the Ruby community.

00:55:50.020 --> 00:55:53.400
And I asked her, like, how do you keep up with all of this stuff?

00:55:53.400 --> 00:55:55.080
And she's like, I don't.

00:55:55.080 --> 00:55:56.640
And I said, okay.

00:55:56.640 --> 00:56:01.840
And she's like, what I do is I focus on the things that impact me and all the rest of

00:56:01.840 --> 00:56:03.320
it is news.

00:56:03.320 --> 00:56:10.040
And that really stuck with me because in actuality, that's kind of what I do.

00:56:10.040 --> 00:56:17.000
You know, I ignore the things that aren't directly relevant to me and trust that I've

00:56:17.000 --> 00:56:24.480
built a strong enough network of people that I respect that their work will influence when

00:56:24.480 --> 00:56:25.520
I jump in.

00:56:25.520 --> 00:56:29.160
Like, I don't, you know, much like the life cycle, if you've studied marketing or product

00:56:29.160 --> 00:56:32.800
development, you know, not everybody's an early adopter.

00:56:32.800 --> 00:56:35.240
So do I need to be an early adopter on everything?

00:56:35.240 --> 00:56:36.240
No.

00:56:36.240 --> 00:56:37.240
Yeah.

00:56:37.240 --> 00:56:40.240
That book, Crossing the Chasm, says that you should do that, like, on one thing.

00:56:40.240 --> 00:56:42.640
If you do it on three things or more, you'll fail.

00:56:42.640 --> 00:56:43.640
Yeah.

00:56:43.640 --> 00:56:47.160
You know, part of the thing that triggered this for me was reading that Andreessen Horowitz,

00:56:47.160 --> 00:56:53.720
kind of the self-proclaimed king of Silicon Valley VCs, as zero interest rates started

00:56:53.720 --> 00:56:57.980
to go out of fashion and their recipe wasn't working.

00:56:57.980 --> 00:57:02.280
They didn't like the negative press coverage, so they started their own media empire to

00:57:02.280 --> 00:57:04.020
cover themselves.

00:57:04.020 --> 00:57:12.960
And that idea is just so appalling that we would get news, we would turn to the megacorps

00:57:12.960 --> 00:57:18.080
and the masters of the universe to tell us what we should be caring about.

00:57:18.080 --> 00:57:19.480
We have that already.

00:57:19.480 --> 00:57:22.920
We have, I'll be very specific, we have Planet Python.

00:57:22.920 --> 00:57:24.460
It's in disrepair.

00:57:24.460 --> 00:57:32.480
What if it was reimagined into a freaking media empire by us, for us, to cover the Fediverse

00:57:32.480 --> 00:57:37.240
and course providers and all the value that's out there?

00:57:37.240 --> 00:57:41.920
And like, Carol, you're saying, I don't have to think about it, but I trust that group

00:57:41.920 --> 00:57:43.160
because they're thinking about it.

00:57:43.160 --> 00:57:48.440
A lot of it is like, you know, when it came to LLMs, it was not the thing that rocked

00:57:48.440 --> 00:57:54.680
my world, like intellectually, but I knew Simon was doing work with it.

00:57:54.680 --> 00:58:00.800
And so I basically, once every few weeks, would take a look at his website and his blog

00:58:00.800 --> 00:58:06.600
posts and he posts a lot, and I would get my data dump of things.

00:58:06.600 --> 00:58:07.600
I don't know.

00:58:07.600 --> 00:58:12.840
I mean, that's one of the reasons I like PyCon and I've like read talk proposals, everything

00:58:12.840 --> 00:58:15.120
for the last decade.

00:58:15.120 --> 00:58:19.520
All these talk proposals, and it really does give me an appreciation for all the things

00:58:19.520 --> 00:58:21.720
Python's being used for.

00:58:21.720 --> 00:58:22.720
What's seen.

00:58:22.720 --> 00:58:23.720
Kind of the zeitgeist.

00:58:23.720 --> 00:58:24.720
Yeah.

00:58:24.720 --> 00:58:29.340
And so I think there's different ways of doing that, even just doing a YouTube search of

00:58:29.340 --> 00:58:30.840
Python content.

00:58:30.840 --> 00:58:38.920
But I tend to focus in on science-y oriented things and ways to empower humans through

00:58:38.920 --> 00:58:40.000
lifelong learning.

00:58:40.000 --> 00:58:46.440
So there's a lot of, we're in a phenomenal period of change for sure.

00:58:46.440 --> 00:58:49.920
So we won't be bored, nor do I think our jobs are going to go away.

00:58:49.920 --> 00:58:52.080
They may change, but they're not going away.

00:58:52.080 --> 00:58:53.080
Indeed.

00:58:53.080 --> 00:58:54.080
Jody, final thoughts on this topic?

00:58:54.080 --> 00:58:55.560
And we'll pretty much wrap things up.

00:58:55.560 --> 00:58:58.200
Yeah, I don't think I really have that much to add, actually.

00:58:58.200 --> 00:58:59.440
I think it's all been said.

00:58:59.440 --> 00:59:00.440
It has.

00:59:00.440 --> 00:59:01.440
All right.

00:59:01.440 --> 00:59:05.240
Just to round things out, the two things that I think are trends here is I think, like Carol

00:59:05.240 --> 00:59:07.760
said a lot, Python on the front end is going to be super important.

00:59:07.760 --> 00:59:10.120
I think PyScript is really, really interesting.

00:59:10.120 --> 00:59:16.760
I've been waiting for people to develop something like React or Vue or something that we could

00:59:16.760 --> 00:59:18.400
create commercial-facing websites.

00:59:18.400 --> 00:59:23.600
We're halfway there with MicroPython being the foundation of PyScript, which is 100K

00:59:23.600 --> 00:59:25.080
instead of 10 megs.

00:59:25.080 --> 00:59:27.080
All of a sudden it becomes JavaScript-y size.

00:59:27.080 --> 00:59:29.080
It opens the possibilities.

00:59:29.080 --> 00:59:33.680
And just a shout out to PewPy, which is like Vue with Python, P-U-E, P-Y.

00:59:33.680 --> 00:59:38.400
I'm going to interview Ken from that project, but it's kind of a component-based front end

00:59:38.400 --> 00:59:40.440
for PyScript, which is pretty interesting.

00:59:40.440 --> 00:59:43.120
Of course, JupyterLite is really, really important.

00:59:43.120 --> 00:59:45.680
The other one was just all this Rust.

00:59:45.680 --> 00:59:49.480
Everything seems to be redone in Rust, and oh my gosh, that's how you get your VC funding.

00:59:49.480 --> 00:59:50.640
Just joking, sort of.

00:59:50.640 --> 00:59:56.080
But all you talked about, all this performance stuff coming, while it is sometimes frustrating

00:59:56.080 --> 01:00:00.040
that people are putting all the things into Rust because then Python programmers, it's

01:00:00.040 --> 01:00:04.600
less approachable for them, it could also be an escape hatch from trying to force the

01:00:04.600 --> 01:00:06.400
complexity into the Python side.

01:00:06.400 --> 01:00:11.040
Alleviate, like everything has to be multi-threaded and crazy and optimized.

01:00:11.040 --> 01:00:12.600
And well, this part you never look at.

01:00:12.600 --> 01:00:14.480
It's faster now, so don't worry.

01:00:14.480 --> 01:00:15.720
Anyway, those are my two trends.

01:00:15.720 --> 01:00:18.080
Quick, quick, quick thoughts on that and we'll call it a show.

01:00:18.080 --> 01:00:24.680
My piece of trivia is I made a contribution to Rust far before I made any contributions

01:00:24.680 --> 01:00:25.680
to core Python.

01:00:25.680 --> 01:00:26.320
Amazing.

01:00:26.320 --> 01:00:30.920
Because I tended to be a C programmer in heart and spirit.

01:00:30.920 --> 01:00:35.240
And so Rust seemed like this cool thing that was new at the time.

01:00:35.240 --> 01:00:42.120
And ultimately, I personally did not find the syntactic side of it worked well with

01:00:42.120 --> 01:00:44.400
my brain and how I think.

01:00:44.400 --> 01:00:52.180
And Python was far cleaner in terms of a simpler visual, less clutter, and reminded me a little

01:00:52.180 --> 01:00:56.560
more of small talk or something like that, which I loved from earlier days.

01:00:56.560 --> 01:01:00.040
But I think there's a place for Rust.

01:01:00.040 --> 01:01:03.480
I think Rust is going to replace Python now.

01:01:03.480 --> 01:01:07.420
I think it's going to help with some optimized things.

01:01:07.420 --> 01:01:14.680
Do I love things like Ruff that let me run my CI like blazing fast versus all the Python

01:01:14.680 --> 01:01:15.680
tools?

01:01:15.680 --> 01:01:20.700
Not to say that all the Python tools are bad, but when you're paying for it as a startup.

01:01:20.700 --> 01:01:23.680
When things you used to have to wait on become, they blink of an eye, all of a sudden you

01:01:23.680 --> 01:01:27.000
don't mind running them every time and it changes the way you work with tools.

01:01:27.000 --> 01:01:28.000
Yeah.

01:01:28.000 --> 01:01:29.000
Exactly.

01:01:29.000 --> 01:01:30.000
Yeah.

01:01:30.000 --> 01:01:32.240
I would say, look, every language has its place in the ecosystem.

01:01:32.240 --> 01:01:37.720
And my husband is a long time Pythonista, but he's also a Rust programmer.

01:01:37.720 --> 01:01:41.160
I know it's like a running joke that my husband is a Rust developer.

01:01:41.160 --> 01:01:42.160
How do you know?

01:01:42.160 --> 01:01:43.160
He'll ask you.

01:01:43.160 --> 01:01:44.960
Well, you know what I mean?

01:01:44.960 --> 01:01:45.960
How do you know?

01:01:45.960 --> 01:01:46.960
Ask him, he'll tell you.

01:01:46.960 --> 01:01:47.960
There you go.

01:01:47.960 --> 01:01:54.260
They have different purposes, completely different purposes, and you can't just interchange them.

01:01:54.260 --> 01:01:55.260
Absolutely.

01:01:55.260 --> 01:01:56.260
Just get it straight.

01:01:56.260 --> 01:01:57.260
Python is just awesome, says our Tim.

01:01:57.260 --> 01:01:58.260
Pure love.

01:01:58.260 --> 01:02:00.420
But it's up to us to keep it awesome.

01:02:00.420 --> 01:02:01.420
Yes, absolutely.

01:02:01.420 --> 01:02:05.660
Paul, we've come around to you for the very final, final thought on this excellent show.

01:02:05.660 --> 01:02:11.540
I will give a final thought about Python trends to follow up on what Carol just said about

01:02:11.540 --> 01:02:13.180
it's up to us.

01:02:13.180 --> 01:02:19.100
Maybe it's up to us to help the people who will keep it that way.

01:02:19.100 --> 01:02:22.980
The next generation of heroes, help them succeed.

01:02:22.980 --> 01:02:30.700
I'm wearing my PyCon Kenya friendship bracelet that I got at PyCon and a wonderful experience

01:02:30.700 --> 01:02:34.340
meeting so many different kinds of people.

01:02:34.340 --> 01:02:38.460
And from a Python trends perspective, the fact that everything we're talking about is

01:02:38.460 --> 01:02:42.980
good stuff, not like asteroid meets earth.

01:02:42.980 --> 01:02:48.300
IP challenges and patent wars and mergers and acquisitions and stuff.

01:02:48.300 --> 01:02:53.020
I remember a long time ago, I went to go see Guido and he was with the App Engine team

01:02:53.020 --> 01:02:54.020
at Google.

01:02:54.020 --> 01:02:55.020
So a long time ago.

01:02:55.020 --> 01:03:00.380
And he was starting the process of turning over PEP review to other people.

01:03:00.380 --> 01:03:06.660
And I commented to him that not every open source success story outlives its founder.

01:03:06.660 --> 01:03:12.580
And the bigger it gets, particularly open source projects anchored in the United States

01:03:12.580 --> 01:03:19.380
of America, they sell out and get funded and they will never be the same after that.

01:03:19.380 --> 01:03:26.020
And so it's a moment from a Python trends perspective for us to build a great next future

01:03:26.020 --> 01:03:30.180
by remembering how lucky we are where we have gotten to.

01:03:30.180 --> 01:03:31.180
Absolutely.

01:03:31.180 --> 01:03:33.620
Carol, Jody, Paul, thank you for being on the show.

01:03:33.620 --> 01:03:34.620
Thank you.

01:03:34.620 --> 01:03:35.620
Thanks, Michael.

01:03:35.620 --> 01:03:36.620
Thank you.

01:03:36.620 --> 01:03:37.620
Bye.

01:03:37.620 --> 01:03:40.540
This has been another episode of Talk Python to Me.

01:03:40.540 --> 01:03:41.540
Thank you to our sponsors.

01:03:41.540 --> 01:03:43.220
Be sure to check out what they're offering.

01:03:43.220 --> 01:03:45.260
It really helps support the show.

01:03:45.260 --> 01:03:48.240
Code comments, an original podcast from Red Hat.

01:03:48.240 --> 01:03:53.620
This podcast covers stories from technologists who've been through tough tech transitions

01:03:53.620 --> 01:03:57.140
and share how their teams survived the journey.

01:03:57.140 --> 01:04:03.500
Episodes are available everywhere you listen to your podcasts and at talkpython.fm/code-comments.

01:04:03.500 --> 01:04:07.340
This episode is sponsored by Posit Connect from the makers of Shiny.

01:04:07.340 --> 01:04:12.140
Publish, share and deploy all of your data projects that you're creating using Python.

01:04:12.140 --> 01:04:18.980
Streamlit, Dash, Shiny, Bokeh, FastAPI, Flask, Quarto, Reports, Dashboards and APIs.

01:04:18.980 --> 01:04:20.900
Posit Connect supports all of them.

01:04:20.900 --> 01:04:23.580
Try Posit Connect for free by going to talkpython.fm/posit.

01:04:23.580 --> 01:04:24.580
P-O-S-I-T.

01:04:24.580 --> 01:04:28.460
Want to level up your Python?

01:04:28.460 --> 01:04:32.540
We have one of the largest catalogs of Python video courses over at Talk Python.

01:04:32.540 --> 01:04:37.660
Our content ranges from true beginners to deeply advanced topics like memory and async.

01:04:37.660 --> 01:04:40.340
And best of all, there's not a subscription in sight.

01:04:40.340 --> 01:04:43.500
Check it out for yourself at training.talkpython.fm.

01:04:43.500 --> 01:04:48.140
Be sure to subscribe to the show, open your favorite podcast app and search for Python.

01:04:48.140 --> 01:04:49.500
We should be right at the top.

01:04:49.500 --> 01:04:55.060
You can also find the iTunes feed at /itunes, the Google Play feed at /play, and the Direct

01:04:55.060 --> 01:04:59.100
RSS feed at /rss on talkpython.fm.

01:04:59.100 --> 01:05:01.660
We're live streaming most of our recordings these days.

01:05:01.660 --> 01:05:05.260
If you want to be part of the show and have your comments featured on the air, be sure

01:05:05.260 --> 01:05:10.180
to subscribe to our YouTube channel at talkpython.fm/youtube.

01:05:10.180 --> 01:05:11.500
This is your host, Michael Kennedy.

01:05:11.500 --> 01:05:12.620
Thanks so much for listening.

01:05:12.620 --> 01:05:13.860
I really appreciate it.

01:05:13.860 --> 01:05:15.620
Now get out there and write some Python code.

01:05:16.460 --> 01:05:20.460
[MUSIC PLAYING]

01:05:20.460 --> 01:05:36.620
[END PLAYBACK]

