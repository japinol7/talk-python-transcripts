WEBVTT

00:00:00.000 --> 00:00:02.000
We all know about Flask and Django.


00:00:02.000 --> 00:00:06.800
And of course, FastAPI made a huge splash when it came on the scene a few years ago.


00:00:06.800 --> 00:00:09.600
But new web frameworks are being created all the time.


00:00:09.600 --> 00:00:12.720
And they have these earlier frameworks to borrow from as well.


00:00:12.720 --> 00:00:17.440
On this episode, we dive into a new framework gaining a lot of traction called Litestar.


00:00:17.440 --> 00:00:19.760
Will it be the foundation of your next project?


00:00:19.760 --> 00:00:23.200
Join me as I get to know Litestar with its maintainers, Jacob Coffey,


00:00:23.200 --> 00:00:25.600
Janek Nowianty, and Jacob Finchner.


00:00:26.480 --> 00:00:31.840
This is episode 433, recorded August 30th, 2023.


00:00:31.840 --> 00:00:49.680
Welcome to Talk Python to Me, a weekly podcast on Python.


00:00:49.680 --> 00:00:51.440
This is your host, Michael Kennedy.


00:00:51.440 --> 00:00:56.640
Follow me on Mastodon, where I'm@mkennedy and follow the podcast using at Talk Python,


00:00:56.640 --> 00:00:59.040
both on fosstodon.org.


00:00:59.040 --> 00:01:04.320
Keep up with the show and listen to over seven years of past episodes at talkpython.fm.


00:01:04.320 --> 00:01:07.840
We've started streaming most of our episodes live on YouTube.


00:01:07.840 --> 00:01:12.400
Subscribe to our YouTube channel over at talkpython.fm/youtube to get notified


00:01:12.400 --> 00:01:15.600
about upcoming shows and be part of that episode.


00:01:15.600 --> 00:01:20.320
This episode is brought to you by Sentry and us over at Talk Python Training.


00:01:20.320 --> 00:01:22.880
Please check out what we're both offering during our segments.


00:01:22.880 --> 00:01:24.640
It really helps support the show.


00:01:24.640 --> 00:01:29.600
Everyone, Janek, Jacob, Cody, welcome to Talk Python to Me.


00:01:29.600 --> 00:01:31.600
Hey, thanks for having us.


00:01:31.600 --> 00:01:32.720
Good to be here.


00:01:32.720 --> 00:01:34.640
Yeah, it's great to have you all here.


00:01:34.640 --> 00:01:40.240
Really excited to talk about one of my favorite topics, web frameworks, APIs,


00:01:40.240 --> 00:01:43.200
async performance, design patterns, like, let's do this.


00:01:43.200 --> 00:01:43.700
Let's do it.


00:01:43.700 --> 00:01:44.960
Cool.


00:01:44.960 --> 00:01:49.840
So we're going to talk about Litestar, which is somewhat new to me.


00:01:49.840 --> 00:01:53.920
I haven't known about it that long, but looking at the GitHub stars being


00:01:53.920 --> 00:01:58.480
several thousand GitHub stars and release two, it's definitely been going for a while.


00:01:58.480 --> 00:02:03.200
So it's a really cool framework that I think people will definitely be excited to learn about.


00:02:03.200 --> 00:02:05.520
But before we get to that, let's start with you all.


00:02:05.520 --> 00:02:08.320
Just a quick introduction for each of you.


00:02:08.320 --> 00:02:12.560
Go around the Brady Bunch squares of our video here.


00:02:12.560 --> 00:02:13.920
Janek, you want to go first?


00:02:13.920 --> 00:02:14.400
Yeah.


00:02:14.400 --> 00:02:14.960
Yeah, sure.


00:02:14.960 --> 00:02:15.840
My name is Janek.


00:02:15.840 --> 00:02:20.320
Obviously, I'm a Python developer from Germany, currently living in Cologne.


00:02:20.320 --> 00:02:26.400
So I'm a bit behind the rest of the other guys when it comes to the time zones.


00:02:26.400 --> 00:02:28.000
I would put it a different way, Janek.


00:02:28.000 --> 00:02:29.520
I'd say you're living in the future.


00:02:29.520 --> 00:02:31.120
You're living hours ahead of time.


00:02:31.120 --> 00:02:32.160
You know what's already happened.


00:02:32.160 --> 00:02:32.480
Oh, yeah.


00:02:32.480 --> 00:02:34.000
That sounds much nicer.


00:02:34.000 --> 00:02:35.840
Yeah.


00:02:35.840 --> 00:02:39.120
Well, I currently work as a Python developer.


00:02:39.120 --> 00:02:42.960
Before I got into Python, I worked as a carpenter.


00:02:43.520 --> 00:02:46.880
So I've built furniture and other cool stuff.


00:02:46.880 --> 00:02:49.920
I think that's all we need to know right now.


00:02:49.920 --> 00:02:52.720
So, Cody, why don't you continue?


00:02:52.720 --> 00:02:53.600
Yeah, I'll be happy to.


00:02:53.600 --> 00:02:54.880
So hey, Michael.


00:02:54.880 --> 00:02:55.360
Hey, guys.


00:02:55.360 --> 00:02:56.160
I'm Cody.


00:02:56.160 --> 00:02:59.440
Really, I've kind of had an interesting journey into the Python space.


00:02:59.440 --> 00:03:03.120
And so I'm kind of probably atypical from the rest of the team here.


00:03:03.120 --> 00:03:07.760
And so I've actually been a long time database guy, specifically in Oracle.


00:03:07.760 --> 00:03:14.320
And so lots of big, nasty data warehouses, large transaction systems,


00:03:14.320 --> 00:03:17.200
and building all the glue that you've got to do to make that stuff run.


00:03:17.200 --> 00:03:22.080
And so I guess really my intro to Python was really around DevOps,


00:03:22.080 --> 00:03:25.600
doing how do you make the whole environment stay running?


00:03:25.600 --> 00:03:27.200
How do you keep it efficient?


00:03:27.200 --> 00:03:29.520
And it's really focused on the database side of things.


00:03:29.520 --> 00:03:32.800
And so about 10 years ago, moved to Dallas from Alabama,


00:03:32.800 --> 00:03:36.720
originally where I'm from, and joined a small team of Oracle developers.


00:03:36.720 --> 00:03:39.440
And so we got acquired by one of the big four consulting firms.


00:03:39.440 --> 00:03:42.400
And so at that point, I shifted into development,


00:03:42.400 --> 00:03:45.040
from development and into cloud migrations.


00:03:45.040 --> 00:03:49.760
So did quite a bit of just Oracle database migrations into the various cloud providers.


00:03:49.760 --> 00:03:54.320
And now, just long, about six years later, I've now wound up at Google


00:03:54.320 --> 00:03:57.200
as part of the database black belt team there.


00:03:57.200 --> 00:04:00.480
And I still try to figure out exactly what a database black belt is.


00:04:00.480 --> 00:04:02.880
But a year in, really what I can tell you is that


00:04:02.880 --> 00:04:04.720
what I do is talk to all of our biggest customers


00:04:04.720 --> 00:04:07.840
and figure out what are the features and things that they need


00:04:07.840 --> 00:04:10.000
to make their enterprises run on Google Cloud.


00:04:10.000 --> 00:04:12.560
And we work with the engineers to make that happen.


00:04:12.560 --> 00:04:14.000
What an interesting background.


00:04:14.000 --> 00:04:17.200
I would say having a really good background in databases,


00:04:17.200 --> 00:04:19.760
and especially the DevOps side of databases,


00:04:19.760 --> 00:04:22.480
is a pretty unique view for building a web framework.


00:04:22.480 --> 00:04:23.760
A lot of people are all about,


00:04:23.760 --> 00:04:26.240
oh, I got to have something for my front end code,


00:04:26.240 --> 00:04:27.840
my JavaScript I'm writing, right?


00:04:27.840 --> 00:04:29.360
And that's really not the same.


00:04:29.360 --> 00:04:32.640
Yes, and my career actually originally started using,


00:04:32.640 --> 00:04:34.880
well, I guess now they're called low code tools,


00:04:34.880 --> 00:04:37.360
but we used to call them rapid application development.


00:04:37.360 --> 00:04:40.000
And so there's just lots of database builders


00:04:40.000 --> 00:04:43.120
where there really wasn't any actual Python or any Java


00:04:43.120 --> 00:04:44.400
or those types of code involved.


00:04:44.400 --> 00:04:45.920
It was all PL SQL.


00:04:45.920 --> 00:04:49.200
So I was actually happy to get involved in the Python world


00:04:49.200 --> 00:04:50.080
and move out of that space.


00:04:50.080 --> 00:04:52.240
So yeah, excellent. Awesome. Jacob.


00:04:52.240 --> 00:04:54.960
Hey, I'm pretty new to being a developer.


00:04:54.960 --> 00:04:58.560
I spent the last four or five years in the system space,


00:04:58.560 --> 00:05:01.520
more on like the IT side of things,


00:05:01.520 --> 00:05:04.480
building systems and helping users.


00:05:04.480 --> 00:05:08.400
The last year though, I've gotten to DevOps on my team


00:05:08.400 --> 00:05:10.720
at O'Reilly, auto parts, not the book people.


00:05:10.720 --> 00:05:12.560
Been really interesting,


00:05:12.560 --> 00:05:15.920
but recently I got to join this team and I'm learning a lot.


00:05:15.920 --> 00:05:18.480
So this is really exciting for me to be here.


00:05:18.480 --> 00:05:20.560
Yeah, well, it's awesome to have you here.


00:05:20.560 --> 00:05:22.960
And like I said, a really exciting web project


00:05:22.960 --> 00:05:25.120
that I think people will appreciate.


00:05:25.120 --> 00:05:28.720
So let's go ahead and jump into it.


00:05:28.720 --> 00:05:31.520
So Litestar at lightstar.dev,


00:05:31.520 --> 00:05:34.080
effortlessly build performant APIs.


00:05:34.080 --> 00:05:38.400
So who wants to give us the elevator pitch here?


00:05:38.400 --> 00:05:40.960
The 30 second view of Litestar.


00:05:40.960 --> 00:05:42.960
Janik, I think Cody should do that.


00:05:42.960 --> 00:05:45.680
Oh, Janik, I'd like to hear what you think.


00:05:45.680 --> 00:05:48.000
And then I can give you about my perspective


00:05:48.000 --> 00:05:51.040
of how I kind of joined the team and what it means to me.


00:05:51.040 --> 00:05:53.440
But I think it would be helpful to hear


00:05:53.440 --> 00:05:54.160
how you think about it.


00:05:54.160 --> 00:05:56.640
All right. So what is Litestar?


00:05:56.640 --> 00:06:00.560
Well, I think our tagline is pretty, puts it pretty well.


00:06:00.560 --> 00:06:04.240
We definitely have a focus on building APIs.


00:06:04.240 --> 00:06:09.440
So not, well, not typical HTML applications monolith.


00:06:09.440 --> 00:06:12.240
It's often compared to FastAPI,


00:06:12.240 --> 00:06:14.640
and it has similarities, definitely,


00:06:14.640 --> 00:06:17.120
which FastAPI is already in the name.


00:06:17.120 --> 00:06:19.280
It's also focused on building APIs,


00:06:19.280 --> 00:06:23.440
but for us really important is the effortless part.


00:06:23.440 --> 00:06:28.160
So what we strive to do is to take away all the,


00:06:28.160 --> 00:06:31.280
well, not all, but as much as we can


00:06:31.280 --> 00:06:33.760
take away the boilerplate for developers,


00:06:33.760 --> 00:06:36.080
you usually have to do anyway


00:06:36.080 --> 00:06:39.120
when you're building any project of size,


00:06:39.120 --> 00:06:42.960
which includes lots of stuff like authorization,


00:06:42.960 --> 00:06:46.160
caching, ORM integration,


00:06:46.160 --> 00:06:49.600
and all these kinds of things that you usually have to do.


00:06:49.600 --> 00:06:53.920
And with micro frameworks like Flask or FastAPI


00:06:53.920 --> 00:06:57.040
or Starlette or any of the other ones out there,


00:06:57.040 --> 00:06:58.240
because there are a lot of them,


00:06:58.240 --> 00:07:01.840
and they are all really great at what they're doing,


00:07:01.840 --> 00:07:05.920
but they do require to build a lot of boilerplates,


00:07:05.920 --> 00:07:09.600
which can be good because it gives you a lot of control


00:07:09.600 --> 00:07:10.560
over what you're doing,


00:07:10.560 --> 00:07:13.600
and you can build it exactly how you want to.


00:07:13.600 --> 00:07:18.000
But it's also not, well, it's not completely effortless,


00:07:18.000 --> 00:07:20.400
which is what we are trying to achieve.


00:07:20.400 --> 00:07:22.800
Yeah, when I think about the web frameworks,


00:07:22.800 --> 00:07:27.040
I have this sort of bimodal distribution at like two ends.


00:07:27.040 --> 00:07:28.880
On one end, you have Django,


00:07:28.880 --> 00:07:30.800
where it comes with all of these helpers


00:07:30.800 --> 00:07:31.840
and all of these things.


00:07:31.840 --> 00:07:34.640
Like you just say, yes, I want a whole back end


00:07:34.640 --> 00:07:37.680
to manage my database with a UI, for example, right?


00:07:37.680 --> 00:07:39.520
Well, there's a bunch of those kinds of things,


00:07:39.520 --> 00:07:42.960
form creation and the ORM migrations,


00:07:42.960 --> 00:07:45.280
all that stuff is kind of just, you get it all.


00:07:45.280 --> 00:07:46.880
And the other end, you have Flask


00:07:46.880 --> 00:07:49.520
and you have FastAPI and a whole bunch of others,


00:07:49.520 --> 00:07:50.960
Sanic, you name it.


00:07:50.960 --> 00:07:53.200
And there's a lot, and they're all about,


00:07:53.200 --> 00:07:56.800
we're going to go and handle the request,


00:07:56.800 --> 00:07:58.000
and then it's up to you.


00:07:58.000 --> 00:07:58.880
Do you want a database?


00:07:58.880 --> 00:07:59.680
You can have a database.


00:07:59.680 --> 00:08:01.200
If you don't want one, don't have one.


00:08:01.200 --> 00:08:04.000
In that regard, FastAPI itself


00:08:04.000 --> 00:08:05.760
is kind of almost prescriptive


00:08:05.760 --> 00:08:09.840
in that it talks about having like model exchange


00:08:09.840 --> 00:08:13.760
and defining models that create how the website works.


00:08:13.760 --> 00:08:15.600
Whereas Flask doesn't even have that.


00:08:15.600 --> 00:08:16.400
You just kind of nailed it.


00:08:16.400 --> 00:08:18.880
And this is actually how I kind of came into,


00:08:18.880 --> 00:08:20.400
it was actually Starlette at the time.


00:08:20.400 --> 00:08:22.560
But I guess about four years ago,


00:08:22.560 --> 00:08:24.960
I built a pretty large scale Django app


00:08:24.960 --> 00:08:26.880
for some consulting work.


00:08:26.880 --> 00:08:30.480
And it was really around data quality and data migration.


00:08:30.480 --> 00:08:31.520
And it worked really well.


00:08:31.520 --> 00:08:34.160
But I was reading all this stuff about FastAPI


00:08:34.160 --> 00:08:36.320
and I really liked what I was seeing.


00:08:36.320 --> 00:08:38.880
And the developer experience of that was really incredible.


00:08:38.880 --> 00:08:41.040
And the tools that those guys put together


00:08:41.040 --> 00:08:42.640
was just kind of second to none.


00:08:42.640 --> 00:08:45.360
It was really refreshing to see that kind of build


00:08:45.360 --> 00:08:48.000
in over what you see in Django.


00:08:48.000 --> 00:08:51.840
And so I started working with FastAPI and really liked it.


00:08:51.840 --> 00:08:54.160
But I got to where I felt like I had a lot of boilerplate


00:08:54.160 --> 00:08:57.360
that I added on top of that to get to that working app.


00:08:57.360 --> 00:08:59.840
And so when we joined up with Google,


00:08:59.840 --> 00:09:01.840
one of the things that I did was say,


00:09:01.840 --> 00:09:04.160
okay, I've got a lot of like boilerplate


00:09:04.160 --> 00:09:05.920
for things that I need to run this app.


00:09:05.920 --> 00:09:08.400
And maybe there's somewhere that I can contribute.


00:09:08.400 --> 00:09:09.200
And so at that point,


00:09:09.200 --> 00:09:12.000
I started looking around at all the web frameworks.


00:09:12.000 --> 00:09:15.040
And that's when I got introduced to Starlette at the time.


00:09:15.040 --> 00:09:18.000
And just to give a little bit of a history,


00:09:18.000 --> 00:09:19.440
it was originally called Starlette


00:09:19.440 --> 00:09:21.840
because it was based on Starlet,


00:09:21.840 --> 00:09:24.160
just like all the other ASCII frameworks out there.


00:09:24.160 --> 00:09:27.120
And obviously Starlette is an awesome tool.


00:09:27.120 --> 00:09:30.080
And we were kind of paying respect to that


00:09:30.080 --> 00:09:31.360
by naming it Starlette.


00:09:31.360 --> 00:09:34.000
But obviously there's very few letters


00:09:34.000 --> 00:09:35.520
in between that and Starlet.


00:09:35.520 --> 00:09:38.320
And so what we found is that many of the posts that we made,


00:09:38.320 --> 00:09:39.600
people were confusing,


00:09:39.600 --> 00:09:40.720
hey, did you mean Starlet?


00:09:40.720 --> 00:09:42.240
Because I don't know what a Starlette is.


00:09:42.240 --> 00:09:43.920
And so long story short,


00:09:43.920 --> 00:09:46.240
we said, okay, it's time for us to rename.


00:09:46.240 --> 00:09:48.960
And I guess we're all not too original


00:09:48.960 --> 00:09:50.320
because we just flipped the wording around.


00:09:50.320 --> 00:09:51.680
And that's how we came up with Litestar.


00:09:51.680 --> 00:09:53.920
It's a cool name. I like it.


00:09:53.920 --> 00:09:56.480
Yeah. And just for people who don't necessarily know,


00:09:56.480 --> 00:10:00.960
much of FastAPI's magic is that it's built on Starlet.


00:10:00.960 --> 00:10:02.000
And so in a sense,


00:10:02.000 --> 00:10:03.840
you're running on the same foundation


00:10:03.840 --> 00:10:06.000
as FastAPI in that regard, right?


00:10:06.000 --> 00:10:07.600
No, we're actually not anymore.


00:10:07.600 --> 00:10:08.000
So...


00:10:08.000 --> 00:10:10.000
Okay. That was the original. All right.


00:10:10.000 --> 00:10:12.000
I think we have dropped Starlet


00:10:12.000 --> 00:10:17.520
as a dependency about like six, seven months ago,


00:10:17.520 --> 00:10:18.480
before version two.


00:10:18.480 --> 00:10:18.880
Yeah.


00:10:18.880 --> 00:10:20.880
So in the beginning, we were...


00:10:20.880 --> 00:10:23.680
Well, Starlette is built very, very modular.


00:10:23.680 --> 00:10:27.280
You can use like FastAPI, use the whole thing,


00:10:27.280 --> 00:10:29.360
and you can just extend the router


00:10:29.360 --> 00:10:30.720
and don't care about anything.


00:10:30.720 --> 00:10:32.400
But it's also designed in such a way


00:10:32.400 --> 00:10:35.680
that you can just take certain things of it.


00:10:35.680 --> 00:10:39.040
So you can say, okay, I just like the routing


00:10:39.040 --> 00:10:40.640
and the rest I'll do myself.


00:10:40.640 --> 00:10:45.360
And what we originally did was we had our own router,


00:10:45.360 --> 00:10:49.440
our own routing system, and plugged that into Starlet


00:10:49.440 --> 00:10:52.000
and built our own application on top of that.


00:10:52.000 --> 00:10:55.680
But over time, we have diverged quite a lot


00:10:55.680 --> 00:10:58.640
from the way Starlette wanted to do things,


00:10:58.640 --> 00:11:00.640
or well, not wanted to do things,


00:11:00.640 --> 00:11:03.120
but Starlette became a bit restrictive


00:11:03.120 --> 00:11:05.600
because we wanted to do things very differently


00:11:05.600 --> 00:11:09.120
at very deep parts of the Starlette stack.


00:11:09.120 --> 00:11:12.240
And so it kind of made sense to us


00:11:12.240 --> 00:11:14.960
that we just wrote our own basically


00:11:14.960 --> 00:11:18.720
and filled in the gaps that Starlette left behind,


00:11:18.720 --> 00:11:21.040
which wasn't an easy decision


00:11:21.040 --> 00:11:24.160
because Starlette is a very great piece of technology


00:11:24.160 --> 00:11:25.760
and it's very well done.


00:11:25.760 --> 00:11:27.600
And it's got a lot of credibility to it, right?


00:11:27.600 --> 00:11:28.960
You know, there's a lot of people


00:11:28.960 --> 00:11:30.000
that run it in production,


00:11:30.000 --> 00:11:32.240
and that means something when you have a tool


00:11:32.240 --> 00:11:33.760
that is known to work well.


00:11:33.760 --> 00:11:36.000
It was a bit of a challenge to get that going.


00:11:36.560 --> 00:11:41.120
But yeah, at the moment, we are from the ASGI side,


00:11:41.120 --> 00:11:42.800
our very own thing.


00:11:42.800 --> 00:11:46.480
We don't depend on anything else in that regard anymore.


00:11:46.480 --> 00:11:47.920
Okay. And is that all Python


00:11:47.920 --> 00:11:52.640
or is that got some other technology making it go in there?


00:11:52.640 --> 00:11:55.280
So that part, the ASGI part is all Python.


00:11:55.280 --> 00:11:58.160
We have some other non-Python parts,


00:11:58.160 --> 00:12:03.120
but they are not at the web serving side, let's say.


00:12:03.120 --> 00:12:06.160
So we've rustified, I guess that's the term, if you will,


00:12:06.160 --> 00:12:07.360
at least one place.


00:12:07.360 --> 00:12:08.880
That's the URL parsers, right?


00:12:08.880 --> 00:12:10.000
Yeah, the query parsers.


00:12:10.000 --> 00:12:12.320
Okay. That certainly is a strong trend these days.


00:12:12.320 --> 00:12:13.840
Although I'm surprised for a framework


00:12:13.840 --> 00:12:15.200
that hasn't been around that long


00:12:15.200 --> 00:12:16.400
that it's already got rust.


00:12:16.400 --> 00:12:16.960
No, just kidding.


00:12:16.960 --> 00:12:20.800
We experimented about a year ago.


00:12:20.800 --> 00:12:23.280
We experimented actually with more rust


00:12:23.280 --> 00:12:25.920
and that was to do the routing in rust.


00:12:25.920 --> 00:12:29.440
So we use a Redix-based router.


00:12:29.440 --> 00:12:32.080
That's something Sanic does that as well.


00:12:32.080 --> 00:12:35.280
And we experimented with a rust implementation,


00:12:35.280 --> 00:12:37.920
but it was decided that the speed up


00:12:37.920 --> 00:12:40.960
that we got from using rust wasn't really worth


00:12:40.960 --> 00:12:44.640
the trade-off between it being harder to maintain


00:12:44.640 --> 00:12:47.920
and being less accessible for other contributors.


00:12:47.920 --> 00:12:50.080
Because most of the people who are using


00:12:50.080 --> 00:12:52.320
a Python web framework, they will know Python,


00:12:52.320 --> 00:12:55.920
but they're not necessarily that fluent in rust.


00:12:55.920 --> 00:12:59.120
And well, basically the router wasn't really


00:12:59.120 --> 00:13:02.400
that big of a bottleneck for Starlette at the time.


00:13:02.400 --> 00:13:04.480
So it didn't make a lot of sense


00:13:04.480 --> 00:13:06.640
to write that part in rust.


00:13:06.640 --> 00:13:08.400
Yeah. It's a big trade-off, isn't it?


00:13:08.400 --> 00:13:10.240
Even things like shipping wheels


00:13:10.240 --> 00:13:12.160
and just pushing out a version.


00:13:12.160 --> 00:13:13.760
Once you start to go into a, well,


00:13:13.760 --> 00:13:16.720
there's a per platform compilation step.


00:13:16.720 --> 00:13:18.160
That has a lot of friction, right?


00:13:18.160 --> 00:13:20.000
And I'm sure you could do a whole podcast


00:13:20.000 --> 00:13:22.080
just on packaging, but Python packaging


00:13:22.080 --> 00:13:24.960
in and of itself is not always the easiest


00:13:24.960 --> 00:13:26.560
or most intuitive process.


00:13:26.560 --> 00:13:28.560
And so, yeah, it definitely gets complicated


00:13:28.560 --> 00:13:30.160
when you add in another language.


00:13:30.160 --> 00:13:31.040
Yeah, I can imagine.


00:13:31.040 --> 00:13:34.320
And in a lot of cases, there are more low-hanging fruits


00:13:34.320 --> 00:13:37.520
that you can grab and just optimize things there


00:13:37.520 --> 00:13:40.160
before you say, okay, now we have optimized everything


00:13:40.160 --> 00:13:42.240
so well, the only way we can get faster


00:13:42.240 --> 00:13:44.720
if we now use a language like rust.


00:13:44.720 --> 00:13:48.240
And I don't think we're at that part yet.


00:13:48.240 --> 00:13:50.480
So we have yet still a lot of things to do.


00:13:50.480 --> 00:13:51.120
That's excellent.


00:13:51.120 --> 00:13:52.880
It's a really good philosophy too, I think.


00:13:52.880 --> 00:13:55.040
There's an interesting new way


00:13:55.040 --> 00:13:56.560
to make your Python code faster


00:13:56.560 --> 00:13:58.400
that used to be the case


00:13:58.400 --> 00:14:00.560
when Moore's law was really in effect.


00:14:00.560 --> 00:14:02.880
You went from a 486 to a Pentium


00:14:02.880 --> 00:14:04.880
to a whatever gigahertz


00:14:04.880 --> 00:14:06.560
and from megahertz to gigahertz


00:14:06.560 --> 00:14:07.600
and all those things, you just wait


00:14:07.600 --> 00:14:08.800
and the hardware got faster.


00:14:08.800 --> 00:14:10.080
So your code went faster.


00:14:10.080 --> 00:14:12.640
But with the faster CPython initiative


00:14:12.640 --> 00:14:16.000
and Guido and Mark Shannon and team over there,


00:14:16.000 --> 00:14:18.640
they're making Python quite a bit faster constantly


00:14:18.640 --> 00:14:19.440
with every release.


00:14:19.440 --> 00:14:22.000
It's really impressive what they've done.


00:14:22.000 --> 00:14:24.160
It was a noticeable for the projects


00:14:24.160 --> 00:14:25.520
that I'm currently using Lightswirl


00:14:25.520 --> 00:14:27.600
and it was a noticeable increase in performance


00:14:27.600 --> 00:14:29.200
when I went to 3.11.


00:14:29.200 --> 00:14:31.520
And yeah, looking forward to seeing what all they do


00:14:31.520 --> 00:14:32.640
over the next couple of releases.


00:14:32.640 --> 00:14:35.200
– Yeah, we just last week, I think,


00:14:35.200 --> 00:14:36.560
no, this week perhaps,


00:14:36.560 --> 00:14:39.360
had the release candidate for 3.12.


00:14:39.360 --> 00:14:42.320
So it's kind of final besides the bugs,


00:14:42.320 --> 00:14:44.400
which is, you know, people can start testing it


00:14:44.400 --> 00:14:45.920
and see what's to come out of there as well.


00:14:45.920 --> 00:14:48.960
– Yeah, we haven't actually tested yet with 3.12


00:14:48.960 --> 00:14:50.080
because we're still waiting


00:14:50.080 --> 00:14:52.160
on some of our dependencies


00:14:52.160 --> 00:14:54.240
to be compatible with that.


00:14:54.240 --> 00:14:56.480
Jacob, do you want to say something?


00:14:56.480 --> 00:14:58.080
– We just have two more.


00:14:58.080 --> 00:15:01.360
I think it's GRPC and Greenlet.


00:15:01.360 --> 00:15:03.440
Greenlet actually, I think, is ready,


00:15:03.440 --> 00:15:06.160
but they need to do a release to PyPI.


00:15:06.160 --> 00:15:10.320
But the GRPC is, I think, one of our stragglers.


00:15:10.320 --> 00:15:10.720
– Okay.


00:15:10.720 --> 00:15:12.000
– I've been eager to test that


00:15:12.000 --> 00:15:13.840
and see what kind of performance we can get.


00:15:13.840 --> 00:15:15.920
I guess we could do the RC one now,


00:15:15.920 --> 00:15:17.840
but we'll wait.


00:15:17.840 --> 00:15:19.280
– We should probably test it out at some point.


00:15:19.280 --> 00:15:20.720
– Okay, interesting.


00:15:20.720 --> 00:15:22.880
Yeah, I mean, that's always the constant struggle, right?


00:15:22.880 --> 00:15:25.840
Is you've got a lot of dependencies here on and on.


00:15:25.840 --> 00:15:27.600
– A huge number of them are optional,


00:15:27.600 --> 00:15:29.920
but yes, it can get a little crazy.


00:15:29.920 --> 00:15:30.320
– Yeah.


00:15:30.320 --> 00:15:31.920
– That's actually a good point to make.


00:15:31.920 --> 00:15:33.200
You know, one of the things you'll see


00:15:33.200 --> 00:15:34.800
is that there are quite a lot of dependencies,


00:15:34.800 --> 00:15:36.160
but you'll see that a lot of them


00:15:36.160 --> 00:15:38.400
are tied to optional groups.


00:15:38.400 --> 00:15:40.160
And so one of the things that we wanted to do


00:15:40.160 --> 00:15:41.680
was make it quick for a user


00:15:41.680 --> 00:15:43.600
to kind of pip install one thing


00:15:43.600 --> 00:15:46.560
and have all the pieces they need to get started.


00:15:46.560 --> 00:15:49.760
And so you can say pip install Litestar,


00:15:49.760 --> 00:15:52.400
and you can add the CLI or the standard group,


00:15:52.400 --> 00:15:55.120
and it'll automatically install the JS beautifier


00:15:55.120 --> 00:15:56.560
and the command line utilities


00:15:56.560 --> 00:15:58.800
and rich and a couple of other libraries.


00:15:58.800 --> 00:16:00.160
And so there's a lot of helpers


00:16:00.160 --> 00:16:02.320
to kind of make that a little bit more easy


00:16:02.320 --> 00:16:03.360
to just jump right in.


00:16:03.360 --> 00:16:03.680
– Right.


00:16:03.680 --> 00:16:06.240
This portion of Talk Python to Me


00:16:06.240 --> 00:16:07.600
is brought to you by Sentry.


00:16:07.600 --> 00:16:10.560
Is your Python application fast


00:16:10.560 --> 00:16:12.960
or does it sometimes suffer from slowdowns


00:16:12.960 --> 00:16:14.400
and unexpected latency?


00:16:14.400 --> 00:16:17.280
Does this usually only happen in production?


00:16:17.280 --> 00:16:19.120
It's really tough to track down the problems


00:16:19.120 --> 00:16:20.000
at that point, isn't it?


00:16:20.000 --> 00:16:22.160
If you've looked at APM,


00:16:22.160 --> 00:16:24.640
Application Performance Monitoring products before,


00:16:24.640 --> 00:16:27.040
they may have felt out of place for software teams.


00:16:27.040 --> 00:16:29.760
Many of them are more focused on legacy problems


00:16:29.760 --> 00:16:31.760
made for ops and infrastructure teams


00:16:31.760 --> 00:16:35.280
to keep their infrastructure and services up and running.


00:16:35.280 --> 00:16:39.360
Sentry has just launched their new APM service.


00:16:39.360 --> 00:16:41.680
And Sentry's approach to application monitoring


00:16:41.680 --> 00:16:44.240
is focused on being actionable, affordable,


00:16:44.240 --> 00:16:46.400
and actually built for developers.


00:16:46.400 --> 00:16:47.920
Whether it's a slow running query


00:16:47.920 --> 00:16:49.280
or latent payment endpoint


00:16:49.280 --> 00:16:52.240
that's at risk of timing out and causing sales to tank,


00:16:52.240 --> 00:16:54.160
Sentry removes the complexity


00:16:54.160 --> 00:16:56.080
and does the analysis for you,


00:16:56.080 --> 00:16:58.320
surfacing the most critical performance issues


00:16:58.320 --> 00:17:00.160
so you can address them immediately.


00:17:00.160 --> 00:17:02.240
Most legacy APM tools focus on


00:17:02.240 --> 00:17:04.400
an ingest-everything approach,


00:17:04.400 --> 00:17:06.320
resulting in high storage costs,


00:17:06.320 --> 00:17:07.200
noisy environments,


00:17:07.200 --> 00:17:09.680
and an enormous amount of telemetry data


00:17:09.680 --> 00:17:12.080
most developers will never need to analyze.


00:17:12.080 --> 00:17:14.640
Sentry has taken a different approach,


00:17:14.640 --> 00:17:17.360
building the most affordable APM solution in the market.


00:17:17.360 --> 00:17:19.040
They remove the noise


00:17:19.040 --> 00:17:20.720
and extract the maximum value


00:17:20.720 --> 00:17:21.920
out of your performance data


00:17:21.920 --> 00:17:24.080
while passing the savings directly onto you,


00:17:24.080 --> 00:17:26.560
especially for Talk Python listeners


00:17:26.560 --> 00:17:28.000
who use the code Talk Python.


00:17:28.000 --> 00:17:32.080
So get started at talkpython.fm/sentry


00:17:32.080 --> 00:17:34.800
and be sure to use their code Talk Python,


00:17:34.800 --> 00:17:35.680
all lowercase,


00:17:35.680 --> 00:17:38.080
so you let them know that you heard about them from us.


00:17:38.080 --> 00:17:40.400
My thanks to Sentry


00:17:40.400 --> 00:17:42.480
for keeping this podcast going strong.


00:17:42.480 --> 00:17:46.560
And it looks like you've got, say, like Oracle


00:17:46.560 --> 00:17:49.760
or DuckDB or other things that maybe not everyone,


00:17:49.760 --> 00:17:51.440
or, you know, AsyncPG,


00:17:51.440 --> 00:17:52.480
all those types of things


00:17:52.480 --> 00:17:54.320
that you probably only need one of those, right?


00:17:54.320 --> 00:17:58.160
You're probably not doing MySQL, Postgres, and Oracle.


00:17:58.160 --> 00:17:59.440
Maybe, but probably not.


00:17:59.440 --> 00:18:00.720
We actually do all of them.


00:18:00.720 --> 00:18:01.920
And so with the same,


00:18:01.920 --> 00:18:02.800
and this is one of the things


00:18:02.800 --> 00:18:04.640
that I think is probably good to point out,


00:18:04.640 --> 00:18:07.760
is that with the repository contrib module


00:18:07.760 --> 00:18:08.480
that we've created,


00:18:08.480 --> 00:18:11.520
you actually can use the same repository,


00:18:11.520 --> 00:18:12.640
the same models,


00:18:12.640 --> 00:18:14.080
the same JSON type,


00:18:14.080 --> 00:18:16.640
and it will automatically select the best data type


00:18:16.640 --> 00:18:18.000
for whatever engine you're running.


00:18:18.000 --> 00:18:19.680
So for instance, if you're on,


00:18:19.680 --> 00:18:20.640
let's just say that today


00:18:20.640 --> 00:18:23.040
you're running on AsyncPG with Postgres,


00:18:23.040 --> 00:18:25.200
and you've got a JSONB data type


00:18:25.200 --> 00:18:28.560
using the built-in custom Litestar JSON type,


00:18:28.560 --> 00:18:31.120
and tomorrow you convert to Oracle,


00:18:31.120 --> 00:18:32.880
all you need to do is change your connect string,


00:18:32.880 --> 00:18:34.960
and it'll automatically deploy that to Oracle


00:18:34.960 --> 00:18:36.560
with the correct JSON type.


00:18:36.560 --> 00:18:39.120
And so you really don't have to do anything additional


00:18:39.120 --> 00:18:41.600
to make your code work between that.


00:18:41.600 --> 00:18:44.560
So honestly, a lot of that came from my time with Django,


00:18:44.560 --> 00:18:45.600
where you got the, you know,


00:18:45.600 --> 00:18:48.720
one set of utilities worked with quite a few databases.


00:18:48.720 --> 00:18:50.480
And so I spent quite a bit of time


00:18:50.480 --> 00:18:52.720
kind of making sure that that worked.


00:18:52.720 --> 00:18:54.400
And so you'll see that,


00:18:54.400 --> 00:18:56.720
including with the Alembic migrations


00:18:56.720 --> 00:18:59.040
that are coming out in 2.1 in a couple of weeks.


00:18:59.040 --> 00:19:00.320
And so through the CLI,


00:19:00.320 --> 00:19:02.720
you'll be able to actually manage your entire database,


00:19:02.720 --> 00:19:05.680
call and configurations and generate them,


00:19:05.680 --> 00:19:07.120
as well as, you know,


00:19:07.120 --> 00:19:09.520
launch and use your app through the same,


00:19:09.520 --> 00:19:10.640
you know, single CLI.


00:19:10.640 --> 00:19:12.960
I don't think I'd ever want to migrate to Oracle.


00:19:12.960 --> 00:19:15.680
Well, when you need Oracle,


00:19:15.680 --> 00:19:16.480
you do need Oracle.


00:19:16.880 --> 00:19:19.440
I'm aware of the stigma, but yeah,


00:19:19.440 --> 00:19:21.520
there's some times and places for all of them.


00:19:21.520 --> 00:19:23.600
I think for those who are unaware


00:19:23.600 --> 00:19:24.720
what you're talking about,


00:19:24.720 --> 00:19:27.440
you're talking about the SQLAlchemy


00:19:27.440 --> 00:19:29.520
repository patterns that we offer.


00:19:29.520 --> 00:19:31.440
So the things you mentioned,


00:19:31.440 --> 00:19:33.520
they are built on top of SQLAlchemy,


00:19:33.520 --> 00:19:36.080
which in itself is already really flexible


00:19:36.080 --> 00:19:38.160
and makes it easy to change databases.


00:19:38.160 --> 00:19:40.400
But there are still a few gaps


00:19:40.400 --> 00:19:41.840
that you need to bridge yourself,


00:19:41.840 --> 00:19:43.360
like the ones you've mentioned.


00:19:43.360 --> 00:19:46.080
And this is an example of the things


00:19:46.080 --> 00:19:48.640
that we try to take care of.


00:19:48.640 --> 00:19:49.600
One last note on that.


00:19:49.600 --> 00:19:51.040
So a lot of the repositories


00:19:51.040 --> 00:19:53.280
that you might see for cookie cutter apps


00:19:53.280 --> 00:19:55.920
or the other existing templates out there


00:19:55.920 --> 00:19:59.280
usually stop at the basic CRUD operations.


00:19:59.280 --> 00:20:00.240
But what we've done here


00:20:00.240 --> 00:20:01.440
is actually implemented


00:20:01.440 --> 00:20:03.200
all the basic CRUD operations


00:20:03.200 --> 00:20:05.360
and efficient bulk operations


00:20:05.360 --> 00:20:07.280
based on whatever database you're using.


00:20:07.280 --> 00:20:09.600
And we choose the most optimal method for that.


00:20:09.600 --> 00:20:11.280
So that includes bulk add,


00:20:11.280 --> 00:20:13.760
bulk update, a merge statement,


00:20:13.760 --> 00:20:14.960
bulk delete, as well as


00:20:14.960 --> 00:20:16.480
all of the standard CRUD operations.


00:20:16.480 --> 00:20:17.760
And so one of the things


00:20:17.760 --> 00:20:19.600
that we really have focused on


00:20:19.600 --> 00:20:21.280
is making sure that this is an incredibly


00:20:21.280 --> 00:20:22.560
feature-complete repository


00:20:22.560 --> 00:20:25.040
that has all of the functionality


00:20:25.040 --> 00:20:26.160
that you might want to use


00:20:26.160 --> 00:20:27.200
just right out of the box.


00:20:27.200 --> 00:20:28.000
That's really excellent


00:20:28.000 --> 00:20:29.200
that you all are handling that for people.


00:20:29.200 --> 00:20:31.040
And it gives me a sense of what you mean


00:20:31.040 --> 00:20:32.480
by the helping people


00:20:32.480 --> 00:20:33.920
do this stuff effortlessly,


00:20:33.920 --> 00:20:35.440
bringing a little bit of those batteries


00:20:35.440 --> 00:20:38.240
included feel of Django without...


00:20:38.240 --> 00:20:39.280
Putting in the batteries.


00:20:39.280 --> 00:20:41.680
Without the very prescriptive way


00:20:41.680 --> 00:20:43.280
that say Django does.


00:20:43.280 --> 00:20:45.760
I guess keeping the micro framework feel,


00:20:45.760 --> 00:20:47.440
but bringing along a lot of the stuff


00:20:47.440 --> 00:20:49.200
that people would otherwise have to choose


00:20:49.200 --> 00:20:49.840
and configure like,


00:20:49.840 --> 00:20:50.880
oh, okay, we're going to use...


00:20:50.880 --> 00:20:52.240
I guess we'll use SQLAlchemy.


00:20:52.240 --> 00:20:54.000
Oh, did you call an async function?


00:20:54.000 --> 00:20:55.280
Well, then you're going to also need


00:20:55.280 --> 00:20:57.920
the async SQLite library installed.


00:20:57.920 --> 00:20:58.720
How do I find that?


00:20:58.720 --> 00:21:01.200
Those series of steps


00:21:01.200 --> 00:21:02.400
you've kind of got to go through.


00:21:02.400 --> 00:21:03.200
And it sounds like


00:21:03.200 --> 00:21:05.280
you've taken care of some of that for people.


00:21:05.280 --> 00:21:06.240
We try to.


00:21:06.240 --> 00:21:08.800
Obviously, we'll continue to evolve it over time.


00:21:08.800 --> 00:21:11.840
But I've now used it a year at work at Google.


00:21:11.840 --> 00:21:13.680
And it's really kind of satisfied.


00:21:13.680 --> 00:21:16.480
I'd say 95% of the use cases I need.


00:21:16.480 --> 00:21:18.560
And so I typically don't have to drop back


00:21:18.560 --> 00:21:19.840
into raw SQL anymore,


00:21:19.840 --> 00:21:21.120
which I think is a huge thing.


00:21:21.120 --> 00:21:23.680
And that's what I would like to propose


00:21:23.680 --> 00:21:24.720
and get everybody else to.


00:21:24.720 --> 00:21:26.880
And so that's where the focus there.


00:21:26.880 --> 00:21:28.400
And the one thing I'll add about it


00:21:28.400 --> 00:21:30.160
is that we still kind of maintain


00:21:30.160 --> 00:21:32.160
that micro framework philosophy,


00:21:32.160 --> 00:21:34.240
because all this work is actually packaged up


00:21:34.240 --> 00:21:35.520
in something called a plugin.


00:21:35.520 --> 00:21:37.760
And so you can configure this one class


00:21:37.760 --> 00:21:39.440
and it automatically registers


00:21:39.440 --> 00:21:40.480
the route handlers,


00:21:40.480 --> 00:21:41.760
the own startup,


00:21:41.760 --> 00:21:44.400
own shutdown handlers that need to happen.


00:21:44.400 --> 00:21:47.520
It'll register the ASCII lifespan


00:21:47.520 --> 00:21:48.240
things that you need.


00:21:48.240 --> 00:21:50.160
And so basically you get this one piece


00:21:50.160 --> 00:21:52.320
where you can just set up your entire app


00:21:52.320 --> 00:21:55.440
and you don't have to do or add the piece


00:21:55.440 --> 00:21:57.360
in several parts of your application.


00:21:57.360 --> 00:21:58.240
Yeah, excellent.


00:21:58.240 --> 00:22:00.080
So before we dive into the features,


00:22:00.080 --> 00:22:01.760
which we have been doing a little bit already,


00:22:01.760 --> 00:22:03.040
at least some of the philosophy,


00:22:03.040 --> 00:22:04.400
I want to talk about benchmarks.


00:22:04.400 --> 00:22:06.240
And I know benchmarks are


00:22:06.240 --> 00:22:07.920
a little controversial in the sense that,


00:22:07.920 --> 00:22:09.760
well, the way I'm using the framework


00:22:09.760 --> 00:22:11.120
is different than the way you use it.


00:22:11.120 --> 00:22:12.400
The way you use it is really fast.


00:22:12.400 --> 00:22:13.840
The way I, you know, whatever, right?


00:22:13.840 --> 00:22:15.760
Like putting that out there


00:22:15.760 --> 00:22:17.440
and just giving a sense


00:22:17.440 --> 00:22:19.200
that this is a really fast framework.


00:22:19.200 --> 00:22:20.560
You know, how does it compare to things


00:22:20.560 --> 00:22:22.160
like FastAPI or Court,


00:22:22.160 --> 00:22:25.680
which is the async version of Flask-ish, right?


00:22:25.680 --> 00:22:27.360
They're working on unifying those more,


00:22:27.360 --> 00:22:29.920
but basically the async version of Flask for now.


00:22:29.920 --> 00:22:31.280
Siennik and then Starlet,


00:22:31.280 --> 00:22:33.200
who wants to give us a quick summary


00:22:33.200 --> 00:22:34.480
of this graph you got here


00:22:34.480 --> 00:22:35.680
in the benchmarks page?


00:22:35.680 --> 00:22:38.000
Before we get into the benchmarks,


00:22:38.000 --> 00:22:38.800
you said it already,


00:22:38.800 --> 00:22:41.200
but I want to add another disclaimer here.


00:22:41.200 --> 00:22:42.560
Like, as you said,


00:22:42.560 --> 00:22:45.760
benchmarks are really, really controversial topic


00:22:45.760 --> 00:22:47.520
and they're insanely hard to get right.


00:22:47.520 --> 00:22:50.480
And it's even harder to get actually benchmarks


00:22:50.480 --> 00:22:53.440
that are useful for your use case.


00:22:53.440 --> 00:22:57.440
And they show you what you actually want to measure


00:22:57.440 --> 00:23:00.320
because most of the time they don't.


00:23:00.320 --> 00:23:01.680
They measure something,


00:23:01.680 --> 00:23:05.840
but they often don't translate one-to-one


00:23:05.840 --> 00:23:07.840
or even somewhere close to that


00:23:07.840 --> 00:23:09.600
to real-world performance.


00:23:09.600 --> 00:23:12.880
And I have spent a lot of time on these benchmarks.


00:23:12.880 --> 00:23:15.680
And I want to say that the benchmarks


00:23:15.680 --> 00:23:18.320
didn't came about as us trying to compare


00:23:18.320 --> 00:23:19.840
to other frameworks,


00:23:19.840 --> 00:23:23.600
but we were experiencing some performance regression


00:23:23.600 --> 00:23:26.720
internally after a major change somewhere.


00:23:26.720 --> 00:23:28.320
And we were trying to track that down.


00:23:28.320 --> 00:23:29.200
And for that,


00:23:29.200 --> 00:23:32.080
I developed a quite comprehensive benchmark suit


00:23:32.080 --> 00:23:36.160
that tried to get us close to a real-world usage


00:23:36.160 --> 00:23:39.440
of how we expected the framework to be used.


00:23:39.440 --> 00:23:43.440
And then that grew to compare other frameworks as well.


00:23:43.440 --> 00:23:45.920
And when I added the other frameworks,


00:23:45.920 --> 00:23:49.520
I tried to follow a very, very simple philosophy,


00:23:49.520 --> 00:23:51.680
which is not necessarily,


00:23:51.680 --> 00:23:53.600
well, some might say it's unfair.


00:23:53.600 --> 00:23:57.760
I think it's one way to get a comparable result.


00:23:57.760 --> 00:24:01.520
What I tried to do is to not optimize anything.


00:24:01.520 --> 00:24:03.120
I just used every,


00:24:03.120 --> 00:24:05.440
I built the same app on every framework


00:24:05.440 --> 00:24:08.400
with the framework as it comes out of the box,


00:24:08.400 --> 00:24:10.960
just took the straight up approach


00:24:10.960 --> 00:24:12.880
that's shown in the documentation.


00:24:12.880 --> 00:24:15.920
And I did that because from almost all of the frameworks,


00:24:15.920 --> 00:24:17.760
there is for every case,


00:24:17.760 --> 00:24:20.800
some way to make it a little bit more performant


00:24:20.800 --> 00:24:23.360
in this special case and in that special case.


00:24:23.360 --> 00:24:26.240
And I'm not an expert in all of these frameworks.


00:24:26.240 --> 00:24:29.280
And I'm sure if you start optimizing,


00:24:29.280 --> 00:24:31.120
there's no point where you can say,


00:24:31.120 --> 00:24:33.680
okay, now it's completely optimized.


00:24:34.320 --> 00:24:36.560
So I just took the completely opposite approach


00:24:36.560 --> 00:24:38.560
and didn't optimize anything at all.


00:24:38.560 --> 00:24:39.920
And that includes Litestar.


00:24:39.920 --> 00:24:42.880
We also do things that could be made more performant


00:24:42.880 --> 00:24:45.600
in Litestar, but we don't do them in the benchmarks.


00:24:45.600 --> 00:24:49.440
Well, that's just our bench line of what we are comparing to.


00:24:49.440 --> 00:24:52.080
And I just think it's an important context to have.


00:24:52.080 --> 00:24:53.120
Yeah, that seems fair.


00:24:53.120 --> 00:24:55.040
So we know what we are comparing.


00:24:55.040 --> 00:24:55.680
Right. Okay.


00:24:55.680 --> 00:24:57.440
So if we look at the benchmarks,


00:24:57.440 --> 00:24:59.840
one thing we can see there,


00:24:59.840 --> 00:25:02.960
so we have the synchronous and asynchronous performance.


00:25:02.960 --> 00:25:05.600
And one thing that we can see there is that for Litestar,


00:25:05.600 --> 00:25:08.160
it's almost identical compared to,


00:25:08.160 --> 00:25:10.480
for example, Starlet, where it's not.


00:25:10.480 --> 00:25:15.120
The reason for that is our model of execution


00:25:15.120 --> 00:25:17.120
for synchronous operations.


00:25:17.120 --> 00:25:21.600
What Starlette does and what you could argue is the safe way


00:25:21.600 --> 00:25:24.560
is to run these in a thread pool by default,


00:25:24.560 --> 00:25:27.200
which is good because if you have a synchronous function


00:25:27.200 --> 00:25:29.760
and asynchronous framework, and it's blocking,


00:25:29.760 --> 00:25:31.760
you might potentially block your main thread


00:25:31.760 --> 00:25:34.720
and all other requests that are coming in at the same time.


00:25:34.720 --> 00:25:36.080
You don't want that.


00:25:36.080 --> 00:25:39.680
So definitely the safest option is to just put that


00:25:39.680 --> 00:25:43.120
in a thread pool, let it run, and you're good.


00:25:43.120 --> 00:25:46.880
The thing is threads are slower than asyncio.


00:25:46.880 --> 00:25:51.040
And so what we do is we force our users


00:25:51.040 --> 00:25:52.640
to make a deliberate choice


00:25:52.640 --> 00:25:54.800
when they have a synchronous function.


00:25:54.800 --> 00:25:58.000
So we say, do you want to run that synchronous function


00:25:58.000 --> 00:26:00.400
in a thread pool or not?


00:26:00.400 --> 00:26:02.400
And if not, we just don't do that.


00:26:02.400 --> 00:26:05.920
– Is that done by a parameter to the, you know,


00:26:05.920 --> 00:26:08.560
like at get or something, and then you say thread pool,


00:26:08.560 --> 00:26:09.600
yes or no, or something like that?


00:26:09.600 --> 00:26:11.040
– You can set that as a parameter.


00:26:11.040 --> 00:26:13.600
And if you don't, and you use a synchronous function,


00:26:13.600 --> 00:26:17.520
you get a very nasty warning about that.


00:26:17.520 --> 00:26:21.760
You can shut that off globally because some, yeah, that.


00:26:21.760 --> 00:26:24.640
– Sync to thread equals false. Okay, cool.


00:26:24.640 --> 00:26:26.400
– Yeah, you can shut that off globally


00:26:26.400 --> 00:26:28.800
if you don't want to be warned about it.


00:26:28.800 --> 00:26:32.160
But so we made the decision that it should be


00:26:32.160 --> 00:26:35.760
a deliberate choice if you want that behavior or not,


00:26:35.760 --> 00:26:38.320
because in many cases, you don't actually need that behavior


00:26:38.320 --> 00:26:41.280
because you're not doing any blocking IO operations


00:26:41.280 --> 00:26:44.720
or any other blocking or CPU bound operations or whatever.


00:26:44.720 --> 00:26:48.640
So the, in fact, the synchronous functions are as blocking


00:26:48.640 --> 00:26:51.120
as the other async functions.


00:26:51.120 --> 00:26:54.880
So there's no benefit to be had from running it in a thread.


00:26:54.880 --> 00:26:58.320
– Yeah, and also a lot of times in production,


00:26:58.320 --> 00:27:01.840
the production server like G-Unicorn or whatever


00:27:01.840 --> 00:27:05.920
is already using multiple threads or things to deal with that.


00:27:05.920 --> 00:27:08.720
And when, or at least multiple processes.


00:27:08.720 --> 00:27:11.600
And then when you're talking to things like a database


00:27:11.600 --> 00:27:13.120
or something, you're doing a network call,


00:27:13.120 --> 00:27:15.440
which deep down is probably releasing the gill


00:27:15.440 --> 00:27:17.040
while it's waiting anyway, right?


00:27:17.040 --> 00:27:21.040
There's a lot of subtleties that are happening down there


00:27:21.040 --> 00:27:22.320
that maybe you don't want to juggle, right?


00:27:22.320 --> 00:27:25.200
– One point to add to that is that the sync to thread option


00:27:25.200 --> 00:27:27.520
applies to the dependency injection as well.


00:27:27.520 --> 00:27:30.880
And so it's not just the routes that you can add that flag to.


00:27:30.880 --> 00:27:32.880
And so to your point about databases,


00:27:32.880 --> 00:27:36.320
all those pieces can have that same kind of behavior.


00:27:36.320 --> 00:27:38.160
– There's a benchmark for that as well,


00:27:38.160 --> 00:27:40.400
somewhere that shows the same difference


00:27:40.400 --> 00:27:42.880
for the dependency stuff, I think.


00:27:42.880 --> 00:27:46.560
Yeah, so that's one difference and another difference.


00:27:46.560 --> 00:27:49.120
And so just to add, this is one choice


00:27:49.120 --> 00:27:50.720
that Started makes for you


00:27:50.720 --> 00:27:53.840
and by extension FastAPI as well makes for you


00:27:53.840 --> 00:27:56.400
that you can't easily turn off.


00:27:56.400 --> 00:27:59.760
But if you look, for example, at the Sonic example,


00:27:59.760 --> 00:28:02.560
you see that it doesn't suffer from the same problem.


00:28:02.560 --> 00:28:06.960
So you can attribute that to this decision.


00:28:06.960 --> 00:28:10.480
The other big difference is because what we're looking at here


00:28:10.480 --> 00:28:14.720
is serializing a dictionary into a list of dictionaries


00:28:14.720 --> 00:28:15.920
into JSON.


00:28:15.920 --> 00:28:20.480
And one of the reasons why Litestar is so much faster


00:28:20.480 --> 00:28:23.200
in this than FastAPI, for example,


00:28:23.200 --> 00:28:26.080
is because we use msgspec,


00:28:26.080 --> 00:28:30.640
which is a JSON validation and parsing library.


00:28:30.640 --> 00:28:34.640
Well, not just JSON, it's also for MessagePack,


00:28:34.640 --> 00:28:37.840
which is an insane thing.


00:28:37.840 --> 00:28:41.280
It's an insanely great piece of technology,


00:28:41.280 --> 00:28:43.360
which we have been using, I think,


00:28:43.360 --> 00:28:45.040
for almost a year now.


00:28:45.040 --> 00:28:48.480
When we started to introduce it, yeah, that one.


00:28:48.480 --> 00:28:50.080
And it's super fast.


00:28:50.080 --> 00:28:51.760
It's written in C.


00:28:51.760 --> 00:28:53.600
The code can be a bit hard to get into


00:28:53.600 --> 00:28:57.360
because it's like one massive 12,000 line C file.


00:28:57.360 --> 00:29:01.920
So if you're not very familiar with C and the Python C API,


00:29:01.920 --> 00:29:03.920
it's not going to be an easy read.


00:29:03.920 --> 00:29:05.920
Yeah, but it's insanely fast.


00:29:05.920 --> 00:29:09.040
And it supports a lot of things out of the box.


00:29:09.040 --> 00:29:13.680
So for example, well, JSON, so all built in Python data types,


00:29:13.680 --> 00:29:16.800
but it also supports data classes and type dicts,


00:29:16.800 --> 00:29:18.240
which helps us a lot.


00:29:18.240 --> 00:29:22.240
And FastAPI, on the other hand, by default,


00:29:22.240 --> 00:29:26.160
well, it uses, for one, uses a standard library JSON module,


00:29:26.160 --> 00:29:30.000
which isn't as fast as any of the other external,


00:29:30.000 --> 00:29:34.880
not external, third party JSON libraries that you can have.


00:29:34.880 --> 00:29:38.560
And it also uses Pydantic to validate the data,


00:29:38.560 --> 00:29:41.040
which I have to point out is something


00:29:41.040 --> 00:29:43.120
that we do not by default.


00:29:43.120 --> 00:29:47.040
So that's the reason why there's such a big difference.


00:29:47.040 --> 00:29:50.720
And even after Pydantic 2 has been released,


00:29:50.720 --> 00:29:54.720
which has been rewritten in Rust


00:29:54.720 --> 00:29:58.160
and has had a significant gain in performance.


00:29:58.160 --> 00:30:01.920
Yes, Samuel Colvin says something like 22 times faster,


00:30:01.920 --> 00:30:03.360
which is remarkable.


00:30:03.360 --> 00:30:07.040
Yeah, but still, if you just don't do that step at all,


00:30:07.040 --> 00:30:09.600
it's obviously going to be faster.


00:30:09.600 --> 00:30:10.560
So yeah, that's true.


00:30:10.560 --> 00:30:13.600
Can you, do you remember this graph here,


00:30:13.600 --> 00:30:16.880
whether this is FastAPI based on Pydantic 1 or 2?


00:30:16.880 --> 00:30:18.000
This is Pydantic 2.


00:30:18.000 --> 00:30:18.480
Okay.


00:30:18.480 --> 00:30:23.040
You could see that it's noticeably faster now with Pydantic 2.


00:30:23.040 --> 00:30:24.880
So there has been a huge gain.


00:30:24.880 --> 00:30:30.800
And to be fair to Pydantic and FastAPI, mostly FastAPI,


00:30:30.800 --> 00:30:35.440
you could also use FastAPI's OR JSON response,


00:30:35.440 --> 00:30:37.760
which uses OR JSON to serialize that.


00:30:37.760 --> 00:30:39.680
And it would be a lot faster.


00:30:39.680 --> 00:30:41.440
But as I said earlier,


00:30:41.440 --> 00:30:45.200
that would, to me, fall into the category of optimization.


00:30:45.200 --> 00:30:47.840
You could do similar things for Litestar.


00:30:47.840 --> 00:30:51.280
And what we wanted to compare is performance out of the box.


00:30:51.280 --> 00:30:53.120
And this is what you get.


00:30:53.120 --> 00:30:56.960
Talk Python to me is partially supported by our training courses.


00:30:56.960 --> 00:31:02.080
Python's async and parallel programming support is highly underrated.


00:31:02.080 --> 00:31:05.040
Have you shied away from the amazing new async and await keywords


00:31:05.040 --> 00:31:07.200
because you've heard it's way too complicated


00:31:07.200 --> 00:31:09.120
or that it's just not worth the effort?


00:31:09.120 --> 00:31:10.720
With the right workloads,


00:31:10.720 --> 00:31:13.200
a hundred times speed up is totally possible


00:31:13.200 --> 00:31:15.120
with minor changes to your code.


00:31:15.120 --> 00:31:17.120
But you do need to understand the internals.


00:31:17.120 --> 00:31:18.320
And that's why our course,


00:31:18.320 --> 00:31:21.200
Async Techniques and Examples in Python,


00:31:21.200 --> 00:31:24.160
show you how to write async code successfully


00:31:24.160 --> 00:31:25.280
as well as how it works.


00:31:25.280 --> 00:31:27.840
Get started with async and await today


00:31:27.840 --> 00:31:31.200
with our course at talkpython.fm/async.


00:31:31.200 --> 00:31:33.920
That's some of the stuff you were talking about, right?


00:31:33.920 --> 00:31:35.760
You could include new JSON parsers.


00:31:35.760 --> 00:31:37.840
You could include UV loop, for example,


00:31:37.840 --> 00:31:39.520
and lots of optimizations, right?


00:31:39.520 --> 00:31:41.520
The benchmarks are on UV loop.


00:31:41.520 --> 00:31:44.960
I think that's one optimization we did across the board for everybody.


00:31:44.960 --> 00:31:47.840
Everyone uses a single UV corn worker.


00:31:47.840 --> 00:31:50.000
Yes. So the environment is the same


00:31:50.000 --> 00:31:52.400
for all frameworks that we test.


00:31:52.400 --> 00:31:54.800
It's UV corn with UV loop,


00:31:54.800 --> 00:31:58.160
the Cython dependencies and one worker


00:31:58.160 --> 00:32:01.360
pinned to one CPU core that's shielded.


00:32:01.360 --> 00:32:04.320
So it just sort of get like something comparable.


00:32:04.320 --> 00:32:05.360
And that's awesome, actually.


00:32:05.360 --> 00:32:06.400
That's really cool. I like it.


00:32:06.400 --> 00:32:07.920
And I guess I'd just like to point out though,


00:32:07.920 --> 00:32:10.160
that often there's other things


00:32:10.160 --> 00:32:12.320
that are in your bottleneck in your application, right?


00:32:12.320 --> 00:32:14.080
And so obviously benchmarks,


00:32:14.080 --> 00:32:15.600
take them with a grain of salt.


00:32:15.600 --> 00:32:18.560
And the other thing is that message pack,


00:32:18.560 --> 00:32:21.360
or message spec, excuse me, is awesome,


00:32:21.360 --> 00:32:24.560
but it's not as feature complete as something like pedantic,


00:32:24.560 --> 00:32:25.840
which is really great.


00:32:25.840 --> 00:32:28.160
So I think there's some differences there.


00:32:28.160 --> 00:32:29.280
And so we wanted to make sure


00:32:29.280 --> 00:32:30.880
that you have the ability to use both.


00:32:30.880 --> 00:32:32.960
But in the context of benchmarks,


00:32:32.960 --> 00:32:35.280
sometimes I guess it's worth noting


00:32:35.280 --> 00:32:36.640
that pedantic is probably doing more


00:32:36.640 --> 00:32:38.560
or can do more than msgspec.


00:32:38.560 --> 00:32:40.560
But I don't think it's necessarily always going to be


00:32:40.560 --> 00:32:42.720
what you see here at the serialization piece


00:32:42.720 --> 00:32:44.400
that's going to be your slowest part.


00:32:44.400 --> 00:32:45.840
I agree. As a database guy,


00:32:45.840 --> 00:32:48.080
you might have database indexes


00:32:48.080 --> 00:32:50.320
and the lack thereof coming to mind or something, right?


00:32:50.320 --> 00:32:51.760
Well, that's one of the things, right?


00:32:51.760 --> 00:32:53.680
You know, it's, and you kind of touched on it.


00:32:53.680 --> 00:32:56.080
It's the network latency and those kinds of things


00:32:56.080 --> 00:32:58.640
between that's really going to consume


00:32:58.640 --> 00:32:59.360
quite a bit of the time.


00:32:59.360 --> 00:32:59.600
Yeah.


00:32:59.600 --> 00:33:01.520
And I think we do have a benchmark,


00:33:01.520 --> 00:33:05.600
which is serialization of complex objects,


00:33:05.600 --> 00:33:08.640
like Pydantic models or data classes


00:33:08.640 --> 00:33:09.840
of something like that,


00:33:09.840 --> 00:33:12.400
which actually I think is very interesting


00:33:12.400 --> 00:33:14.880
because it shows that if you're using pedantic


00:33:14.880 --> 00:33:18.160
with Litestar, it's actually not faster than FastAPI,


00:33:18.160 --> 00:33:20.000
because then what you're measuring


00:33:20.000 --> 00:33:21.360
is the speed of pedantic,


00:33:21.360 --> 00:33:23.920
which in both cases is the same.


00:33:23.920 --> 00:33:26.000
And you can, it sounds like, which is interesting.


00:33:26.000 --> 00:33:29.680
Okay. So quick takeaway, Litestar is quite fast.


00:33:29.680 --> 00:33:31.840
One of the reasons you might choose it is the speed.


00:33:31.840 --> 00:33:34.160
And it sounds like there's a lot of good options there.


00:33:34.160 --> 00:33:34.560
All right.


00:33:34.560 --> 00:33:35.600
But not the only one.


00:33:35.600 --> 00:33:36.720
I want to point out, on that note,


00:33:36.720 --> 00:33:38.720
if you allow me to point out one more thing.


00:33:38.720 --> 00:33:39.280
Of course.


00:33:39.280 --> 00:33:40.560
We are quite fast.


00:33:40.560 --> 00:33:43.760
And I think for the feature set that we have,


00:33:43.760 --> 00:33:46.160
we are probably among the fastest,


00:33:46.160 --> 00:33:50.720
but we are not by far the fastest ASGI framework out there.


00:33:50.720 --> 00:33:53.120
That would be, to my knowledge, Black Sheep,


00:33:53.120 --> 00:33:55.360
which is insanely fast.


00:33:55.360 --> 00:33:57.920
And we actually don't include that in the benchmarks


00:33:57.920 --> 00:34:00.880
because it makes the benchmarks absolutely useless


00:34:00.880 --> 00:34:03.520
because then you just have one gigantic bar,


00:34:03.520 --> 00:34:04.720
that's Black Sheep.


00:34:04.720 --> 00:34:07.520
And then you have two very, very teeny, tiny bars,


00:34:07.520 --> 00:34:08.640
which is everything else,


00:34:08.640 --> 00:34:12.880
which is another micro framework that's written in Cython.


00:34:12.880 --> 00:34:14.320
I have not heard of Black Sheep.


00:34:14.320 --> 00:34:15.760
That's something I have to look into.


00:34:15.760 --> 00:34:16.640
Okay, cool.


00:34:16.640 --> 00:34:19.040
But obviously, speed is interesting.


00:34:19.040 --> 00:34:20.320
Speed is important.


00:34:20.320 --> 00:34:22.800
It's certainly something that if it was really poor,


00:34:22.800 --> 00:34:24.480
people might choose like, well, it's interesting,


00:34:24.480 --> 00:34:25.680
but it's not that fast.


00:34:25.680 --> 00:34:28.640
But given the speed, it's certainly an advantage,


00:34:28.640 --> 00:34:30.240
not a drawback.


00:34:30.240 --> 00:34:33.040
But I think a lot of the advantages come from


00:34:33.040 --> 00:34:34.080
a bunch of the features.


00:34:34.080 --> 00:34:35.520
So maybe we could talk through some of these


00:34:35.520 --> 00:34:37.520
and whoever wants to just jump in on them


00:34:37.520 --> 00:34:39.360
as we go, feel free to.


00:34:39.360 --> 00:34:41.200
So I think it probably came through already


00:34:41.200 --> 00:34:42.400
from the conversation,


00:34:42.400 --> 00:34:45.440
but the programming API is very micro framework,


00:34:45.440 --> 00:34:47.760
Flask, FastAPI like, right?


00:34:47.760 --> 00:34:50.160
You create a function, you do an at get,


00:34:50.160 --> 00:34:52.800
give it a URL, decorator on the front,


00:34:52.800 --> 00:34:55.600
and you've got an endpoint on the web


00:34:55.600 --> 00:34:57.200
that you can do things with.


00:34:57.200 --> 00:34:58.640
So that's pretty straightforward.


00:34:58.640 --> 00:34:59.840
At its core, exactly.


00:34:59.840 --> 00:35:01.120
And we take it one step further.


00:35:01.120 --> 00:35:04.400
So all of the patterns you know and love from Django.


00:35:04.400 --> 00:35:06.000
So some of the things that you see


00:35:06.000 --> 00:35:07.600
from Django REST framework.


00:35:07.600 --> 00:35:09.520
So we have controllers that are very similar to that,


00:35:09.520 --> 00:35:10.960
where you can define a class


00:35:10.960 --> 00:35:12.720
and have multiple methods in it.


00:35:12.720 --> 00:35:14.640
And so, you know, that's really kind of where


00:35:14.640 --> 00:35:15.920
things start to differentiate.


00:35:15.920 --> 00:35:17.760
But at its core, we definitely wanted to make sure


00:35:17.760 --> 00:35:20.400
you had that exact micro framework experience


00:35:20.400 --> 00:35:21.280
that you see everywhere.


00:35:21.280 --> 00:35:22.400
So the first one,


00:35:22.400 --> 00:35:24.560
let's just touch on some of the main features here.


00:35:24.560 --> 00:35:27.440
The first one is data validation and parsing.


00:35:27.440 --> 00:35:29.120
So leveraging the power of type ints,


00:35:29.120 --> 00:35:30.960
which is very, very nice.


00:35:30.960 --> 00:35:32.720
Who wants to highlight that feature?


00:35:32.720 --> 00:35:33.520
Take your own mute.


00:35:33.520 --> 00:35:35.040
Good that you pointed that out.


00:35:35.040 --> 00:35:37.200
So that's definitely one of the areas


00:35:37.200 --> 00:35:40.800
that was directly inspired by a FastAPI.


00:35:40.800 --> 00:35:43.520
Because FastAPI, a few years ago,


00:35:43.520 --> 00:35:47.120
came up with this brilliant idea of the combination


00:35:47.120 --> 00:35:48.880
of just leveraging the type hints


00:35:48.880 --> 00:35:52.480
and the emerging Pydantic stuff and whatever,


00:35:52.480 --> 00:35:54.560
and build your APIs on that,


00:35:54.560 --> 00:35:57.520
based around that as your core.


00:35:57.520 --> 00:36:01.200
And it's been very increasingly popular


00:36:01.200 --> 00:36:03.360
to build your APIs like that.


00:36:03.360 --> 00:36:05.760
So it's definitely directly inspired


00:36:05.760 --> 00:36:07.200
and influenced by this.


00:36:07.200 --> 00:36:09.600
We are approaching things a bit differently though.


00:36:09.600 --> 00:36:12.880
So for example, you are not tied to Pydantic.


00:36:12.880 --> 00:36:16.320
You can use any data modeling, not any,


00:36:16.320 --> 00:36:18.560
but a lot of data modeling libraries


00:36:18.560 --> 00:36:19.920
that you might want to choose


00:36:19.920 --> 00:36:21.360
are supported out of the box.


00:36:21.360 --> 00:36:23.520
Pydantic is supported.


00:36:23.520 --> 00:36:25.680
You can also use the method spec,


00:36:25.680 --> 00:36:29.600
which supports some data modeling like Pydantic,


00:36:29.600 --> 00:36:32.800
not as featureful, but very, very fast.


00:36:32.800 --> 00:36:34.480
You can use adders,


00:36:34.480 --> 00:36:37.680
you can use plain data class or type dicts


00:36:37.680 --> 00:36:42.080
to validate your data and to transform your data,


00:36:42.080 --> 00:36:44.320
which is what you are currently looking at,


00:36:44.320 --> 00:36:47.440
which are our DTOs,


00:36:47.440 --> 00:36:51.920
which have been written by the brilliant Peter Schutt,


00:36:51.920 --> 00:36:53.520
who isn't here with us today,


00:36:53.520 --> 00:36:56.240
which are, well, data transfer objects.


00:36:56.240 --> 00:36:59.360
So they are a way for you to define


00:36:59.360 --> 00:37:02.320
how your data should be transformed on the way in


00:37:02.320 --> 00:37:03.520
or on the way out.


00:37:03.520 --> 00:37:06.640
So you have incoming data that's unstructured,


00:37:06.640 --> 00:37:09.680
JSON data, and you have a target model,


00:37:09.680 --> 00:37:13.200
and you might want to apply certain transformations to that,


00:37:13.200 --> 00:37:16.320
say rename fields from snake case to camel case,


00:37:16.320 --> 00:37:18.560
very common thing to do


00:37:18.560 --> 00:37:21.040
while you are validating it on the fly


00:37:21.040 --> 00:37:24.400
that it confirms to a certain schema,


00:37:24.400 --> 00:37:27.840
for example, a Pydantic model or a data class.


00:37:27.840 --> 00:37:31.280
And so DTOs are basically an abstraction layer


00:37:31.280 --> 00:37:33.520
between that where you can say,


00:37:33.520 --> 00:37:35.520
okay, this is my source model,


00:37:35.520 --> 00:37:37.280
this is my Pydantic model,


00:37:37.280 --> 00:37:40.000
and it has a user ID that's an integer


00:37:40.000 --> 00:37:41.680
and it has a name that's a string.


00:37:41.680 --> 00:37:43.600
And by default, Litestar,


00:37:43.600 --> 00:37:44.960
if you give it that,


00:37:44.960 --> 00:37:47.360
will validate that the incoming data


00:37:47.360 --> 00:37:48.640
confirms to that schema,


00:37:48.640 --> 00:37:52.320
will have Pydantic run all the validation


00:37:52.320 --> 00:37:55.280
and parsing on it like you would normally,


00:37:55.280 --> 00:37:58.000
which is quite similar to how FastAPI does it,


00:37:58.000 --> 00:37:59.760
or how you might also want,


00:37:59.760 --> 00:38:01.760
would do it by hand.


00:38:01.760 --> 00:38:05.120
The DTOs come in where you have one data model


00:38:05.120 --> 00:38:07.680
that has different representations.


00:38:07.680 --> 00:38:10.000
So for example, you might have a database model


00:38:10.000 --> 00:38:11.760
that's a SQLAlchemy model,


00:38:11.760 --> 00:38:13.200
but on the way out,


00:38:13.200 --> 00:38:16.080
you don't want to include the password field


00:38:16.080 --> 00:38:17.920
because of reasons.


00:38:17.920 --> 00:38:20.720
But you want it on the way in


00:38:20.720 --> 00:38:23.280
when you create the user to sign up.


00:38:23.280 --> 00:38:25.680
So one way to do that manually would be


00:38:26.240 --> 00:38:28.960
if you're using Pydantic to create two models,


00:38:28.960 --> 00:38:30.160
one for the way in,


00:38:30.160 --> 00:38:31.360
one for the way out,


00:38:31.360 --> 00:38:32.880
or to create one base model


00:38:32.880 --> 00:38:34.800
with all the properties that are the same


00:38:34.800 --> 00:38:37.680
and then two additional models, whatever.


00:38:37.680 --> 00:38:40.240
DTOs basically do that,


00:38:40.240 --> 00:38:41.680
but they do it for you.


00:38:41.680 --> 00:38:44.080
So you don't have to actually write out


00:38:44.080 --> 00:38:45.040
those two models.


00:38:45.040 --> 00:38:47.600
They can take in one of the models,


00:38:47.600 --> 00:38:49.120
one of the supported model types.


00:38:49.120 --> 00:38:50.560
I think at the moment,


00:38:50.560 --> 00:38:53.120
we support Pydantic, SQLAlchemy,


00:38:53.120 --> 00:38:56.880
msgspec, Adders, and DataClasses.


00:38:56.880 --> 00:38:57.760
Correct me if I'm wrong.


00:38:57.760 --> 00:38:58.960
No, I think you got all of them.


00:38:58.960 --> 00:39:01.440
So if you have a class of that type,


00:39:01.440 --> 00:39:03.520
you can create DTO from it.


00:39:03.520 --> 00:39:06.160
And then you have a DTO config


00:39:06.160 --> 00:39:07.120
where you can say,


00:39:07.120 --> 00:39:08.640
exclude these fields


00:39:08.640 --> 00:39:10.160
or only include these fields


00:39:10.160 --> 00:39:12.000
and rename these fields.


00:39:12.000 --> 00:39:13.120
And all you have to do


00:39:13.120 --> 00:39:16.800
is create a type annotation with that DTO.


00:39:16.800 --> 00:39:18.560
And Litestar will take it,


00:39:18.560 --> 00:39:19.920
use it to transform your data,


00:39:19.920 --> 00:39:21.360
and then give you back


00:39:21.360 --> 00:39:23.040
your original model


00:39:23.040 --> 00:39:25.600
in the form you specified.


00:39:25.600 --> 00:39:26.240
I see.


00:39:26.240 --> 00:39:27.600
And you say in the decorator,


00:39:27.600 --> 00:39:29.520
you set the DTO model


00:39:29.520 --> 00:39:31.920
that does that conversion for you.


00:39:31.920 --> 00:39:32.240
Got it.


00:39:32.240 --> 00:39:33.040
Yeah, that's a good point.


00:39:33.040 --> 00:39:34.400
You set it in the decorator


00:39:34.400 --> 00:39:35.280
and not at the point


00:39:35.280 --> 00:39:37.360
where you receive or return the data.


00:39:37.360 --> 00:39:39.760
So the data you receive and return


00:39:39.760 --> 00:39:42.160
will always be the actual model


00:39:42.160 --> 00:39:43.360
that you're dealing with,


00:39:43.360 --> 00:39:45.120
which has the great benefit


00:39:45.120 --> 00:39:46.720
that your type annotations


00:39:46.720 --> 00:39:48.160
are always correct.


00:39:48.160 --> 00:39:50.000
And you don't have to worry about that,


00:39:50.000 --> 00:39:51.520
about, you know, casting something


00:39:51.520 --> 00:39:52.400
to something else


00:39:52.400 --> 00:39:53.920
or doing the serialization


00:39:53.920 --> 00:39:55.600
in your route handler directly,


00:39:55.600 --> 00:39:57.360
because otherwise the type annotations


00:39:57.360 --> 00:39:58.640
for the return type won't match


00:39:58.640 --> 00:40:00.480
because you have excluded the field


00:40:00.480 --> 00:40:01.280
or whatever.


00:40:01.280 --> 00:40:02.240
So you just set it


00:40:02.240 --> 00:40:05.120
completely separately from that,


00:40:05.120 --> 00:40:07.120
just as information for Litestar


00:40:07.120 --> 00:40:08.720
to say, okay, use this


00:40:08.720 --> 00:40:10.720
to do the transformations.


00:40:10.720 --> 00:40:14.080
But the end result is my original model,


00:40:14.080 --> 00:40:15.840
whatever you want it to be.


00:40:15.840 --> 00:40:16.880
Okay, so this is kind of


00:40:16.880 --> 00:40:19.680
the model equivalent of FastAPI.


00:40:20.400 --> 00:40:22.240
The DTO, that's really neat.


00:40:22.240 --> 00:40:23.280
There's a lot of,


00:40:23.280 --> 00:40:24.320
maybe a little bit of overlap


00:40:24.320 --> 00:40:25.760
in something like SQL model, right?


00:40:25.760 --> 00:40:26.640
Where you can declare


00:40:26.640 --> 00:40:28.640
your SQLAlchemy model


00:40:28.640 --> 00:40:29.840
as a Pydantic model.


00:40:29.840 --> 00:40:30.560
And in this case,


00:40:30.560 --> 00:40:33.280
and you're welcome to use SQL model


00:40:33.280 --> 00:40:34.080
with Litestar,


00:40:34.080 --> 00:40:34.800
but in this case,


00:40:34.800 --> 00:40:35.760
you can now just use


00:40:35.760 --> 00:40:37.200
the normal SQLAlchemy model


00:40:37.200 --> 00:40:38.640
and declare a DTO


00:40:38.640 --> 00:40:40.320
and it'll automatically convert that


00:40:40.320 --> 00:40:42.560
to, you know, a msgspec struct


00:40:42.560 --> 00:40:43.280
on the way out


00:40:43.280 --> 00:40:45.280
and serialize it that way.


00:40:45.280 --> 00:40:45.760
Very cool.


00:40:45.760 --> 00:40:46.480
That's a good point.


00:40:46.480 --> 00:40:48.320
You bring up the msgspec struct.


00:40:48.320 --> 00:40:50.240
So that's one other area


00:40:50.240 --> 00:40:52.560
where we use message spec


00:40:52.560 --> 00:40:54.480
for to create these models


00:40:54.480 --> 00:40:57.120
because msgspec is extremely fast


00:40:57.120 --> 00:40:58.720
and has this struct type,


00:40:58.720 --> 00:41:01.360
which is sort of like an Adders class


00:41:01.360 --> 00:41:02.720
or a Pydantic model,


00:41:02.720 --> 00:41:04.080
but it has the benefit of being,


00:41:04.080 --> 00:41:06.240
as far as I know,


00:41:06.240 --> 00:41:08.560
the fastest library


00:41:08.560 --> 00:41:10.160
for that type of stuff


00:41:10.160 --> 00:41:12.560
for Python that exists at the moment.


00:41:12.560 --> 00:41:14.720
So what we are building there,


00:41:14.720 --> 00:41:15.920
the transformation layer


00:41:16.160 --> 00:41:18.480
is as performant as it can be.


00:41:18.480 --> 00:41:19.040
Excellent.


00:41:19.040 --> 00:41:20.000
In fact, I think,


00:41:20.000 --> 00:41:21.120
and I had to go look up


00:41:21.120 --> 00:41:22.000
the actual quote,


00:41:22.000 --> 00:41:23.520
but I think the struct


00:41:23.520 --> 00:41:24.560
is actually faster


00:41:24.560 --> 00:41:25.920
than the data class


00:41:25.920 --> 00:41:27.040
in a lot of scenarios.


00:41:27.040 --> 00:41:28.160
And so they've done


00:41:28.160 --> 00:41:29.440
an incredible job with that library.


00:41:29.440 --> 00:41:30.720
That is incredible, actually.


00:41:30.720 --> 00:41:32.640
And you're beating the building stuff, right?


00:41:32.640 --> 00:41:33.440
That's cool.


00:41:33.440 --> 00:41:33.760
All right.


00:41:33.760 --> 00:41:34.560
We talked a little bit


00:41:34.560 --> 00:41:36.800
about the open ecosystem, right?


00:41:36.800 --> 00:41:37.920
The ability to use pedantic


00:41:37.920 --> 00:41:40.560
versus other custom DTOs,


00:41:40.560 --> 00:41:42.000
other libraries,


00:41:42.000 --> 00:41:44.400
open API, swagger,


00:41:44.400 --> 00:41:45.520
the whole generate


00:41:45.520 --> 00:41:47.200
your documentation for you.


00:41:47.200 --> 00:41:48.160
That sounds pretty excellent.


00:41:48.160 --> 00:41:49.120
I'm guessing it's based


00:41:49.120 --> 00:41:50.720
a little bit on the DTOs as well


00:41:50.720 --> 00:41:52.560
to describe the schema.


00:41:52.560 --> 00:41:53.840
Every class has the ability


00:41:53.840 --> 00:41:56.720
to export what that output looks like.


00:41:56.720 --> 00:41:58.160
And so the DTO knows


00:41:58.160 --> 00:41:59.840
how to output its signature


00:41:59.840 --> 00:42:01.280
so that it can generate


00:42:01.280 --> 00:42:03.200
the correct open API schema.


00:42:03.200 --> 00:42:04.160
And I guess really


00:42:04.160 --> 00:42:05.120
the main thing to point out,


00:42:05.120 --> 00:42:06.800
and we obviously do


00:42:06.800 --> 00:42:08.320
the typical swagger schemas,


00:42:08.320 --> 00:42:09.920
but one other thing that we add in


00:42:09.920 --> 00:42:13.200
is redot and stoplight elements as well.


00:42:13.200 --> 00:42:14.960
And so you've got a couple of options


00:42:14.960 --> 00:42:17.040
for your documentation host.


00:42:17.040 --> 00:42:18.400
Middleware.


00:42:18.400 --> 00:42:19.680
So middleware is things


00:42:19.680 --> 00:42:21.360
that can see the request


00:42:21.360 --> 00:42:23.520
before your view function runs


00:42:23.520 --> 00:42:25.440
or make changes after it runs


00:42:25.440 --> 00:42:29.360
for cores or logging or other things.


00:42:29.360 --> 00:42:30.160
Want to talk about that?


00:42:30.160 --> 00:42:31.760
Cody, do you want to talk about


00:42:31.760 --> 00:42:34.000
another ChromePreston stuff, for example?


00:42:34.000 --> 00:42:34.800
I'll happily do that.


00:42:34.800 --> 00:42:36.240
So, you know, you kind of nailed


00:42:36.240 --> 00:42:38.240
what the core of the middleware is,


00:42:38.240 --> 00:42:40.160
but really it's all those pieces


00:42:40.160 --> 00:42:41.600
that you need to add in


00:42:41.600 --> 00:42:43.440
to maybe add in security


00:42:43.440 --> 00:42:44.800
or add in some type of


00:42:44.800 --> 00:42:45.920
additional functionality,


00:42:45.920 --> 00:42:47.120
compression, for instance.


00:42:47.120 --> 00:42:48.720
And so a lot of, you know,


00:42:48.720 --> 00:42:50.080
outside of the plugin system,


00:42:50.080 --> 00:42:51.280
a lot of that functionality


00:42:51.280 --> 00:42:53.200
is included in the middleware.


00:42:53.200 --> 00:42:55.520
And so you'll see built in stuff


00:42:55.520 --> 00:42:57.120
for most of the things


00:42:57.120 --> 00:42:58.080
that you're going to want to do


00:42:58.080 --> 00:42:59.520
out of a normal application.


00:42:59.520 --> 00:43:00.560
There's probably a few things


00:43:00.560 --> 00:43:02.880
that you may need to roll on your own,


00:43:02.880 --> 00:43:04.800
but we've got all the core things.


00:43:04.800 --> 00:43:06.080
And so you've got compression,


00:43:06.080 --> 00:43:07.920
both broadly and GZIP.


00:43:07.920 --> 00:43:09.920
You've got open telemetry


00:43:09.920 --> 00:43:11.520
and Prometheus integration.


00:43:11.520 --> 00:43:13.680
You've got several different types


00:43:13.680 --> 00:43:14.960
of authentication backends


00:43:14.960 --> 00:43:16.640
that would get integrated here,


00:43:16.640 --> 00:43:19.040
including a session-based backend


00:43:19.040 --> 00:43:21.360
that one, there's a cookie-based backend


00:43:21.360 --> 00:43:22.320
and a session-based backend


00:43:22.320 --> 00:43:23.600
where it stores, you know,


00:43:23.600 --> 00:43:25.680
on the actual server itself.


00:43:25.680 --> 00:43:27.920
And we also have a JWT auth


00:43:27.920 --> 00:43:29.360
configuration that you can use here.


00:43:29.360 --> 00:43:31.440
And so I encourage all the listeners


00:43:31.440 --> 00:43:32.720
to just check out what we have


00:43:32.720 --> 00:43:34.160
as part of the default middleware.


00:43:34.160 --> 00:43:35.600
But, you know, most of the things


00:43:35.600 --> 00:43:37.360
that they're going to want to do


00:43:37.360 --> 00:43:38.960
from a web app


00:43:38.960 --> 00:43:39.920
are going to be built right in.


00:43:39.920 --> 00:43:41.440
We also have the logging,


00:43:41.440 --> 00:43:44.240
the cores, all the basic stuff.


00:43:44.240 --> 00:43:45.680
See it like cross-site,


00:43:45.680 --> 00:43:47.520
reference, rate limiting.


00:43:47.520 --> 00:43:48.480
Cross-site, yeah,


00:43:48.480 --> 00:43:50.320
requests forgery for forms.


00:43:50.320 --> 00:43:50.880
Yeah.


00:43:50.880 --> 00:43:51.840
And then you can add your own


00:43:51.840 --> 00:43:53.840
and they're all just little ASCII apps


00:43:53.840 --> 00:43:55.760
that you can plug in as you need them.


00:43:55.760 --> 00:43:57.440
On before and on after requests,


00:43:57.440 --> 00:43:58.400
something like that, right?


00:43:58.400 --> 00:43:59.200
This is really cool here


00:43:59.200 --> 00:44:00.000
where you could say


00:44:00.000 --> 00:44:02.480
in a particular view decorator,


00:44:02.480 --> 00:44:03.920
you can say, for example,


00:44:03.920 --> 00:44:06.160
exclude from CSRF


00:44:06.160 --> 00:44:08.560
for just this form, for example.


00:44:08.560 --> 00:44:09.440
And actually, this is something


00:44:09.440 --> 00:44:10.960
that you'll see as a feature.


00:44:10.960 --> 00:44:12.000
You're going to see this


00:44:12.000 --> 00:44:13.600
all throughout the code


00:44:13.600 --> 00:44:15.280
and it's layered permissions.


00:44:15.280 --> 00:44:17.120
And so this exclude from CRS,


00:44:17.120 --> 00:44:20.240
CRSRF and several other things.


00:44:20.240 --> 00:44:21.120
You may see that.


00:44:21.120 --> 00:44:22.320
It is a mouthful.


00:44:22.320 --> 00:44:23.200
You're going to see that


00:44:23.200 --> 00:44:24.640
in several different places, right?


00:44:24.640 --> 00:44:26.880
And so you can apply that at the controller


00:44:26.880 --> 00:44:28.320
or you can apply that at the


00:44:28.320 --> 00:44:30.560
route level that you see here.


00:44:30.560 --> 00:44:32.960
And so that's one of the


00:44:32.960 --> 00:44:34.400
helpful features that you'll see


00:44:34.400 --> 00:44:36.000
where you can put it in one spot.


00:44:36.000 --> 00:44:37.040
It'll cascade down.


00:44:37.040 --> 00:44:38.400
Yeah, I saw that for the DTOs.


00:44:38.400 --> 00:44:39.600
Yeah, we have a lot of that


00:44:39.600 --> 00:44:41.440
like layered dependency stuff,


00:44:41.440 --> 00:44:42.720
like the dependency,


00:44:42.720 --> 00:44:44.080
but dependency injection,


00:44:44.080 --> 00:44:45.840
like you could also do at the app level


00:44:45.840 --> 00:44:48.080
or just at the controller level.


00:44:48.080 --> 00:44:50.080
There's so much other applications,


00:44:50.080 --> 00:44:51.680
controllers, routers


00:44:51.680 --> 00:44:53.200
and the route handles.


00:44:53.200 --> 00:44:55.440
These are our basic layers.


00:44:55.440 --> 00:44:57.440
And most of these types


00:44:57.440 --> 00:44:58.880
of configurations,


00:44:58.880 --> 00:45:01.040
so middleware's dependencies,


00:45:01.040 --> 00:45:02.800
header configurations,


00:45:02.800 --> 00:45:04.080
middleware configurations,


00:45:04.080 --> 00:45:04.880
they're all layered.


00:45:04.880 --> 00:45:06.160
So you can apply them


00:45:06.160 --> 00:45:07.680
on every layer you want


00:45:07.680 --> 00:45:08.800
and they will affect


00:45:08.800 --> 00:45:10.320
the layers below that.


00:45:10.320 --> 00:45:12.480
So it's quite flexible


00:45:12.480 --> 00:45:13.360
how you want to


00:45:13.360 --> 00:45:16.080
or where you want to configure your stuff.


00:45:16.080 --> 00:45:17.600
Well, the ORM integration,


00:45:17.600 --> 00:45:18.320
we talked a little bit


00:45:18.320 --> 00:45:20.080
about SQLAlchemy as well.


00:45:20.080 --> 00:45:21.600
So that's pretty cool.


00:45:21.600 --> 00:45:23.840
And I'll be happy to elaborate on that.


00:45:23.840 --> 00:45:24.560
But, you know,


00:45:24.560 --> 00:45:25.680
we've covered quite a bit


00:45:25.680 --> 00:45:26.960
of what you'll see here.


00:45:26.960 --> 00:45:27.760
I think the only thing


00:45:27.760 --> 00:45:28.640
that I haven't mentioned


00:45:28.640 --> 00:45:30.160
that we've integrated in


00:45:30.160 --> 00:45:32.880
and that will be coming in 2.1


00:45:32.880 --> 00:45:35.120
is the use of lambda statement.


00:45:35.120 --> 00:45:36.800
And I'm not sure if you're even


00:45:36.800 --> 00:45:38.480
have seen that or if your listeners have,


00:45:38.480 --> 00:45:41.120
but it's a relatively new function


00:45:41.120 --> 00:45:42.400
that's in SQLAlchemy


00:45:42.400 --> 00:45:44.000
to help with statement caching.


00:45:44.000 --> 00:45:45.360
And so the repository


00:45:45.360 --> 00:45:46.800
has been converted over that.


00:45:46.800 --> 00:45:48.240
Actually, I see some great things


00:45:48.240 --> 00:45:48.720
in the chat.


00:45:48.720 --> 00:45:50.560
There's HTMX integration.


00:45:50.560 --> 00:45:51.360
Obviously, we want to make sure


00:45:51.360 --> 00:45:52.000
we touch on that.


00:45:52.000 --> 00:45:54.400
And I really want to let somebody


00:45:54.400 --> 00:45:56.560
talk about the WebSockets


00:45:56.560 --> 00:45:58.320
and the channels integration too.


00:45:58.320 --> 00:45:59.760
So there's some really cool stuff


00:45:59.760 --> 00:46:01.440
I'd love for your listeners to hear.


00:46:01.440 --> 00:46:03.120
Before we move on to the WebSockets,


00:46:03.120 --> 00:46:04.480
which I also want to talk about,


00:46:04.480 --> 00:46:05.680
I do want to give,


00:46:05.680 --> 00:46:08.720
since we're on the ORM integration,


00:46:08.720 --> 00:46:10.320
I can see some comments out there


00:46:10.320 --> 00:46:13.600
from, for example, Roman behind Beanie,


00:46:13.600 --> 00:46:16.560
which is a MongoDB ORM or ODM.


00:46:16.560 --> 00:46:18.320
Says, I like the DTO concept.


00:46:18.320 --> 00:46:20.240
Having such tools separately would be great.


00:46:20.240 --> 00:46:21.840
I mean, things such as SQLAlchemy,


00:46:21.840 --> 00:46:23.360
excuse me, SQLAlchemy objects


00:46:23.360 --> 00:46:24.800
when needed, pandas, data frames,


00:46:24.800 --> 00:46:26.400
by data model, depending on the context


00:46:26.400 --> 00:46:27.280
is really cool.


00:46:27.280 --> 00:46:29.760
We actually have talked about that.


00:46:29.760 --> 00:46:32.000
Well, not we, the people present here,


00:46:32.000 --> 00:46:35.680
but Peter Schutt, the person who created


00:46:35.680 --> 00:46:37.360
the DTO implementation at me,


00:46:37.360 --> 00:46:38.800
we have actually talked about that,


00:46:38.800 --> 00:46:41.840
making the DTOs a separate library


00:46:41.840 --> 00:46:44.880
because it's a very useful concept.


00:46:44.880 --> 00:46:48.400
So it's not something we have planned.


00:46:48.400 --> 00:46:50.320
It's something that has crossed our minds as well.


00:46:50.320 --> 00:46:51.520
– That's very cool.


00:46:51.520 --> 00:46:53.040
The question was,


00:46:53.040 --> 00:46:55.120
what about the MongoDB people


00:46:55.120 --> 00:46:57.600
or the other NoSQL folks


00:46:57.600 --> 00:46:59.280
for whom SQLAlchemy


00:46:59.280 --> 00:47:01.120
doesn't necessarily want to talk to


00:47:01.120 --> 00:47:02.400
because it's relational?


00:47:02.400 --> 00:47:03.360
What's the story there?


00:47:03.360 --> 00:47:05.440
Like, is it still pretty easy to use Litestar?


00:47:05.440 --> 00:47:05.920
– It is.


00:47:05.920 --> 00:47:06.880
And I think that there's actually


00:47:06.880 --> 00:47:07.840
a native integration


00:47:07.840 --> 00:47:09.920
that's maybe not totally finished,


00:47:09.920 --> 00:47:11.200
but there is an open PR


00:47:11.200 --> 00:47:13.760
for a Mongo-based repository.


00:47:13.760 --> 00:47:16.640
So there's going to be that much tighter coupling


00:47:16.640 --> 00:47:18.960
coming soon for those that want to use it.


00:47:18.960 --> 00:47:20.000
But if they,


00:47:20.000 --> 00:47:22.320
there's nothing that would limit compatibility now.


00:47:22.320 --> 00:47:23.680
So if they want to go ahead and configure that


00:47:23.680 --> 00:47:24.560
with their application,


00:47:24.560 --> 00:47:26.000
there, you're certainly free to do so.


00:47:26.000 --> 00:47:27.840
But there will be a first party


00:47:27.840 --> 00:47:29.200
kind of clean integration


00:47:29.200 --> 00:47:30.640
for those things coming soon.


00:47:30.640 --> 00:47:31.680
– Oh, that's excellent.


00:47:31.680 --> 00:47:32.800
So for right now,


00:47:32.800 --> 00:47:35.120
you know, B&E is based on Pydantic.


00:47:35.120 --> 00:47:36.320
You all work with Pydantic.


00:47:36.320 --> 00:47:37.120
It sounds like,


00:47:37.120 --> 00:47:39.440
can I just use that as the go-between maybe?


00:47:39.440 --> 00:47:40.160
– Absolutely.


00:47:40.160 --> 00:47:42.640
And you're free to use Pydantic with Litestar


00:47:42.640 --> 00:47:45.120
just as you can with FastAPI,


00:47:45.120 --> 00:47:45.760
and it'll just work.


00:47:45.760 --> 00:47:49.200
And so there's no reason to change everything


00:47:49.200 --> 00:47:50.720
to msgspec if you want to.


00:47:50.720 --> 00:47:51.600
You can mix and match


00:47:51.600 --> 00:47:53.120
and leave everything in Pydantic


00:47:53.120 --> 00:47:54.240
if that's what you prefer as well.


00:47:54.240 --> 00:47:55.040
– That's a good point.


00:47:55.040 --> 00:47:56.400
So the thing we do,


00:47:56.400 --> 00:47:58.400
all these integrations with Pydantic


00:47:58.400 --> 00:47:59.760
and others and whatever,


00:47:59.760 --> 00:48:02.080
so they are not baked in


00:48:02.080 --> 00:48:05.280
somewhere deep into the application.


00:48:05.280 --> 00:48:06.640
They are all plugins,


00:48:06.640 --> 00:48:08.640
plugins that you could write yourself


00:48:08.640 --> 00:48:09.680
if you wanted to


00:48:09.680 --> 00:48:13.440
and write for every library that you desire.


00:48:13.440 --> 00:48:15.840
That's one of the larger things


00:48:15.840 --> 00:48:18.320
that we tackled with the 2.0 release,


00:48:18.320 --> 00:48:20.720
where we tried to decouple us from Pydantic


00:48:20.720 --> 00:48:24.080
because we were based on Pydantic before


00:48:24.080 --> 00:48:25.840
and we wanted to be more open.


00:48:25.840 --> 00:48:29.440
So we basically ripped out everything Pydantic


00:48:29.440 --> 00:48:30.960
in Litestar's core


00:48:30.960 --> 00:48:32.240
and put it into a plugin


00:48:32.240 --> 00:48:34.160
and at the same time made sure


00:48:34.160 --> 00:48:37.120
that the plugin API was so versatile


00:48:37.120 --> 00:48:38.960
that it could support all the features


00:48:38.960 --> 00:48:40.640
that we had supported before.


00:48:40.640 --> 00:48:41.680
And now we're at the point


00:48:41.680 --> 00:48:43.520
where it's very trivial actually


00:48:43.520 --> 00:48:46.880
to add support for a library like Pydantic


00:48:46.880 --> 00:48:50.800
with everything from DTOs to OpenAPI


00:48:50.800 --> 00:48:53.600
to serialization, validation, parsing


00:48:53.600 --> 00:48:58.160
fully supported by a fairly trivial plugin


00:48:58.160 --> 00:48:59.680
that you have to add.


00:48:59.680 --> 00:49:03.040
So even if it's not provided out of the box,


00:49:03.040 --> 00:49:06.400
it's fairly easy to just do it yourself.


00:49:06.400 --> 00:49:07.040
It's really cool.


00:49:07.040 --> 00:49:08.480
All right, WebSockets.


00:49:08.480 --> 00:49:10.560
Let's talk about WebSockets here a little bit.


00:49:10.560 --> 00:49:12.400
Janik was the mastermind behind this.


00:49:12.400 --> 00:49:13.920
All right, Janik, first tell people


00:49:13.920 --> 00:49:16.640
what WebSockets are and why they care about them.


00:49:16.640 --> 00:49:18.880
Why is this not just another HTTP request?


00:49:18.880 --> 00:49:20.720
WebSockets, explaining WebSockets


00:49:20.720 --> 00:49:22.080
in a few sentences.


00:49:22.080 --> 00:49:22.800
Probably not that easy.


00:49:22.800 --> 00:49:24.480
Yeah, you have three sentences, go.


00:49:26.240 --> 00:49:29.680
So for people who have been around longer


00:49:29.680 --> 00:49:31.360
in the web development space,


00:49:31.360 --> 00:49:33.840
they might remember long polling.


00:49:33.840 --> 00:49:36.560
So where you had, where you faked,


00:49:36.560 --> 00:49:38.800
well, back and forth communication


00:49:38.800 --> 00:49:40.320
between the server and the client


00:49:40.320 --> 00:49:42.640
by having a request that never terminates.


00:49:42.640 --> 00:49:44.880
And then you can always send more data


00:49:44.880 --> 00:49:47.200
from the server because the request


00:49:47.200 --> 00:49:48.800
wasn't actually done yet.


00:49:48.800 --> 00:49:51.280
And I would say WebSockets is kind of like


00:49:51.280 --> 00:49:52.880
that concept but evolved.


00:49:54.000 --> 00:49:57.520
So you can easily send bidirectional data


00:49:57.520 --> 00:49:59.200
from the server to the client


00:49:59.200 --> 00:50:01.600
with a very, very minimal overhead.


00:50:01.600 --> 00:50:05.760
And WebSockets are a core functionality of ASGI.


00:50:05.760 --> 00:50:08.480
You could, there were several ways


00:50:08.480 --> 00:50:11.360
you could do WebSockets with WSGI,


00:50:11.360 --> 00:50:14.560
but they were all not very easy and straightforward


00:50:14.560 --> 00:50:17.280
because they are asynchronous by nature.


00:50:17.280 --> 00:50:18.480
This is what they are.


00:50:18.480 --> 00:50:20.640
They are an asynchronous communication channel.


00:50:20.640 --> 00:50:24.160
So baking that into a synchronous protocol


00:50:24.160 --> 00:50:25.520
is always a bit tricky.


00:50:25.520 --> 00:50:28.400
And I think there's no ASGI framework


00:50:28.400 --> 00:50:31.200
that I know of that does not support WebSockets


00:50:31.200 --> 00:50:32.320
in some way.


00:50:32.320 --> 00:50:35.680
So it is a core functionality of that type


00:50:35.680 --> 00:50:37.920
of Python framework, I would say.


00:50:37.920 --> 00:50:41.360
And so our WebSocket implementation


00:50:41.360 --> 00:50:43.200
has kind of like two layers.


00:50:43.200 --> 00:50:47.120
You have the low layer where it's basically


00:50:47.120 --> 00:50:49.840
you receive the socket object,


00:50:49.840 --> 00:50:51.360
which is just the connection.


00:50:51.360 --> 00:50:53.280
And then you can act on that connection


00:50:53.280 --> 00:50:55.360
and you have to accept it and you can terminate it


00:50:55.360 --> 00:50:57.440
and you can send data or whatever.


00:50:57.440 --> 00:51:00.960
And then you have what we call WebSocket listeners,


00:51:00.960 --> 00:51:04.160
which are an abstraction over WebSockets.


00:51:04.160 --> 00:51:08.320
And they basically work like you would normally define


00:51:08.320 --> 00:51:12.800
a route handle in Flask or FastAPI or Litestar,


00:51:12.800 --> 00:51:15.040
where you receive some data


00:51:15.040 --> 00:51:18.160
and then you return some data and that is your function.


00:51:18.160 --> 00:51:20.880
And the rest will be handled by the listeners.


00:51:20.880 --> 00:51:24.480
So you define a handler function for an event


00:51:24.480 --> 00:51:25.600
that might occur.


00:51:25.600 --> 00:51:28.800
One of the cool aspects of this is that these support


00:51:28.800 --> 00:51:31.200
all the features that Litestar supports


00:51:31.200 --> 00:51:32.720
in other layers of the application.


00:51:32.720 --> 00:51:34.480
So you can use DTOs with them.


00:51:34.480 --> 00:51:36.400
You can use validation with them.


00:51:36.400 --> 00:51:39.120
So if you define a DTO and you say,


00:51:39.120 --> 00:51:40.320
okay, so this is my model


00:51:40.320 --> 00:51:42.000
and this is what I want to receive,


00:51:42.000 --> 00:51:44.160
the incoming data from the WebSocket


00:51:44.160 --> 00:51:45.680
will be parsed as this model.


00:51:45.680 --> 00:51:46.800
It will be validated


00:51:46.800 --> 00:51:49.280
and then it will be presented to your function.


00:51:49.280 --> 00:51:53.040
So functionally, these WebSocket listeners,


00:51:53.040 --> 00:51:55.600
they look and work exactly the same


00:51:55.600 --> 00:51:58.640
as a regular HTTP route.


00:51:58.640 --> 00:51:59.520
Yeah, that's really cool.


00:51:59.520 --> 00:52:03.360
Enables another thing that a lot of ACI frameworks


00:52:03.360 --> 00:52:07.120
don't have, which is handling of WebSockets synchronously,


00:52:07.120 --> 00:52:09.600
because we do the async stuff in the background.


00:52:09.600 --> 00:52:12.480
And so you can use an asynchronous function,


00:52:12.480 --> 00:52:14.640
but you can also just synchronous function


00:52:14.640 --> 00:52:18.880
because all the dealing with the actual WebSocket itself


00:52:18.880 --> 00:52:20.400
is handled somewhere else.


00:52:20.400 --> 00:52:21.680
It's deeper, yeah.


00:52:21.680 --> 00:52:24.320
So my thought was probably this is what I want to write


00:52:24.320 --> 00:52:26.880
in a standard, like I want to receive a message


00:52:26.880 --> 00:52:30.480
from the client back to the server


00:52:30.480 --> 00:52:32.400
or and process that there.


00:52:32.400 --> 00:52:36.560
But if you want to do like all the weird multicast stuff,


00:52:36.560 --> 00:52:38.400
different listeners or groups of listeners,


00:52:38.400 --> 00:52:39.520
you can do with WebSockets.


00:52:39.520 --> 00:52:41.360
That's probably the lower level version


00:52:41.360 --> 00:52:42.480
you're talking about, right?


00:52:42.480 --> 00:52:43.200
Did I get that right?


00:52:43.200 --> 00:52:45.200
Yeah, perhaps not.


00:52:45.200 --> 00:52:47.280
It depends how weird you want to get.


00:52:47.280 --> 00:52:50.720
So a fairly standard use case would be for something


00:52:50.720 --> 00:52:54.560
like, let's say, a chat room where you have some sort


00:52:54.560 --> 00:52:57.440
of predefined channels and then you have multiple clients


00:52:57.440 --> 00:53:00.320
that want to send data over the same channel


00:53:00.320 --> 00:53:03.680
and then fan it out to all the other clients.


00:53:03.680 --> 00:53:06.560
And for stuff like that, we actually


00:53:06.560 --> 00:53:09.920
have a full integration, which we call channels,


00:53:09.920 --> 00:53:11.920
which themselves aren't necessarily


00:53:11.920 --> 00:53:13.280
tied to WebSockets.


00:53:13.280 --> 00:53:18.400
They are basically distributed message bus sort of thing.


00:53:18.400 --> 00:53:22.080
I have yet to come up with a good, short description


00:53:22.080 --> 00:53:24.400
of what channels actually are.


00:53:24.400 --> 00:53:26.880
It changes a bit from depending what I'm talking about.


00:53:26.880 --> 00:53:30.080
I think message bus is the way to think about it, right?


00:53:30.080 --> 00:53:32.400
And it keeps the history of the events.


00:53:32.400 --> 00:53:34.320
And so a message bus is perfectly fine.


00:53:34.320 --> 00:53:35.840
They are backed by, at the moment,


00:53:35.840 --> 00:53:38.000
by Redis via different methods.


00:53:38.000 --> 00:53:41.760
So you can use PubSub or other methods that


00:53:41.760 --> 00:53:43.760
are quite a bit more involved.


00:53:43.760 --> 00:53:47.200
And they can also handle WebSockets for you.


00:53:47.200 --> 00:53:53.440
So you can say, OK, so I want to create a channel named Chat.


00:53:53.440 --> 00:53:56.640
And every time someone signs up to that,


00:53:56.640 --> 00:53:58.800
please accept the WebSocket request


00:53:58.800 --> 00:54:01.680
and then add the client to this subscriber list.


00:54:01.680 --> 00:54:06.240
And then every time a message comes in, I want to do this.


00:54:06.240 --> 00:54:09.200
And then I also want to distribute the message


00:54:09.200 --> 00:54:12.720
they send to all these other clients in those channels.


00:54:12.720 --> 00:54:15.360
And I know if they send a special message,


00:54:15.360 --> 00:54:17.200
then I want to unsubscribe them.


00:54:17.200 --> 00:54:22.480
And so for this kind of standard use case, we have that built in.


00:54:22.480 --> 00:54:25.920
You can, of course, build your own logic on top of that.


00:54:25.920 --> 00:54:29.920
And as you said, if you want to go into really weird stuff,


00:54:29.920 --> 00:54:32.800
you will have to use the low-level interface, which


00:54:32.800 --> 00:54:34.640
is also there, which you can also


00:54:34.640 --> 00:54:36.560
access from the WebSocket listener.


00:54:36.560 --> 00:54:38.400
So you can, via dependency injection,


00:54:38.400 --> 00:54:40.640
just receive the raw socket object


00:54:40.640 --> 00:54:43.840
if you want to deal with that for some reason.


00:54:43.840 --> 00:54:45.040
So it's available if you need it,


00:54:45.040 --> 00:54:47.200
but you can do the easy thing by default.


00:54:47.200 --> 00:54:47.840
Oh, awesome.


00:54:47.840 --> 00:54:48.640
That sounds really cool.


00:54:48.640 --> 00:54:49.760
And the channels sound great.


00:54:49.760 --> 00:54:51.600
Also, Chris out in the audience said,


00:54:51.600 --> 00:54:54.160
does that also mean server-side events are?


00:54:54.160 --> 00:54:54.720
Yes.


00:54:54.720 --> 00:54:56.880
Server-sent events, rather, excuse me, are available.


00:54:56.880 --> 00:55:00.800
And I saw that you have a dependency on HTTPxSSE,


00:55:00.800 --> 00:55:04.000
which is like a lightweight, lightweight WebSocket


00:55:04.000 --> 00:55:04.480
type of thing.


00:55:04.480 --> 00:55:05.040
It's very cool.


00:55:05.040 --> 00:55:07.200
That's a development dependency for testing.


00:55:07.200 --> 00:55:08.160
Ah, for testing.


00:55:08.160 --> 00:55:08.880
OK.


00:55:08.880 --> 00:55:12.960
So we do have server-sent events support built in.


00:55:12.960 --> 00:55:13.920
You can do that.


00:55:13.920 --> 00:55:16.320
And you can, for example, use that


00:55:16.320 --> 00:55:17.760
in combination with channels.


00:55:17.760 --> 00:55:21.600
So instead of fanning out the messages via WebSockets,


00:55:21.600 --> 00:55:24.400
you could do that with a server-sent event as well.


00:55:24.400 --> 00:55:24.960
Excellent.


00:55:24.960 --> 00:55:25.200
All right.


00:55:25.200 --> 00:55:27.360
We're getting quite short on time.


00:55:27.360 --> 00:55:29.840
I want to close this out with maybe


00:55:29.840 --> 00:55:33.040
what would be the last thing in the process of building out


00:55:33.040 --> 00:55:34.480
an app in Litestar?


00:55:34.480 --> 00:55:36.240
That would be deployment.


00:55:36.240 --> 00:55:38.720
And I didn't see a lot of conversation


00:55:38.720 --> 00:55:41.600
about how I should be deploying this stuff on the website.


00:55:41.600 --> 00:55:43.440
But I saw on the benchmarks that you said,


00:55:43.440 --> 00:55:46.880
we use GUnicorn with the UVicorn worker and so on.


00:55:46.880 --> 00:55:50.960
And it sounds like maybe using GUnicorn is a good option.


00:55:50.960 --> 00:55:52.080
What's the deployment story?


00:55:52.080 --> 00:55:54.080
What do you tell people that want to put this


00:55:54.080 --> 00:55:56.640
in some real scaled-out production story?


00:55:56.640 --> 00:55:58.480
That's still a good option.


00:55:58.480 --> 00:56:00.960
But personally, I think Cody's well.


00:56:00.960 --> 00:56:05.280
We've just been using UVicorn, not as a worker,


00:56:05.280 --> 00:56:06.400
just by itself.


00:56:06.400 --> 00:56:08.000
That has worked really well.


00:56:08.000 --> 00:56:09.840
It really just depends on how you're going to run it.


00:56:09.840 --> 00:56:14.000
So if you're using Docker or Kubernetes or something else


00:56:14.000 --> 00:56:16.800
that's managing that process, then it's


00:56:16.800 --> 00:56:20.640
possible that GUnicorn may not be something that really


00:56:20.640 --> 00:56:21.920
is needed in your environment.


00:56:21.920 --> 00:56:24.240
And in fact, it might actually just add overhead.


00:56:24.240 --> 00:56:27.120
And so if you've got something like Cloud Run or Docker


00:56:27.120 --> 00:56:29.120
or Kubernetes or anything like that,


00:56:29.120 --> 00:56:30.880
what we've realized is that sometimes it's


00:56:30.880 --> 00:56:32.960
quite a bit faster to just run it with UVicorn.


00:56:32.960 --> 00:56:36.400
And if the process dies, then your container management,


00:56:36.400 --> 00:56:38.880
whatever you're using to manage those things,


00:56:38.880 --> 00:56:41.600
will automatically start and scale those processes out.


00:56:41.600 --> 00:56:44.320
It notices that the container exited anyway,


00:56:44.320 --> 00:56:45.760
and so it's going to create a new one, right?


00:56:45.760 --> 00:56:46.480
OK, got it.


00:56:46.480 --> 00:56:46.960
Correct, yeah.


00:56:46.960 --> 00:56:50.160
But if I'm going to a Linux machine directly?


00:56:50.160 --> 00:56:51.680
Then I think there's more of a decision


00:56:51.680 --> 00:56:53.120
to make on whether or not you want to host it


00:56:53.120 --> 00:56:54.960
through something like GUnicorn.


00:56:54.960 --> 00:56:56.720
And I guess the other thing I'd like to add


00:56:56.720 --> 00:57:00.640
is that really there's any of the ASCII servers


00:57:00.640 --> 00:57:02.400
can run Litestar.


00:57:02.400 --> 00:57:05.600
So you've got Daphne, Hypercorn.


00:57:05.600 --> 00:57:08.400
There's work that we're doing right now with Socketify.


00:57:08.400 --> 00:57:09.440
It's a mouthful as well.


00:57:09.440 --> 00:57:11.280
But they've got some cool stuff going on there.


00:57:11.280 --> 00:57:13.920
And so hopefully we'll have compatibility with that soon.


00:57:13.920 --> 00:57:16.480
And so yeah, the idea is that the same way


00:57:16.480 --> 00:57:18.080
that you would host any other ASCII app


00:57:18.080 --> 00:57:20.800
would apply to how you would manage a Litestar app.


00:57:20.800 --> 00:57:21.360
Excellent.


00:57:21.360 --> 00:57:24.720
And maybe Nginx or something like that in front for SSL


00:57:24.720 --> 00:57:26.320
and Let's Encrypt and all those things.


00:57:26.320 --> 00:57:26.800
Absolutely.


00:57:26.800 --> 00:57:29.120
I think that's probably about it for time.


00:57:29.120 --> 00:57:30.480
Final thing here.


00:57:30.480 --> 00:57:33.600
So you all said you just released a week ago or so.


00:57:33.600 --> 00:57:36.000
Last week, released version two.


00:57:36.000 --> 00:57:38.080
I want to give a quick shout out to the changes


00:57:38.080 --> 00:57:39.440
for people maybe already using it.


00:57:39.440 --> 00:57:41.360
I don't know if that's even possible.


00:57:41.360 --> 00:57:44.480
This has been in development for over seven months now.


00:57:44.480 --> 00:57:44.880
Okay.


00:57:44.880 --> 00:57:47.280
And there have been substantial changes


00:57:47.280 --> 00:57:51.280
to basically every part of the application


00:57:51.280 --> 00:57:52.720
that you could think of.


00:57:52.720 --> 00:57:55.440
A lot of the features that we have talked about today,


00:57:55.440 --> 00:57:57.600
they are new in version 2.0.


00:57:57.600 --> 00:58:00.000
The DTOs, they are new in 2.0.


00:58:00.000 --> 00:58:02.000
The SQLAlchemy integration is new.


00:58:02.000 --> 00:58:02.960
Channels are new.


00:58:02.960 --> 00:58:04.720
The WebSocket listeners are new.


00:58:04.720 --> 00:58:06.800
Message spec integration is new.


00:58:06.800 --> 00:58:08.800
Pedantic billing being optional is new.


00:58:08.800 --> 00:58:10.560
So I think it doesn't make a lot of sense


00:58:10.560 --> 00:58:12.640
to compare it to version 1.0.


00:58:12.640 --> 00:58:13.840
So just in this context.


00:58:13.840 --> 00:58:16.160
Strongly encourage people to use 2.0.


00:58:16.160 --> 00:58:17.760
Yeah, definitely.


00:58:17.760 --> 00:58:19.280
Please use version two.


00:58:19.280 --> 00:58:22.000
We also have the new stores interface.


00:58:22.000 --> 00:58:22.880
As well.


00:58:22.880 --> 00:58:26.720
And so many other features that I forgot about


00:58:26.720 --> 00:58:28.400
or don't have time to list.


00:58:28.400 --> 00:58:30.000
HTMX request.


00:58:30.000 --> 00:58:30.800
All sorts of good stuff.


00:58:30.800 --> 00:58:31.120
Okay.


00:58:31.120 --> 00:58:33.520
Yeah, there have been so many people,


00:58:33.520 --> 00:58:37.040
amazing contributors over the last several months


00:58:37.040 --> 00:58:38.240
spending time on this


00:58:38.240 --> 00:58:41.200
and delivering awesome features for us,


00:58:41.200 --> 00:58:42.240
for the community.


00:58:42.240 --> 00:58:44.480
There's been so much work going into this.


00:58:44.480 --> 00:58:48.080
And well, I was relieved when I finally


00:58:48.080 --> 00:58:51.600
was able to hit the publish button on GitHub


00:58:51.600 --> 00:58:54.080
and we could finally get it out.


00:58:54.080 --> 00:58:55.440
It's a big, big project.


00:58:55.440 --> 00:58:56.000
That's right.


00:58:56.000 --> 00:58:58.880
A lot of people have already been using version 2.0


00:58:58.880 --> 00:58:59.680
in production.


00:58:59.680 --> 00:59:00.720
Cody, you have.


00:59:00.720 --> 00:59:01.840
Jacob, you have as well.


00:59:01.840 --> 00:59:04.480
Basically, since we started development,


00:59:04.480 --> 00:59:05.360
I actually haven't.


00:59:05.360 --> 00:59:11.600
I've stuck on 1.5 for a long time.


00:59:11.600 --> 00:59:12.160
Now it's out.


00:59:12.160 --> 00:59:13.360
One of the things I'll add is that


00:59:13.360 --> 00:59:15.040
the velocity of the project is,


00:59:15.040 --> 00:59:16.800
it seems to be really high.


00:59:16.800 --> 00:59:19.760
And it's encouraging to see all the contributions


00:59:19.760 --> 00:59:22.000
and all the edits that everybody's making.


00:59:22.000 --> 00:59:24.720
And so I, for one, I'm really excited about


00:59:24.720 --> 00:59:26.720
what it's going to look like in a year.


00:59:26.720 --> 00:59:28.720
I think we've got a lot of opportunity ahead of us


00:59:28.720 --> 00:59:32.400
and looking forward to seeing everybody jump in


00:59:32.400 --> 00:59:33.440
and try things out.


00:59:33.440 --> 00:59:36.320
And if something doesn't work the way that you want it to,


00:59:36.320 --> 00:59:38.800
feel free to open up an issue or hop on Discord.


00:59:38.800 --> 00:59:40.320
We're all very responsive


00:59:40.320 --> 00:59:41.760
and would love to kind of hear


00:59:41.760 --> 00:59:43.920
what our users are thinking about


00:59:43.920 --> 00:59:45.440
as they build their applications.


00:59:45.440 --> 00:59:46.800
It seems like a great framework.


00:59:46.800 --> 00:59:49.040
I really like the balance you're striking


00:59:49.040 --> 00:59:50.240
between the micro frameworks


00:59:50.240 --> 00:59:52.080
and some of the batteries included.


00:59:52.080 --> 00:59:54.160
So congrats to all of you.


00:59:54.160 --> 00:59:55.360
Now, before we get out of here,


00:59:55.360 --> 00:59:57.360
just I'll ask one quick question,


00:59:57.360 --> 00:59:59.360
you know, for I usually ask at the end,


00:59:59.360 --> 01:00:02.160
and that is a quick shout out to some package


01:00:02.160 --> 01:00:04.160
or library out there that you like


01:00:04.160 --> 01:00:05.920
and want to spread the word about.


01:00:05.920 --> 01:00:07.120
I guess I'll start.


01:00:07.120 --> 01:00:08.240
DuckDB for me.


01:00:08.240 --> 01:00:11.680
So I have used a massive amount of DuckDB


01:00:11.680 --> 01:00:13.200
and you can kind of think about it


01:00:13.200 --> 01:00:15.280
as like an analytical SQLite.


01:00:15.280 --> 01:00:17.280
And so it's in process.


01:00:17.280 --> 01:00:18.320
And so you can start it up


01:00:18.320 --> 01:00:22.320
and just run SQL directly from your Python process.


01:00:22.320 --> 01:00:24.480
And so the project that I'm working on at Google


01:00:24.480 --> 01:00:26.160
actually has quite a bit of DuckDB


01:00:26.160 --> 01:00:28.880
as kind of this like middle ETL piece


01:00:28.880 --> 01:00:30.000
where data gets ingested.


01:00:30.000 --> 01:00:32.240
We do things in DuckDB


01:00:32.240 --> 01:00:33.760
and then that actually gets exported


01:00:33.760 --> 01:00:36.240
to BigQuery or other database engines.


01:00:36.240 --> 01:00:38.160
And so this really has kind of opened up


01:00:38.160 --> 01:00:39.360
the flexibility of us


01:00:39.360 --> 01:00:41.120
to be able to do quite a bit of transformations,


01:00:41.120 --> 01:00:43.760
just in RAM without having to write to disk.


01:00:43.760 --> 01:00:44.240
That's cool.


01:00:44.240 --> 01:00:47.920
An in-process SQL lab database management system.


01:00:47.920 --> 01:00:48.160
Cool.


01:00:48.160 --> 01:00:51.040
He's been recruiting us to use DuckDB


01:00:51.040 --> 01:00:52.240
for quite a while now.


01:00:52.240 --> 01:00:53.440
And he succeeded.


01:00:53.440 --> 01:00:55.200
That's cool.


01:00:55.200 --> 01:00:57.520
I love what the standard library has,


01:00:57.520 --> 01:01:01.680
but Click is like one of my favorite CLI building tools.


01:01:01.680 --> 01:01:04.800
Rich is the thing that makes you


01:01:04.800 --> 01:01:06.240
make your terminal beautiful.


01:01:06.240 --> 01:01:07.760
But there's this really cool package.


01:01:07.760 --> 01:01:09.840
I mean, you can use them both separately,


01:01:09.840 --> 01:01:11.600
but rich-qlik.


01:01:11.600 --> 01:01:15.600
And it's what we use for our CLI.


01:01:15.600 --> 01:01:18.160
You have the great Click CLI building stuff,


01:01:18.160 --> 01:01:20.000
but then rich on top of it


01:01:20.000 --> 01:01:21.840
automatically makes everything pretty.


01:01:21.840 --> 01:01:22.560
That's cool.


01:01:22.560 --> 01:01:25.840
So it's like all the magic and niceness of rich,


01:01:25.840 --> 01:01:27.760
but available for Click,


01:01:27.760 --> 01:01:29.920
like colors and your help documents.


01:01:29.920 --> 01:01:32.320
I haven't gotten to check out Sebastian's typer yet,


01:01:32.320 --> 01:01:33.920
but I've seen some screenshots


01:01:33.920 --> 01:01:34.880
and it's sort of similar.


01:01:34.880 --> 01:01:36.560
I don't know a whole lot about that,


01:01:36.560 --> 01:01:38.720
but I think it also uses rich, right?


01:01:38.720 --> 01:01:39.280
I think so.


01:01:39.280 --> 01:01:39.760
Nice.


01:01:39.760 --> 01:01:40.480
All right, Yannick.


01:01:40.480 --> 01:01:43.200
Well, for me, it's got to be message spec


01:01:43.200 --> 01:01:44.480
because it's just...


01:01:44.480 --> 01:01:48.800
So if you do any kind of JSON parsing or serialization


01:01:48.800 --> 01:01:50.960
or msgspec parsing or serialization


01:01:50.960 --> 01:01:55.040
or data modeling that you might usually


01:01:55.040 --> 01:01:56.960
want to do with a data class


01:01:56.960 --> 01:01:59.680
and want to add a bit of validation on top,


01:01:59.680 --> 01:02:01.920
or just if you're curious,


01:02:01.920 --> 01:02:04.480
you should absolutely check this library out


01:02:04.480 --> 01:02:06.400
because it's super amazing.


01:02:06.400 --> 01:02:09.280
The author is really, really great.


01:02:09.280 --> 01:02:11.920
I can just give him just a huge shout out


01:02:11.920 --> 01:02:14.400
because he's done such a great job


01:02:14.400 --> 01:02:16.800
at supporting our integration with it.


01:02:16.800 --> 01:02:20.240
It has been quite a tight collaboration at some points


01:02:20.240 --> 01:02:22.400
because when we started integrating it,


01:02:22.400 --> 01:02:25.600
there were a lot of things where we felt like,


01:02:25.600 --> 01:02:29.360
okay, so, well, we kind of can't use it right now


01:02:29.360 --> 01:02:31.040
because of this reason or that reason.


01:02:31.040 --> 01:02:33.920
And he's been so responsive and helpful


01:02:33.920 --> 01:02:36.880
in finding ways for us to work around that


01:02:36.880 --> 01:02:38.720
or just straight up implementing features


01:02:38.720 --> 01:02:40.160
that were missing for us.


01:02:40.160 --> 01:02:40.880
And it's really...


01:02:40.880 --> 01:02:41.840
That's pretty awesome.


01:02:41.840 --> 01:02:43.360
I can't thank him enough.


01:02:43.360 --> 01:02:44.720
It's really great.


01:02:44.720 --> 01:02:46.560
It's a pleasure to work with him.


01:02:46.560 --> 01:02:48.480
And it's an awesome library


01:02:48.480 --> 01:02:50.880
that everyone should check out, I think.


01:02:50.880 --> 01:02:52.000
Cool. That's news to me.


01:02:52.000 --> 01:02:53.520
So I will definitely check it out.


01:02:53.520 --> 01:02:55.680
All right. Well, thank you all for being here.


01:02:55.680 --> 01:02:56.640
Final call to action.


01:02:56.640 --> 01:02:58.480
People want to get started with Litestar.


01:02:58.480 --> 01:02:59.040
What do you tell them?


01:02:59.040 --> 01:03:00.560
Go to lightstar.dev.


01:03:00.560 --> 01:03:01.760
You can read the docs.


01:03:01.760 --> 01:03:03.680
Use it 15 minutes, 30 minutes.


01:03:03.680 --> 01:03:04.800
You'll know if you like it or not.


01:03:04.800 --> 01:03:06.800
Join us on Discord if you have questions.


01:03:06.800 --> 01:03:09.840
We're happy to help answer anything that may come up.


01:03:09.840 --> 01:03:12.480
I don't think I can add anything valuable to that anymore.


01:03:12.480 --> 01:03:14.080
All right.


01:03:14.080 --> 01:03:15.200
Well, yeah.


01:03:15.200 --> 01:03:16.000
Sounds good, guys.


01:03:16.000 --> 01:03:17.040
Thank you for being here.


01:03:17.040 --> 01:03:18.000
Congrats on the project.


01:03:18.000 --> 01:03:18.640
Thank you, Michael.


01:03:18.640 --> 01:03:19.140
Bye-bye.


01:03:20.100 --> 01:03:22.980
This has been another episode of Talk Python to Me.


01:03:22.980 --> 01:03:24.980
Thank you to our sponsors.


01:03:24.980 --> 01:03:26.500
Be sure to check out what they're offering.


01:03:26.500 --> 01:03:27.860
It really helps support the show.


01:03:27.860 --> 01:03:30.180
Take some stress out of your life.


01:03:30.180 --> 01:03:33.620
Get notified immediately about errors and performance issues


01:03:33.620 --> 01:03:36.180
in your web or mobile applications with Sentry.


01:03:36.180 --> 01:03:41.060
Just visit talkpython.fm/Sentry and get started for free.


01:03:41.060 --> 01:03:44.340
And be sure to use the promo code talkpython, all one word.


01:03:44.340 --> 01:03:46.580
Want to level up your Python?


01:03:46.580 --> 01:03:50.740
We have one of the largest catalogs of Python video courses over at Talk Python.


01:03:50.740 --> 01:03:55.780
Our content ranges from true beginners to deeply advanced topics like memory and async.


01:03:55.780 --> 01:03:58.420
And best of all, there's not a subscription in sight.


01:03:58.420 --> 01:04:01.620
Check it out for yourself at training.talkpython.fm.


01:04:01.620 --> 01:04:03.300
Be sure to subscribe to the show.


01:04:03.300 --> 01:04:06.180
Open your favorite podcast app and search for Python.


01:04:06.180 --> 01:04:07.620
We should be right at the top.


01:04:07.620 --> 01:04:10.500
You can also find the iTunes feed at /itunes,


01:04:10.500 --> 01:04:17.140
the Google Play feed at slash Play, and the direct RSS feed at /rss on talkpython.fm.


01:04:17.140 --> 01:04:19.700
We're live streaming most of our recordings these days.


01:04:19.700 --> 01:04:23.140
If you want to be part of the show and have your comments featured on the air,


01:04:23.140 --> 01:04:27.460
be sure to subscribe to our YouTube channel at talkpython.fm/youtube.


01:04:27.460 --> 01:04:29.700
This is your host, Michael Kennedy.


01:04:29.700 --> 01:04:30.900
Thanks so much for listening.


01:04:30.900 --> 01:04:32.020
I really appreciate it.


01:04:32.020 --> 01:04:33.860
Now get out there and write some Python code.


01:04:34.580 --> 01:04:42.180
Bye.


01:04:42.180 --> 01:04:54.500
Bye.


01:04:54.500 --> 01:04:57.260
this is a test.

